import{e}from"./vendor/toon.js";import{J as t}from"./vendor/jsox.js";const n={math:"input_text",url:"input_image",text:"input_text",input_text:"input_text",output_text:"input_text",image_url:"input_image",image:"input_image",input_image:"input_image",input_url:"input_image",json:"input_text",markdown:"input_text",code:"input_text",entity:"input_text",structured:"input_text"},r=e=>{if(!e)return"input_text";const t=e.toLowerCase();return t.includes("image")?"input_image":t.includes("json")?"json":t.includes("javascript")||t.includes("typescript")?"code":t.includes("markdown")||t.includes("md")?"markdown":t.includes("url")?"input_url":t.includes("text/html")?"markdown":(t.includes("text/plain"),"input_text")},a=e=>{const t=e?.context,r=n?.[e?.dataKind||"input_text"],a=o(t);switch(r){case"input_image":return`${a}\n\nRecognize data from image, also preferred to orient by fonts in image.\n\nAfter recognition, do not include or remember image itself.\n\n---\n\nIn (\`recognized_data\` key), can be written phone numbers, emails, URLs, dates, times, codes, etc. Additional formatting rules:\n\nIn recognized from image data (what you seen in image), do:\n- If textual content, format as Markdown string (multiline).\n- If phone number, format as as correct phone number (in normalized format).\n  - Also, if phone numbers (for example starts with +7, format as 8), replace to correct regional code.\n  - Remove brackets, parentheses, spaces or other symbols from phone number.\n  - Trim spaces from phone number.\n- If email, format as as correct email (in normalized format), and trim spaces from email.\n- If URL, format as as correct URL (in normalized format), and unicode codes to human readable, and trim spaces from URL.\n- If date, format as as correct date (in normalized format).\n- If time, format as as correct time (in normalized format).\n- If math (expression, equation, formula), format as $KaTeX$\n- If table (or looks alike table), format as | table |\n- If image, format as [$image$]($image$)\n- If code, format as \`\`\`$code$\`\`\` (multiline) or \`$code$\` (single-line)\n- If JSON, format as correct JSON string, and trim spaces from JSON string.\n- If other, format as $text$.\n- If seen alike list, format as list (in markdown format).\n\n---\n\nSome additional actions:\n- Collect some special data tags and keywords (if has any).\n- Also, can you provide in markdown pre-formatted free-form analyzed or recognized verbose data (in \`verbose_data\` key).\n\n---\n\nCRITICAL OUTPUT FORMAT: Return ONLY valid JSON. No markdown code blocks, no explanations, no prose.\nYour response must start with { or [ and end with } or ].\n\nExpected output structure:\n{\n    "keywords_and_tags": ["string array"],\n    "recognized_data": ["any array"],\n    "verbose_data": "markdown string",\n    "using_ready": true,\n    "confidence": 0.95,\n    "suggested_type": "document_type"\n}\n`;case"input_text":return`${a}\n\nAnalyze text and extract specific or special data from it, also normalize data by those rules...\n\n---\n\nIn (\`recognized_data\` key), can be written phone numbers, emails, URLs, dates, times, codes, etc. Additional formatting rules:\n\nNormalize phone numbers, emails, URLs, dates, times, codes, etc for best efforts and by those rules.\n- If phone number, format as as correct phone number (in normalized format).\n  - If phone numbers (for example starts with +7, format as 8), replace to correct regional code.\n  - Trim spaces from phone numbers, emails, URLs, dates, times, codes, etc.\n  - Remove brackets, parentheses, spaces or other symbols from phone numbers.\n- If email, format as as correct email (in normalized format), and trim spaces from email.\n- If URL, format as as correct URL (in normalized format), and unicode codes to human readable, and trim spaces from URL.\n- If date, format as as correct date (in normalized format).\n- If time, format as as correct time (in normalized format).\n- If math, format as $KaTeX$\n- If table, format as | table |\n- If image, format as [$image$]($image$)\n- If code, format as \`\`\`$code$\`\`\` (multiline) or \`$code$\` (single-line)\n- If JSON, format as correct JSON string, and trim spaces from JSON string.\n- If other, format as $text$.\n- If seen alike list, format as list (in markdown format).\n\n---\n\nSome additional actions:\n- Collect some special data tags and keywords (if has any).\n- Also, can you provide in markdown pre-formatted free-form analyzed or recognized verbose data (in \`verbose_data\` key).\n- Detect entity type if applicable (task, event, person, place, service, item, etc.)\n\n---\n\nCRITICAL OUTPUT FORMAT: Return ONLY valid JSON. No markdown code blocks, no explanations, no prose.\nYour response must start with { or [ and end with } or ].\n\nExpected output structure:\n{\n    "keywords_and_tags": ["string array"],\n    "recognized_data": ["any array"],\n    "verbose_data": "markdown string",\n    "using_ready": true,\n    "confidence": 0.95,\n    "suggested_type": "entity_type",\n    "suggested_modifications": []\n}\n`}return a||""},o=e=>{if(!e)return"";const t=[];if(e.operation&&t.push(`Operation: ${{create:"Create new data entries based on provided information.",modify:"Modify existing data with provided changes while preserving structure.",merge:"Intelligently merge new data with existing data, avoiding duplicates.",analyze:"Analyze and extract structured information from the data.",extract:"Extract specific data points matching the criteria."}[e.operation]||e.operation}`),e.entityType&&t.push(`Target entity type: ${e.entityType}`),e.existingData&&t.push("Existing data context provided - consider for merge/update operations."),e.filters?.length){const n=e.filters.map(e=>`${e.field} ${e.operator} ${JSON.stringify(e.value)}`).join(", ");t.push(`Apply filters: ${n}`)}return e.searchTerms?.length&&t.push(`Search terms: ${e.searchTerms.join(", ")}`),e.priority&&t.push(`Priority level: ${e.priority}`),t.length?`Context:\n${t.join("\n")}\n\n---\n`:""},s=[/```json\s*\n?([\s\S]*?)\n?```/i,/```toon\s*\n?([\s\S]*?)\n?```/i,/```\s*\n?([\s\S]*?)\n?```/,/(\{[\s\S]*\})/,/(\[[\s\S]*\])/],i=e=>e&&"string"==typeof e?e.replace(/^\uFEFF/,"").replace(/[\u200B-\u200D\uFEFF]/g,"").replace(/\r\n/g,"\n").replace(/\r/g,"\n").trim():"",c=e=>{let t=e;return t=t.replace(/,(\s*[}\]])/g,"$1"),t=t.replace(/:\s*"([^"]*)\n([^"]*)"/g,(e,t,n)=>`: "${t}\\n${n}"`),t=t.replace(/[\x00-\x08\x0B\x0C\x0E-\x1F]/g,""),t},l=e=>{if(!e)return{ok:!1,error:"Empty input"};try{return{ok:!0,data:t.parse(e)}}catch{}try{return{ok:!0,data:JSON.parse(e)}}catch{}try{const n=c(e);return{ok:!0,data:t.parse(n)}}catch{}try{const n=e.match(/^[^{[]*([{\[][\s\S]*[}\]])[^}\]]*$/);if(n?.[1])return{ok:!0,data:t.parse(n[1])}}catch{}return{ok:!1,error:"Failed to parse JSON with all strategies"}},d=e=>{if(null==e)return{ok:!1,error:"Response is null or undefined"};if("string"!=typeof e)return"object"==typeof e?{ok:!0,data:e,source:"direct"}:{ok:!1,error:"Expected string, got "+typeof e};const t=i(e);if(!t)return{ok:!1,error:"Response is empty after cleaning",raw:e};const n=l(t);if(n.ok)return{ok:!0,data:n.data,raw:e,source:"direct"};for(const a of s){const n=t.match(a);if(n?.[1]){const t=i(n[1]),r=l(t);if(r.ok)return{ok:!0,data:r.data,raw:e,source:"markdown_block"}}}const r=t.match(/(\{[\s\S]+\}|\[[\s\S]+\])/);if(r?.[1]){const t=c(r[1]),n=l(t);if(n.ok)return{ok:!0,data:n.data,raw:e,source:"recovered"}}return{ok:!1,error:"Could not extract valid JSON from response",raw:e}},u={low:6e4,medium:3e5,high:9e5},p=async t=>{const r=void 0!==globalThis.File?globalThis.File:void 0,a=void 0!==globalThis.Blob?globalThis.Blob:void 0;if(a&&t?.dataSource instanceof a||r&&t?.dataSource instanceof r){const e=t?.dataSource?.size||0,r=10485760;if(e>r)return console.warn(`[GPT-Responses] File too large: ${e} bytes > ${r} bytes`),{type:"input_text",text:`[File too large: ${(e/1024/1024).toFixed(1)}MB. Maximum allowed: ${(r/1024/1024).toFixed(1)}MB]`};if("input_image"===n?.[t?.dataKind||"input_text"]||t?.dataSource?.type?.startsWith?.("image/"))try{const e=`data:${t?.dataSource?.type};base64,`,n=await(t?.dataSource?.arrayBuffer());if(!n)throw new Error("Failed to read file as ArrayBuffer");const r=e+(e=>{if(void 0!==globalThis.Buffer)return globalThis.Buffer.from(e).toString("base64");const t=1048576;if(e.length>t){let n="";for(let r=0;r<e.length;r+=t){const a=e.slice(r,r+t);let o="";for(let e=0;e<a.length;e++)o+=String.fromCharCode(a[e]);n+="function"==typeof btoa?btoa(o):""}return n}let n="";for(let r=0;r<e.length;r++)n+=String.fromCharCode(e[r]);return"function"==typeof btoa?btoa(n):""})(new Uint8Array(n));return{type:"input_image",detail:"auto",image_url:r}}catch(s){return console.error("[GPT-Responses] Failed to process image file:",s),{type:"input_text",text:`[Failed to process image file: ${s}]`}}try{const e=await(t?.dataSource?.text?.());if(e)return{type:"input_text",text:e}}catch(s){return console.error("[GPT-Responses] Failed to read text file:",s),{type:"input_text",text:`[Failed to read text file: ${s}]`}}}else if("string"==typeof t?.dataSource){const e=t?.dataKind||(e=>{if(!e||"string"!=typeof e)return"input_text";const t=e.trim();if(t.startsWith("{")&&t.endsWith("}")||t.startsWith("[")&&t.endsWith("]"))try{return JSON.parse(t),"json"}catch{}return URL.canParse(t?.trim?.()||"",void 0===("undefined"!=typeof window?window:globalThis)?.location?void 0:("undefined"!=typeof window?window:globalThis)?.location?.origin||"")?"url":t.startsWith("data:image/")&&t.includes(";base64,")?"input_image":/\$\$[\s\S]+\$\$|\$[^$]+\$|\\begin\{equation\}/.test(t)?"math":/```[\s\S]+```|^(function|const|let|var|class|import|export)\s/m.test(t)?"code":/^#{1,6}\s|^\*\*|^-\s|\[.+\]\(.+\)|^>\s/m.test(t)?"markdown":"input_text"})(t.dataSource);return t?.dataSource?.startsWith?.("data:image/")&&t?.dataSource?.includes?.(";base64,")||URL.canParse(t?.dataSource?.trim?.()||"",void 0===("undefined"!=typeof window?window:globalThis)?.location?void 0:("undefined"!=typeof window?window:globalThis)?.location?.origin||"")||"input_image"==n?.[e]?{type:"input_image",image_url:t?.dataSource,detail:"auto"}:{type:"input_text",text:t?.dataSource}}let o=t?.dataSource;try{o="object"!=typeof t?.dataSource?t?.dataSource:e(t?.dataSource)}catch(i){console.warn(i)}return{type:n?.[t?.dataKind||"input_text"]||"text",text:o}};class m{apiKey;apiSecret;apiUrl="https://api.proxyapi.ru/openai/v1";model="gpt-5.2";responseId=null;pending=[];messages=[];tools=/* @__PURE__ */new Map;context=null;responseMap=/* @__PURE__ */new Map;constructor(e,t,n,r){this.apiKey=e||"",this.apiUrl=t||this.apiUrl,this.apiSecret=n||"",this.model=r||this.model}setContext(e){return this.context=e,this}async useMCP(e,t,n,r){return this.tools.set(t?.trim?.(),{type:"mcp",server_label:e,server_url:t,headers:{authorization:`Bearer ${n}:${r}`},require_approval:"never"}),this.tools.get(t?.trim?.())}async convertPlainToInput(e,t=null,n=null){t??=r(e?.type)||"input_text";const o={dataSource:e,dataKind:t,context:this.context},s=await p(o);return{type:"message",role:"user",content:[{type:"input_text",text:"What to do: "+a(o)},n?{type:"text",text:"Additional request data: "+n}:null,{type:"input_text",text:"\n === BEGIN:ATTACHED_DATA === \n"},{...s},{type:"input_text",text:"\n === END:ATTACHED_DATA === \n"}]?.filter?.(e=>null!==e)}}async attachToRequest(e,t=null,n=null){return this.pending.push(await this.convertPlainToInput(e,t??=r(e?.type)||"input_text")),n&&this.pending.push(await this.askToDoAction(n)),this.pending[this.pending.length-1]}async attachExistingData(t,n){return this.context={...this.context,existingData:t,entityType:n||this.context?.entityType},await this.giveForRequest(`existing_data: \`${e(t)}\`\n`),this}async giveForRequest(e){return this?.pending?.push?.({type:"message",role:"user",content:[{type:"input_text",text:"Additional data for request: "},{type:"input_text",text:e}]}),this?.pending?.[this?.pending?.length-1]}async askToDoAction(e){return this?.pending?.push?.({type:"message",role:"user",content:[{type:"input_text",text:e}]}),this?.pending?.[this?.pending?.length-1]}beginFromResponseId(e=null){return this.responseId=this.responseId=e||this.responseId,this}async sendRequest(e="low",n="low",r=null,a={}){e??="low",n??="low";const o=/* @__PURE__ */new Map;for(const u of this.pending)if(u)try{const e="object"==typeof u?t.stringify(u):String(u);o.has(e)||o.set(e,u)}catch(h){o.set(Math.random().toString(),u)}const s=Array.from(o.values()),i="json"===a?.responseFormat?'\nCRITICAL OUTPUT FORMAT REQUIREMENTS:\n\n1. Your response MUST be ONLY valid JSON - no markdown, no explanations, no prose.\n2. Do NOT wrap the JSON in code blocks (```json or ```).\n3. Do NOT include any text before or after the JSON object.\n4. The response must start with { or [ and end with } or ].\n5. All strings must be properly escaped (newlines as \\n, quotes as \\").\n6. Use null for missing/unknown values, not undefined or empty strings.\n7. Numbers should be unquoted. Booleans should be true/false (lowercase).\n8. Arrays should not have trailing commas.\n9. The JSON must be parseable by JSON.parse() without modification.\n\nIf you cannot provide the requested data, return: {"error": "description of the issue", "ok": false}\n':void 0,c={model:this.model,tools:Array.from(this?.tools?.values?.()||[])?.filter?.(e=>!!e),input:s,reasoning:{effort:e},text:{verbosity:n},max_output_tokens:a?.maxTokens||4e5,previous_response_id:this.responseId=r||this?.responseId,instructions:i};void 0!==a?.temperature&&(c.temperature=a.temperature);const{timeout:l,maxRetries:d}=function(e){try{const t=globalThis.runtimeSettings?.ai||require("../../config/RuntimeSettings").getRuntimeSettings?.()?.ai||require("../../config/Settings").loadSettings?.()?.ai,n=t?.requestTimeout,r=t?.maxRetries??2;return{timeout:1e3*(n?.[e]??u[e]),maxRetries:r}}catch{return{timeout:u[e],maxRetries:2}}}(e);console.log("[GPT] Making request to:",`${this?.apiUrl}/responses`),console.log("[GPT] API key present:",!!this?.apiKey),console.log("[GPT] Request timeout:",`${l}ms (${e} effort)`),console.log("[GPT] Max retries:",d),console.log("[GPT] Request body size:",JSON.stringify(c).length,"characters");let p=null;for(let t=0;t<=d;t++){t>0&&(console.log(`[GPT] Retry attempt ${t}/${d} after 2000ms delay`),await new Promise(e=>setTimeout(e,2e3)));try{const e=new AbortController,n=setTimeout(()=>{console.warn(`[GPT] Request timeout after ${l}ms (attempt ${t+1})`),e.abort()},l),r=await fetch(`${this?.apiUrl}/responses`,{method:"POST",priority:"auto",signal:e.signal,headers:{"Content-Type":"application/json",...this?.apiKey?{Authorization:`Bearer ${this?.apiKey}`}:{}},body:JSON.stringify(c)});if(clearTimeout(n),console.log("[GPT] Response status:",r.status,`(attempt ${t+1})`),200!==r.status){const e=await(r?.json?.()?.catch?.(e=>(console.error("[GPT] Failed to parse error response:",e),null))),t=e?.error?.message||e?.message||`HTTP ${r.status}`;if(p=new Error(`API error (${r.status}): ${t}`),console.error("[GPT] API error:",t),r.status>=400&&r.status<500)throw p;continue}return await this.processSuccessfulResponse(r)}catch(h){if(p=h instanceof Error?h:new Error(String(h)),console.error(`[GPT] Request failed (attempt ${t+1}):`,p.message),"AbortError"===p.name||p.message.includes("HTTP 4"))break}}const m=p?p.message:"Unknown error after all retries";throw console.error("[GPT] All retry attempts failed:",m),new Error(`Request failed after ${d+1} attempts: ${m}`)}async processSuccessfulResponse(e){const n=await(e?.json?.()?.catch?.(e=>(console.warn("[GPT] Failed to parse successful response:",e),null)));if(!n)return null;this.responseMap.set(this.responseId=n?.id||n?.response_id||this.responseId,n),this?.messages?.push?.(...this?.pending||[]),this?.pending?.splice?.(0,this?.pending?.length),this.messages.push(...n?.output||[]);const r=(e=>{try{if(!e)return null;if("string"==typeof e)return e;if(e.output_text&&Array.isArray(e.output_text)&&e.output_text.length)return e.output_text.join("\n\n");const t=e.output||[],n=[];for(const e of t){const t=e?.content||[];if(t)for(const e of t)"string"==typeof e?.text?n.push(e.text):e?.text?.value&&n.push(e.text.value)}if(n.length)return n.join("\n\n")}catch(t){console.warn("[GPT] Error extracting text:",t)}return null})(n);if(null!=r)return r;try{return t.parse(n?.output??n)}catch{}return""}async modifyExistingData(t,n,r=[]){try{this.setContext({operation:"modify",existingData:t}),await this.giveForRequest('\nYou are a data modification assistant. Your task is to modify existing data based on the provided instructions.\n\nRules for modification:\n1. Preserve the original data structure unless explicitly asked to change it.\n2. Apply modifications in order, one by one.\n3. Validate data types match the schema.\n4. Return the complete modified entity, not just the changes.\n5. If a modification cannot be applied, include it in the "errors" array with explanation.\n\nCRITICAL: Output ONLY valid JSON. No markdown code blocks, no explanations, no prose.\nYour response must start with { and end with }.\n\nExpected output structure:\n{\n    "modified_entity": { /* complete modified entity */ },\n    "changes_made": [ /* list of applied changes */ ],\n    "errors": [ /* list of failed modifications with reasons */ ],\n    "warnings": [ /* non-critical issues */ ]\n}\n'),await this.giveForRequest(`existing_entity: \`${e(t)}\`\n`),r.length&&await this.giveForRequest((e=>{if(!e?.length)return"";const t=e.map((e,t)=>{const n=e.conditions?.length?` when ${e.conditions.map(e=>`${e.field} ${e.operator} ${JSON.stringify(e.value)}`).join(" AND ")}`:"";switch(e.action){case"update":return`${t+1}. UPDATE field "${e.target}" to ${JSON.stringify(e.value)}${n}`;case"delete":return`${t+1}. DELETE field "${e.target}"${n}`;case"merge":return`${t+1}. MERGE into "${e.target}" with ${JSON.stringify(e.value)}${n}`;case"append":return`${t+1}. APPEND ${JSON.stringify(e.value)} to "${e.target}"${n}`;case"replace":return`${t+1}. REPLACE "${e.target}" with ${JSON.stringify(e.value)}${n}`;case"transform":return`${t+1}. TRANSFORM "${e.target}" using: ${e.transformFn}${n}`;default:return""}}).filter(Boolean);return t.length?`\nModification instructions:\n${t.join("\n")}\n`:""})(r)),await this.askToDoAction(n);const a=await this.sendRequest("high","medium",null,{responseFormat:"json",temperature:.2}),o=d(a);return o.ok?{ok:!0,data:o.data?.modified_entity||o.data,responseId:this.responseId}:(console.warn("JSON extraction failed:",o.error,"Raw:",o.raw),{ok:!1,error:o.error||"Failed to parse AI response"})}catch(a){return console.error("Error in modifyExistingData:",a),{ok:!1,error:String(a)}}}async selectAndFilterData(t,n,r=[]){try{this.setContext({operation:"extract",filters:n,searchTerms:r}),await this.giveForRequest('\nYou are a data selection and filtering assistant. Your task is to find and select data matching the criteria.\n\nSelection rules:\n1. Apply all filters in order (AND logic by default).\n2. Rank results by relevance to search terms.\n3. Include confidence scores for fuzzy matches.\n4. Group similar results to avoid duplicates.\n\nCRITICAL: Output ONLY valid JSON. No markdown code blocks, no explanations, no prose.\nYour response must start with { and end with }.\n\nExpected output structure:\n{\n    "selected_items": [ /* items matching criteria */ ],\n    "total_matches": number,\n    "filter_stats": { /* breakdown by filter */ },\n    "suggestions": [ /* related items that might be relevant */ ]\n}\n'),await this.giveForRequest(`data_set: \`${e(t)}\`\n`);const a=n.map(e=>`Filter: ${e.field} ${e.operator} ${JSON.stringify(e.value)}`).join("\n");await this.askToDoAction(`\nSelect items from the provided data set matching these criteria:\n${a}\n${r.length?`\nSearch terms: ${r.join(", ")}`:""}\n\nReturn matching items with relevance scores.\n            `);const o=await this.sendRequest("medium","low",null,{responseFormat:"json",temperature:.1}),s=d(o);return s.ok?{ok:!0,data:s.data?.selected_items||s.data,responseId:this.responseId}:(console.warn("JSON extraction failed:",s.error,"Raw:",s.raw),{ok:!1,error:s.error||"Failed to parse AI response"})}catch(a){return console.error("Error in selectAndFilterData:",a),{ok:!1,error:String(a)}}}async mergeEntities(t,n,r="prefer_primary"){try{this.setContext({operation:"merge",existingData:t}),await this.giveForRequest('\nYou are an entity merging assistant. Your task is to intelligently merge multiple entities or data sources.\n\nMerge rules:\n1. Prefer newer/more complete data when conflicts arise.\n2. Combine arrays without duplicates.\n3. Merge nested objects recursively.\n4. Preserve IDs and relationships.\n5. Track the source of each merged field.\n\nCRITICAL: Output ONLY valid JSON. No markdown code blocks, no explanations, no prose.\nYour response must start with { and end with }.\n\nExpected output structure:\n{\n    "merged_entity": { /* result of merge */ },\n    "conflicts_resolved": [ /* list of conflicts and how they were resolved */ ],\n    "sources_used": [ /* which source contributed what */ ],\n    "merge_confidence": number\n}\n'),await this.giveForRequest(`primary_entity: \`${e(t)}\`\n`),await this.giveForRequest(`secondary_data: \`${e(n)}\`\n`),await this.askToDoAction(`\nMerge the secondary data into the primary entity using "${r}" strategy:\n- prefer_primary: Keep primary values when conflicts occur\n- prefer_secondary: Use secondary values when conflicts occur\n- prefer_newer: Compare timestamps and use newer values\n- merge_all: Combine all unique values (arrays concatenated, objects deeply merged)\n\nReturn the merged entity with conflict resolution details.\n            `);const a=await this.sendRequest("high","medium",null,{responseFormat:"json",temperature:.2}),o=d(a);return o.ok?{ok:!0,data:o.data?.merged_entity||o.data,responseId:this.responseId}:(console.warn("JSON extraction failed:",o.error,"Raw:",o.raw),{ok:!1,error:o.error||"Failed to parse AI response"})}catch(a){return console.error("Error in mergeEntities:",a),{ok:!1,error:String(a)}}}async searchSimilar(t,n,r=.7){try{this.setContext({operation:"analyze"}),await this.giveForRequest(`reference_entity: \`${e(t)}\`\n`),await this.giveForRequest(`candidate_set: \`${e(n)}\`\n`),await this.askToDoAction(`\nFind items in the candidate set that are similar to the reference entity.\nConsider semantic similarity, not just exact matches.\nCompare:\n- Names/titles (fuzzy match)\n- Types/kinds\n- Properties overlap\n- Relationships\n\nReturn items with similarity score >= ${r}\n\nExpected output structure:\n{\n    "similar_items": [\n        { "item": {...}, "similarity": 0.85, "match_reasons": [...] }\n    ],\n    "potential_duplicates": [...],\n    "related_but_different": [...]\n}\n            `);const a=await this.sendRequest("medium","medium",null,{responseFormat:"json",temperature:.3}),o=d(a);return o.ok?{ok:!0,data:o.data?.similar_items||[],responseId:this.responseId}:(console.warn("JSON extraction failed:",o.error,"Raw:",o.raw),{ok:!1,error:o.error||"Failed to parse AI response"})}catch(a){return console.error("Error in searchSimilar:",a),{ok:!1,error:String(a)}}}async batchProcess(t,n,r=10){const a=[],o=[];for(let s=0;s<t.length;s+=r){const i=t.slice(s,s+r);await this.giveForRequest(`batch_items: \`${e(i)}\`\n`),await this.askToDoAction(`\nProcess this batch of ${i.length} items:\n${n}\n\nReturn processed items in same order.\nExpected output: { "processed": [...], "failed": [...] }\n            `);const c=await this.sendRequest("medium","low",null,{responseFormat:"json"});if(c){const e=d(c);e.ok&&e.data?(a.push(...e.data?.processed||[]),e.data?.failed?.length&&o.push(...e.data.failed.map(e=>e?.error||"Unknown error"))):console.warn("Batch parsing failed:",e.error)}}return{ok:0===o.length,data:a,error:o.length?o.join("; "):void 0,responseId:this.responseId}}clearPending(){return this.pending.splice(0,this.pending.length),this}getResponseId(){return this?.responseId}getMessages(){return this?.messages}getPending(){return this?.pending}getContext(){return this?.context}getResponse(e){return this?.responseMap?.get?.(e)}}const h=(e,t,n)=>new m(e,t||"https://api.proxyapi.ru/openai/v1","",n||"gpt-5.2"),f=/*#__PURE__*/Object.freeze(/*#__PURE__*/Object.defineProperty({__proto__:null,DEFAULT_MAX_RETRIES:2,DEFAULT_REQUEST_TIMEOUTS:u,GPTResponses:m,RETRY_DELAY:2e3,createGPTInstance:h,getUsableData:p},Symbol.toStringTag,{value:"Module"}));export{f as G,h as c,d as e,p as g};