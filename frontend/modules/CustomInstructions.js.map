{"version":3,"mappings":";;;AAgBA,MAAM,UAAU,CAAC,aAAW;AACxB,MAAI,oBAAoB,OAAO,oBAAoB,KAAK;AACpD,eAAW,MAAM,KAAK,UAAU,UAAU;AAAA,EAC9C;AACA,SAAO;AACX;AAGA,MAAM,GAAG;AAAA,EACL;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA,WAAgB;AAAA,EAChB,YAAiB;AAAA,EACjB,WAA0B,EAAC;AAAA,EAC3B,QAAQ,SAAS,cAAc,EAAE;AAAA;AAAA,EAGjC,eAA4B;AAAA;AAAA,EAG5B,YAAY,cAA2B,MAAM;AACzC,QAAI,aAAa;AACb,WAAK,aAAY;AAAG,WAAK,YAAY;AAAM,WAAK,WAAW;AAC3D,WAAK,aAAa,YAAY,aAAa,KAAK,OAAO,KAAK,IAAI,GAAG,MAAM,QAAQ,KAAK,WAAW,CAAC;AAClG,WAAK,cAAc,WAAW,KAAK,aAAa,KAAK,UAAU,KAAK,IAAI,CAAC;AAAA,IAC7E;AAAA,EACJ;AAAA;AAAA,EAGA,IAAI,cAAc;AACd,WAAO,KAAK;AAAA,EAChB;AAAA,EACA,IAAI,YAAY,OAAoB;AAChC,QAAI,iBAAiB,eAAeA,eAAA,CAAc,KAAK,KAAK,SAAS,KAAK,cAAc;AACpF,WAAK,eAAe;AAAO,WAAK,YAAY,KAAK;AAAG,MAAgB,KAAK;AAAA,IAE7E;AAAA,EACJ;AAAA;AAAA,EAGA,YAAY,YAAY,QAAa,CAAC,OAAO,IAAI;AAAA;AAAA,IAA6I;AAAA,KAAM;AAEhM,QAAI,aAAa,KAAK,OAAO,OAAO,cAAc,cAAc,OAAO,cAAc,aAAa,CAAC,aAAa,UAAU,IAAI;AAC1H,OAAC,YAAY,KAAK,IAAI,CAAC,OAAO,UAAU;AAAA,IAC5C;AAGA,QAAI,CAAC,YAAY,SAAS,QAAQ,OAAO,SAAS,aAAa,CAAC,aAAa,KAAK,GAAG;AACjF,gBAAU;AAAA,IACd;AAGA,SAAK,QAAQ,SAAS,cAAc,EAAE;AACtC,SAAK,6BAAa,SAAQ;AAC1B,SAAK,6BAAa,KAAc;AAChC,SAAK,UAAU,SAAS,OAAQ,OAAO,SAAS,aAAa,QAAS,OAAO,SAAS,WAAW,OAAO,SAAS,OAAS,UAAU,CAAC,OAAO;AAC5I,SAAK,eAAe,aAAa,UAAU,IAAI,aAAc,YAAY,YAAY,OAAO,YAAY,eAAgB,EAAC;AACzH,SAAK,aAAa,SAAS,wBAAuB;AAGlD,UAAM,eAAe,EAAE,kCAAkC,MAAM,kBAAkB,MAAM,QAAQ,MAAK;AACpG,UAAM,eAAeA,eAAA,CAAc,OAAc,IAAI,OAAQ,YAAmC,EAAC;AACjG,SAAK,WAAW,OAAO,OAAO,cAAc,WAAW;AAGvD,SAAK,cAAcA,gBAAc,KAAK,UAAU,WAAkB,MAAMA,eAAA,CAAc,OAAc,KAAK;AACzG,QAAI,CAAC,KAAK,aAAa;AACnB,UAAI,KAAK,SAAS,QAAQ;AACtB;AAAA,UACI,KAAK;AAAA,UAAY,KAAK;AAAA,UACtB,KAAK,OAAO,KAAK,IAAI;AAAA,SACzB;AACA,YAAI,KAAK,WAAW,WAAW,WAAW,GAAG;AACzC,eAAK,WAAW,YAAY,KAAK,KAAK;AAAA,QAC1C;AAAA,MACJ;AAAA,IACJ;AAAA,EACJ;AAAA;AAAA,EAGA,KAAK,OAAO,IAAI;AAAE,WAAO;AAAA,EAAM;AAAA;AAAA,EAG/B,0BAA0B,WAAgB;AACtC,YAAQ,IAAI,MAAM;AACd,YAAM,UAAU,QAAQ,KAAK,cAAc,CAAC,GAAG,KAAK,OAAO,KAAK,IAAI,GAAG,CAAC;AACxE,UAAI,CAAC,WAAW,CAAC,aAAa,SAAS,WAAW,SAAS,KAAK,aAAa,SAAS;AAClF;AAAA,MACJ;AACA,UAAI,qBAAqB,eAAeA,eAAA,CAAc,SAAS,GAAG;AAC9D,YAAI,MAAM,KAAK,WAAW,QAAQ,EAAE,KAAK,CAAC,SAAS,SAAS,OAAO,GAAG;AAClE,eAAK,cAAc;AAAA,QACvB,OAAO;AACH,gBAAM,WAAW,IAAI,iBAAiB,CAAC,YAAY;AAC/C,uBAAW,UAAU,SAAS;AAC1B,kBAAI,OAAO,SAAS,aAAa;AAC7B,oBAAI,OAAO,WAAW,SAAS,GAAG;AAC9B,wBAAM,gBAAgB,MAAM,KAAM,OAAO,cAAsB,EAAE,EAAE,KAAK,CAAC,SAAS,SAAS,OAAO;AAClG,sBAAI,eAAe;AACf,yBAAK,cAAc;AACnB,6BAAS,YAAW;AAAA,kBACxB;AAAA,gBACJ;AAAA,cACJ;AAAA,YACJ;AAAA,UACJ,CAAC;AACD,mBAAS,QAAQ,WAAW,EAAE,WAAW,MAAM;AAAA,QACnD;AAAA,MACJ;AAAA,IACJ,CAAC,GAAG,QAAQ,QAAQ,KAAK,KAAK,OAAO,CAAC;AAGtC,WAAO,KAAK;AAAA,EAChB;AAAA;AAAA,EAGA,IAAI,WAAW;AAAE,WAAO,QAAQ,KAAK,WAAW;AAAA,EAAG;AAAA;AAAA,EAGnD,IAAI,OAAqD;AACrD,UAAM,aAAa,QAAQ,KAAK,cAAc,CAAC,GAAG,KAAK,OAAO,KAAK,IAAI,GAAG,CAAC;AAC3E,UAAM,cAAcA,eAAA,CAAc,YAAY,aAAa,IAAI,YAAY,gBAAgB,KAAK;AAChG,SAAK,gBAAgBA,eAAA,CAAc,WAAW,KAAK,KAAK;AAGxD,mBAAe,MAAM;AACjB,YAAMC,eAAcD,eAAA,CAAc,YAAY,aAAa,IAAI,YAAY,gBAAgB,KAAK;AAChG,WAAK,gBAAgBA,eAAA,CAAcC,YAAW,KAAK,KAAK;AAAA,IAC5D,CAAC;AAGD,WAAQ,eAAe,KAAK,eAAgB;AAAA,MACxC,KAAK;AAAA,MAAY,KAAK;AAAA,MACtB,KAAK,OAAO,KAAK,IAAI;AAAA,KACzB;AAAA,EACJ;AAAA;AAAA,EAGA,IAAI,UAAwD;AACxD,UAAM,WAAW,KAAK,YAAY,YAAY,SAAS,IAAI,KAAK,aAAa,QAAQ,KAAK,cAAc,CAAC,GAAG,KAAK,OAAO,KAAK,IAAI,GAAG,CAAC;AACrI,UAAM,cAAcD,eAAA,CAAc,UAAU,aAAa,IAAI,UAAU,gBAAgB,KAAK;AAC5F,SAAK,gBAAgBA,eAAA,CAAc,WAAW,KAAK,KAAK;AAGxD,mBAAe,MAAM;AACjB,YAAMC,eAAcD,eAAA,CAAc,UAAU,aAAa,IAAI,UAAU,gBAAgB,KAAK;AAC5F,WAAK,gBAAgBA,eAAA,CAAcC,YAAW,KAAK,KAAK;AAAA,IAC5D,CAAC;AAGD,WAAO;AAAA,EACX;AAAA;AAAA,EAGA,IAAI,SAAS;AACT,WAAO,IAAI,SAAS;AAChB,UAAI,OAAO,CAAC,aAAa,MAAM;AAAE,eAAO,OAAO,CAAC;AAAA,MAAG;AAGnD,UAAI,OAAO,CAAC,aAAa,WAAW,OAAQ,OAAO,CAAC,GAAW,QAAQ,YAAY;AAAE,eAAO;AAAA,MAAM;AAGlG,WACK,OAAO,CAAC,KAAK,QAAQ,OAAO,CAAC,IAAI,MAAM,OAAO,OAAO,CAAC,KAAK,YAAY,CAAC,aAAa,OAAO,CAAC,CAAQ,QACrG,MAAM,QAAQ,KAAK,WAAW,KAAO,KAAK,uBAA+B,MAC5E;AAAE;AAAA,MAAQ;AAGZ,UAAI,OAAO,CAAC,KAAK,SAAS,OAAO,OAAO,CAAC,KAAK,YAAY,OAAO,OAAO,CAAC,KAAK,cAAc,OAAO,OAAO,CAAC,KAAK,WAC5G;AAAE,eAAO,KAAK,OAAO,YAAY,OAAO,CAAC,GAAG,KAAK,OAAO,GAAG,IAAI,CAAC;AAAA,MAAG;AAGvE,UAAI,OAAO,CAAC,KAAK,QAAQ,KAAK,uBAAuB,KACjD;AAAE,eAAO,KAAK,OAAO,YAAY,OAAO,CAAC,GAAG,KAAK,OAAO,GAAG,IAAI,CAAC;AAAA,MAAG;AAGvE,UAAI,OAAO,CAAC,KAAK,QAAQ,KAAK,uBAAuB,KAAK;AAEtD,YAAI,OAAO,OAAO,CAAC,KAAK,YAAY,OAAO,OAAO,CAAC,KAAK,cAAc,OAAO,OAAO,CAAC,KAAK,UACtF;AAAE,iBAAO,KAAK,OAAO,YAAY,OAAO,CAAC,GAAG,KAAK,OAAO,GAAG,IAAI,CAAC;AAAA,QAAG,WAEnE,OAAO,OAAO,CAAC,KAAK,YAAY,OAAO,OAAO,CAAC,KAAK,cAAc,OAAO,OAAO,CAAC,KAAK,UACtF;AAAE,iBAAO,KAAK,OAAO,YAAY,OAAO,CAAC,GAAG,KAAK,OAAO,GAAG,IAAI,CAAC;AAAA,QAAG,OACnE;AAAE,iBAAO,KAAK,OAAO,YAAY,OAAO,CAAC,GAAG,KAAK,OAAO,GAAG,IAAI,CAAC;AAAA,QAAG;AAAA,MAC3E;AAGA,UAAI,OAAO,CAAC,KAAK,MAAM;AACnB,YAAI,KAAK,UAAU,oBAAoB,YAAY,OAAO,CAAC,CAAC,GACxD;AAAE,iBAAO,KAAK,OAAO,YAAY,OAAO,CAAC,GAAG,KAAK,OAAO,GAAG,IAAI,CAAC;AAAA,QAAG,OACnE;AAAE,iBAAO,KAAK,OAAO,GAAG,IAAI;AAAA,QAAG;AAAA,MACvC;AAAA,IACJ;AAAA,EACJ;AAAA;AAAA,EAGA,UAAU,OAAO,KAAK,OAAO,KAAoB,IAAI;AAEjD,SAAK,MAAM,aAAa,MAAM,WAAW,YAAY,KAAK,KAAK,SAAS,SAAS,KAAK,UAAU,kBAC5F;AAAE,WAAK,OAAO,OAAO,KAAK;AAAA,IAAG;AAGjC,UAAM,WAAW,QAAQ,KAAK,WAAW;AAAG,UAAM,SAAS,MAAM,KAAK,KAAK,aAAa,QAAO,IAAK,EAAE;AACtG,QAAI,MAAM,QAAQ,QAAQ,MAAM,KAAK,UAAU,mCAAoC,gBAAgB,QAAQ,KAAK,YAAY,KAAK,IAAK,UAAU,UAAU,SAAS,GAC/J;AAAE,sBAAgB,KAAK,aAAa,UAAU,MAAM,CAAC,IAAI,UAAU,QAAQ,IAAI,KAAK,QAAQ,SAAS,KAAK,KAAK,OAAO,KAAK,WAAW,CAAC,KAAK,EAAE;AAAA,IAAG;AAGrJ,UAAM,UAAU,CAAC,YAAY,SAAS,WAAW;AAGjD,QAAI,OAAO,aAAa,SAAS;AAC7B,YAAMC,WAAU,QAAQ,OAAO,KAAK,QAAQ,OAAO,UAAU,GAAG,IAAI,MAAM,EAAE;AAC5E,UAAI,KAAK,MAAM,eAAe,KAAK,aAAa;AAC5C,YAAIA,YAAW,KAAK,eAAeA,SAAQ,eAAe,KAAK,aAAa;AACxE,eAAK,YAAY,aAAa,KAAK,OAAOA,QAAO;AAAA,QACrD,WAAW,KAAK,eAAe,CAAC,KAAK,YAAY,eAAc,EAAG;AAC9D,eAAK,YAAY,YAAY,KAAK,KAAK;AAAA,QAC3C;AAAA,MACJ;AAAA,IACJ;AAGA,UAAM,UAAU,QAAQ,OAAO,KAAK,QAAQ,OAAO,UAAU,GAAG,IAAI,MAAM,EAAE;AAC5E,UAAM,OAAO,MAAM,MAAO,SAAS,cAAc,KAAK,cAAsB,cAAc,EAAE,GAAG,UAAU,OAAO;AAChH,UAAM,OAAO,UAAU,UAAU,KAAK;AACtC,UAAM,UAAU,QAAQ,OAAO,KAAK,QAAQ,OAAO,UAAU,GAAG,IAAI,MAAO,OAAO,IAAI,MAAM,MAAO,KAAK,WAAW;AAGnH,UAAM,MAAM,KAAK;AAAA,MACb;AAAA,MAAS,OAAO,UAAU,GAAG,IAAI,MAAO,OAAO,IAAI,OAAO;AAAA,MAC1D;AAAA,MACA,OAAO,MAAM,QAAQ,KAAK,WAAW,IAAI,SAAS;AAAA,MAClD,KAAK;AAAA,KAAW;AAGpB,QAAI,CAAC,WAAW,KAAK,MAAM,aAAa;AAAE,WAAK,MAAM,QAAO;AAAA,IAAG;AAC/D,WAAO;AAAA,EACX;AAAA;AAAA,EAGA,EAAE,OAAO,QAAQ,IAAI;AACjB,QAAI,IAAE;AACN,QAAI,KAAK,aAAa;AAClB,eAAS,MAAM,KAAK,aAChB;AAAE,cAAM,KAAK,OAAO,IAAI,GAAG;AAAA,MAAG;AAAA,IACtC;AACA;AAAA,EACJ;AACJ;AAGO,MAAM,IAAI,CAAC,YAAY,OAAQ,cAA2C,SAAS;AACtF,SAAO,IAAI,GAAG,YAAY,OAAO,WAAW;AAChD;;AC9QO,SAAS,iBAAiB,MAAc,WAAW,GAAW;AACjE,MAAI,MAAM;AACV,WAAS,IAAI,GAAG,IAAI,KAAK,QAAQ,KAAK;AAClC,UAAM,KAAK,KAAK,CAAC;AACjB,QAAI,OAAO,KAAK,OAAO;AAAA,aACd,OAAO,KAAM,OAAO,WAAY,MAAM;AAAA,SAC1C;AAAA,EACT;AACA,SAAO;AACX;AAGO,SAAS,mBAAmB,MAAc,SAAiB,WAAW,GAAW;AACpF,MAAI,MAAM,GAAG,IAAI;AACjB,SAAO,IAAI,KAAK,UAAU,MAAM,SAAS;AACrC,UAAM,KAAK,KAAK,CAAC;AACjB,QAAI,OAAO,KAAK;AAAE,aAAO;AAAG;AAAA,IAAK,WACxB,OAAO,KAAM;AAAE,aAAO,WAAY,MAAM;AAAW;AAAA,IAAK,OAC5D;AAAA,EACT;AACA,SAAO,KAAK,MAAM,CAAC;AACvB;AAGO,SAAS,QAAQ,GAAmB;AACvC,MAAI,EAAE,SAAS,MAAM,GAAG,OAAO;AAC/B,MAAI,EAAE,SAAS,IAAI,GAAG,OAAO;AAC7B,SAAO;AACX;AAGO,SAAS,IAAI,GAAW,GAAmB;AAC9C,MAAI,KAAK,IAAI,CAAC;AAAG,MAAI,KAAK,IAAI,CAAC;AAC/B,SAAO,IAAI,GAAG,CAAC,IAAI,CAAC,GAAG,IAAI,CAAC;AAC5B,SAAO;AACX;AAGO,SAAS,iBACZ,MACA,EAAE,kBAAkB,MAAM,WAAW,GAAE,GAAI,EAAC,EACqB;AACjE,QAAM,QAAQ,KAAK,MAAM,YAAY;AACrC,QAAM,QAAQ,kBAAkB,IAAI;AAEpC,QAAM,UAAoB,EAAC;AAC3B,WAAS,IAAI,OAAO,IAAI,MAAM,QAAQ,KAAK;AACvC,UAAM,KAAK,MAAM,CAAC;AAClB,QAAI,GAAG,MAAK,KAAM,IAAI;AACtB,YAAQ,KAAK,iBAAiB,IAAI,QAAQ,CAAC;AAAA,EAC/C;AACA,MAAI,QAAQ,WAAW,GAAG,OAAO,EAAE,KAAK,GAAG,MAAM,GAAG,SAAS,MAAM,SAAS,MAAK;AAEjF,QAAM,MAAM,KAAK,IAAI,GAAG,OAAO;AAC/B,QAAM,UAAU,QAAQ,IAAI,OAAK,IAAI,GAAG,EAAE,OAAO,OAAK,IAAI,CAAC;AAC3D,MAAI,OAAO;AACX,aAAW,KAAK,SAAS,OAAO,OAAO,IAAI,MAAM,CAAC,IAAI;AAEtD,QAAM,UAAU,QAAQ,MAAM,OAAK,IAAI,MAAM,CAAC;AAC9C,QAAM,UAAU,QAAQ,MAAM,OAAK,IAAI,MAAM,CAAC;AAG9C,MAAI,SAAS,GAAG;AAEZ,WAAO,UAAU,IAAI,UAAU,IAAI;AAAA,EACvC,OAAO;AACH,QAAI,OAAO,MAAM,GAAG,OAAO;AAAA,aAClB,OAAO,MAAM,GAAG,OAAO;AAAA,SAC3B,OAAO;AAAA,EAChB;AAEA,SAAO,EAAE,KAAK,MAAM,SAAS,SAAQ;AACzC;AAGO,SAAS,mBACZ,MACA,MACA,OAAqC,SACrC,WAAW,GACL;AACN,MAAI,CAAC,QAAQ,QAAQ,GAAG,OAAO;AAC/B,QAAM,MAAM,iBAAiB,MAAM,QAAQ;AAC3C,MAAI,QAAQ,GAAG,OAAO;AACtB,MAAI;AACJ,MAAI,SAAS,WAAW,SAAS,KAAK,MAAM,MAAM,IAAI,IAAI;AAAA,WACjD,SAAS,QAAQ,SAAS,KAAK,KAAK,MAAM,IAAI,IAAI;AAAA,OACtD,SAAS,KAAK,MAAM,MAAM,IAAI,IAAI;AAEvC,QAAM,QAAQ,MAAM;AACpB,MAAI,QAAQ,GAAG;AAEX,WAAO,mBAAmB,MAAM,OAAO,QAAQ;AAAA,EACnD,WAAW,QAAQ,GAAG;AAElB,WAAO,IAAI,OAAO,CAAC,KAAK,IAAI;AAAA,EAChC;AACA,SAAO;AACX;AAGO,SAAS,4BACZ,MACA,EAAE,QAAQ,aAAkD,GAAI,EAAC,EAC3D;AACN,MAAI,CAAC,QAAQ,OAAO,SAAS,UAAU,OAAO;AAE9C,QAAM,2BAAW,IAAI;AAAA,IACjB;AAAA,IAAQ;AAAA,IAAQ;AAAA,IAAM;AAAA,IAAO;AAAA,IAAS;AAAA,IAAM;AAAA,IAAO;AAAA,IAAS;AAAA,IAAQ;AAAA,IACpE;AAAA,IAAS;AAAA,IAAU;AAAA,IAAS;AAAA,GAC/B;AAED,MAAI,MAAM;AACV,MAAI,IAAI;AACR,QAAM,IAAI,KAAK;AAEf,SAAO,IAAI,GAAG;AACV,UAAM,KAAK,KAAK,CAAC;AACjB,QAAI,OAAO,KAAK;AAAE,aAAO;AAAI;AAAK;AAAA,IAAU;AAG5C,QAAI,KAAK,WAAW,QAAQ,CAAC,GAAG;AAC5B,YAAM,MAAM,KAAK,QAAQ,OAAO,IAAI,CAAC;AACrC,UAAI,QAAQ,IAAI;AAAE,eAAO,KAAK,MAAM,CAAC;AAAG;AAAA,MAAO;AAC/C,aAAO,KAAK,MAAM,GAAG,MAAM,CAAC;AAC5B,UAAI,MAAM;AACV;AAAA,IACJ;AAEA,QAAI,KAAK,IAAI,CAAC,MAAM,OAAO,KAAK,IAAI,CAAC,MAAM,KAAK;AAC5C,YAAM,MAAM,KAAK,QAAQ,KAAK,IAAI,CAAC;AACnC,UAAI,QAAQ,IAAI;AAAE,eAAO,KAAK,MAAM,CAAC;AAAG;AAAA,MAAO;AAC/C,aAAO,KAAK,MAAM,GAAG,MAAM,CAAC;AAC5B,UAAI,MAAM;AACV;AAAA,IACJ;AAEA,QAAI,KAAK,IAAI,CAAC,MAAM,KAAK;AACrB,YAAM,MAAM,KAAK,QAAQ,KAAK,IAAI,CAAC;AACnC,UAAI,QAAQ,IAAI;AAAE,eAAO,KAAK,MAAM,CAAC;AAAG;AAAA,MAAO;AAC/C,aAAO,KAAK,MAAM,GAAG,MAAM,CAAC;AAC5B,UAAI,MAAM;AACV;AAAA,IACJ;AAGA,QAAI,IAAI,IAAI;AAEZ,WAAO,IAAI,KAAK,KAAK,KAAK,KAAK,CAAC,CAAC,GAAG;AACpC,UAAM,YAAY;AAClB,WAAO,IAAI,KAAK,gBAAgB,KAAK,KAAK,CAAC,CAAC,GAAG;AAC/C,UAAM,UAAU,KAAK,MAAM,WAAW,CAAC,EAAE,aAAY;AAErD,QAAI,IAAI;AACR,QAAI,QAA0B;AAC9B,WAAO,IAAI,GAAG;AACV,YAAM,IAAI,KAAK,CAAC;AAChB,UAAI,OAAO;AACP,YAAI,MAAM,OAAO,QAAQ;AACzB;AAAA,MACJ,OAAO;AACH,YAAI,MAAM,OAAO,MAAM,KAAK;AAAE,kBAAQ;AAAgB;AAAA,QAAK,WAClD,MAAM,KAAK;AAAE;AAAA,QAAO,OACxB;AAAE;AAAA,QAAK;AAAA,MAChB;AAAA,IACJ;AACA,QAAI,KAAK,GAAG;AAAE,aAAO,KAAK,MAAM,CAAC;AAAG;AAAA,IAAO;AAC3C,UAAM,SAAS,KAAK,MAAM,GAAG,IAAI,CAAC;AAElC,UAAM,kBACF,UAAU,SACT,UAAU,gBAAgB,YAAY,WACtC,UAAU,eAAe,KAAK,IAAI,OAAO;AAE9C,QAAI,CAAC,iBAAiB;AAClB,aAAO;AACP,UAAI,IAAI;AACR;AAAA,IACJ;AAGA,QAAI,MAAM;AACV,QAAI,IAAsB;AAC1B,QAAI,KAAK;AACT,aAAS,IAAI,GAAG,IAAI,OAAO,QAAQ,KAAK;AACpC,YAAM,IAAI,OAAO,CAAC;AAClB,UAAI,GAAG;AACH,eAAO;AACP,YAAI,MAAM,GAAG,IAAI;AACjB;AAAA,MACJ;AACA,UAAI,MAAM,OAAO,MAAM,KAAK;AAAE,YAAI;AAAgB,eAAO;AAAG,aAAK;AAAO;AAAA,MAAU;AAClF,UAAI,MAAM,QAAQ,MAAM,QAAQ,MAAM,OAAQ,MAAM,KAAK;AACrD,YAAI,CAAC,IAAI;AAAE,iBAAO;AAAK,eAAK;AAAA,QAAM;AAClC;AAAA,MACJ;AACA,aAAO;AACP,WAAK;AAAA,IACT;AAEA,UAAM,IAAI,QAAQ,iBAAiB,KAAK;AAExC,WAAO;AACP,QAAI,IAAI;AAAA,EACZ;AAEA,SAAO;AACX;AAGO,SAAS,gCACZ,MACA,EAAE,sBAAsB,MAAK,GAAI,EAAC,EAC5B;AACN,MAAI,CAAC,QAAQ,OAAO,SAAS,UAAU,OAAO;AAE9C,MAAI,CAAC,qBAAqB;AAEtB,WAAO,KAAK,QAAQ,UAAU,IAAI;AAAA,EACtC;AAGA,QAAM,OAAO;AAEb,MAAI,IAAI;AAKR,MAAI,EACC,QAAQ,wBAAwB,MAAM,IAAI,MAAM,EAChD,QAAQ,qBAAqB,MAAM,IAAI,GAAG,EAC1C,QAAQ,sBAAsB,IAAI,IAAI,MAAM;AAGjD,MAAI,EAAE,QAAQ,UAAU,IAAI;AAG5B,MAAI,EAAE,QAAQ,IAAI,OAAO,MAAM,GAAG,GAAG,GAAG;AAExC,SAAO;AACX;AAGO,SAAS,mCACZ,MACA;AAAA,EACI,kBAAkB;AAAA;AAAA,EAClB,kBAAkB;AAAA;AAAA,EAClB,WAAW;AAAA;AAAA,EACX,YAAY;AAAA;AAAA,EACZ,WAAW;AAAA;AACf,IAAI,EAAC,EACC;AACN,MAAI,CAAC,QAAQ,OAAO,SAAS,YAAY,KAAK,QAAQ,GAAG,MAAM,IAAI,OAAO;AAC1E,SAAO,MAAM,QAAO;AAGpB,QAAM,eAAyB,EAAC;AAChC,QAAM,gBAAgB,KAAK;AAAA,IACvB;AAAA,IACA,CAAC,MAAM;AACH,YAAM,IAAI,aAAa,KAAK,CAAC,IAAI;AACjC,aAAO,KAAS,CAAC;AAAA,IACrB;AAAA,GACJ;AAEA,QAAM,MAAM,QAAQ,aAAa;AACjC,QAAM,QAAQ,cAAc,MAAM,YAAY;AAC9C,QAAM,QAAQ,kBAAkB,IAAI;AAGpC,QAAM,EAAE,KAAK,MAAM,UAAS,GAAI,iBAAiB,eAAe,EAAE,iBAAiB,UAAU;AAG7F,MAAI,mBAAmB,MAAM,GAAG;AAC5B,aAAS,IAAI,OAAO,IAAI,MAAM,QAAQ,KAAK;AACvC,YAAM,KAAK,MAAM,CAAC;AAClB,UAAI,GAAG,MAAK,KAAM,IAAI;AACtB,YAAM,CAAC,IAAI,mBAAmB,IAAI,KAAK,QAAQ;AAAA,IACnD;AAAA,EACJ;AAGA,MAAI,OAAO,cAAc,SAAS,WAAW;AAC7C,MAAI,aAAa,UAAU,OAAO,GAAG;AACjC,aAAS,IAAI,OAAO,IAAI,MAAM,QAAQ,KAAK;AACvC,YAAM,KAAK,MAAM,CAAC;AAClB,UAAI,GAAG,MAAK,KAAM,IAAI;AACtB,YAAM,CAAC,IAAI,mBAAmB,IAAI,MAAM,UAAU,QAAQ;AAAA,IAC9D;AAAA,EACJ;AAGA,MAAI,UAAU,MAAM,KAAK,GAAG;AAG5B,YAAU,4BAA4B,SAAS,EAAE,OAAO,aAAa;AAGrE,YAAU,gCAAgC,OAAO;AAGjD,QAAM,UAAU,QAAQ,QAAQ,sBAAsB,CAAC,GAAG,MAAM,aAAa,CAAC,CAAC,CAAC;AAChF,SAAO,SAAS,QAAO;AAC3B;AAGO,SAAS,oBAAoB,iBAA2B,KAAe;AAC1E,QAAM,UAAU,MAAM,CAAC,KAAK;AAC5B,QAAM,MAAM,aAAa,QAAQ,OAAO;AAExC,MAAI,MAAM,GAAG;AACT,UAAM,OAAQ,KAAK,OAAO,EAAE,KAAK;AACjC,WAAO,0BAA0B,KAAK,IAAI,KAAK,CAAC,YAAY,KAAK,IAAI;AAAA,EACzE;AAGA,QAAM,SAAS,aAAa,MAAM,GAAG,MAAM,CAAC,EAAE,KAAK,EAAE;AACrD,MAAI,QAAQ,OAAO,WAAW,OAAO,WAAW;AAEhD,WAAS,IAAI,GAAG,IAAI,OAAO,QAAQ,KAAK;AACpC,UAAM,KAAK,OAAO,CAAC;AACnB,UAAM,OAAO,OAAO,IAAI,CAAC,KAAK;AAE9B,QAAI,CAAC,OAAO;AACR,UAAI,OAAO,KAAK;AAEZ,YAAI,eAAe,KAAK,IAAI,GAAG;AAC3B,kBAAQ;AAAM,qBAAW;AAAO,qBAAW;AAAA,QAC/C;AAAA,MACJ;AACA;AAAA,IACJ;AAEA,QAAI,CAAC,YAAY,CAAC,UAAU;AACxB,UAAI,OAAO,KAAK;AAAE,mBAAW;AAAM;AAAA,MAAU;AAC7C,UAAI,OAAO,KAAK;AAAE,mBAAW;AAAM;AAAA,MAAU;AAC7C,UAAI,OAAO,KAAK;AAAE,gBAAQ;AAAO;AAAA,MAAU;AAAA,IAC/C,WAAW,UAAU;AACjB,UAAI,OAAO,KAAK;AAAE,mBAAW;AAAO;AAAA,MAAU;AAAA,IAClD,WAAW,UAAU;AACjB,UAAI,OAAO,KAAK;AAAE,mBAAW;AAAO;AAAA,MAAU;AAAA,IAClD;AAAA,EACJ;AAEA,SAAO;AACX;;ACrVA,MAAM,uBAAO,IAAI,SAAQ,EAAG,WAAW,CAAC,QAAQ;AAAE,QAAM,QAAQ,IAAI,MAAM,oEAAoE;AAAG,MAAI,CAAC,OAAO,OAAO,EAAE,KAAK,KAAK,IAAI,MAAM,WAAW,MAAK;AAAG,QAAM,GAAG,MAAM,OAAO,IAAI,QAAQ,IAAI;AAAO,QAAM,YAAY,WAAW,SAAS,QAAQ,OAAO,GAAG,EAAE,MAAK,GAAI;AAAM,SAAO,EAAE,KAAK,IAAI,WAAU;AAAG;AAIlW,MAAM,aAAa,CAAC,UAAuC;AACvD,MAAI,OAAO,SAAS,YAAY,CAAC,OAAO,UAAU,OAAO;AACzD,QAAM,QAAQ,MAAM,MAAM,YAAY;AACtC,SAAO,QAAQ,SAAS,QAAQ,CAAC,KAAK,IAAI,IAAI;AAClD;AAGA,MAAM,iBAAiB,CAAC,IAAwB,KAAY,KAAY,WAAsC;AAC1G,MAAI,CAAC,IAAI,OAAO;AAChB,MAAI,MAAM,MAAM;AACZ,UAAM,aAAiC,EAAC;AACxC,UAAM,mBAAmB,CAAC,SAAgC;AACtD,YAAM,OAAO,MAAM,KAAK,IAAI,cAAc,EAAE,EAAE,KAAK,CAACC,UAAUA,MAAK,QAAQ,QAAQA,MAAK,OAAO,WAAW,IAAI,CAAE;AAChH,UAAI,MAAM;AACN,cAAM,OAAsB,CAAC,MAAM,WAAW,MAAM,KAAK,KAAK,EAAE;AAChE,mBAAW,KAAK,IAAI;AAAG,eAAO;AAAA,MAClC;AACA,aAAO,CAAC,MAAM,EAAE;AAAA,IACpB;AAGA,UAAM,oBAAoB,CAAC,WAAW,SAAS,aAAa,WAAW,QAAQ,SAAS,KAAK;AAC7F,sBAAkB,QAAQ,CAAC,SAAS,iBAAiB,IAAI,CAAC;AAG1D,UAAM,cAAc,CAAC,YAA+B,WAA+C;AAC/F,YAAM,UAA2B,EAAC;AAClC,iBAAW,QAAQ,MAAM,KAAK,IAAI,cAAc,EAAE,GAAG;AAEjD,cAAM,kBAA4B,MAAM,QAAQ,UAAU,IAAI,YAAY,OAAO,CAAC,QAAc,OAAK,EAAE,IAAK,cAAc;AAC1H,cAAM,UAAkB,MAAM,QAAQ,UAAU,IAAI,WAAW,KAAK,CAAC,UAAU,KAAK,MAAM,aAAa,KAAK,CAAC,IAAK,aAAa,KAAK,MAAM,aAAa,UAAU,IAAI,aAAa,OAAkB;AACpM,cAAM,oBAAoB,KAAK,KAAK,MAAK,EAAG,UAAU,QAAQ,EAAE;AAChE,cAAM,gBAAgB,KAAK,OAAO,WAAW,IAAI,KAAK,KAAK,OAAO,WAAW,GAAG;AAChF,cAAM,WAAW,WAAW,MAAM,KAAK;AACvC,cAAM,WAAqB,MAAM,QAAQ,MAAM,IAAI,QAAQ,OAAO,CAAC,QAAc,mBAAmB,aAAa,GAAG,CAAC,IAAK,UAAU;AAEpI,YAAI,kBAAmB,UAAU,MAAM,mBAAoB,UAAU,OAAO,YAAY,KAAK,CAAC,UAAU;AACpG,kBAAQ,KAAK,CAAC,mBAAmB,QAAQ,CAAC;AAAA,QAC9C;AAAA,MACJ;AACA,aAAO;AAAA,IACX;AAGA,UAAM,wBAAwB,CAAC,YAA+B,QAA2B,WAA8B,OAAO;AAC1H,YAAM,iCAAiB,KAAmB;AAC1C,iBAAW,QAAQ,MAAM,KAAK,IAAI,cAAc,EAAE,GAAG;AACjD,cAAM,kBAA4B,MAAM,QAAQ,UAAU,IAAI,YAAY,OAAO,CAAC,QAAc,OAAK,EAAE,IAAK,cAAc;AAC1H,cAAM,UAAkB,MAAM,QAAQ,UAAU,IAAI,WAAW,KAAK,CAAC,UAAU,KAAK,MAAM,aAAa,KAAK,CAAC,IAAK,aAAa,KAAK,MAAM,aAAa,UAAU,IAAI,aAAa,OAAkB;AACpM,cAAM,oBAAoB,KAAK,KAAK,MAAK,EAAG,UAAU,QAAQ,EAAE;AAChE,cAAM,gBAAgB,KAAK,OAAO,WAAW,IAAI,KAAK,KAAK,OAAO,WAAW,GAAG;AAChF,cAAM,WAAW,WAAW,MAAM,KAAK,KAAK;AAE5C,cAAM,WAAqB,MAAM,QAAQ,MAAM,IAAI,QAAQ,OAAO,CAAC,QAAc,mBAAmB,aAAa,GAAG,CAAC,IAAK,UAAU;AACpI,cAAM,cAAuB,MAAM,QAAQ,QAAQ,IAAI,UAAU,OAAO,CAAC,QAAc,KAAK,SAAS,GAAG,IAAK,KAAK,SAAS,aAAc,aAAa;AAEtJ,YAAI,kBAAoB,UAAU,MAAM,mBAAoB,UAAU,MAAO,eAAe,YAAY,KAAK,CAAC,UAAU;AACpH,gBAAM,MAAM,aAAa,KAAK,OAAO;AACrC,cAAI,CAAC,WAAW,IAAI,GAAG,GAAG;AACtB,uBAAW,IAAI,KAAK,EAAE;AAAA,UAC1B;AACA,qBAAW,IAAI,GAAG,GAAG,KAAK,QAAQ;AAAA,QACtC;AAAA,MACJ;AACA,aAAO,MAAM,KAAK,WAAW,SAAS;AAAA,IAC1C;AAGA,QAAI,oBAAqC,YAAY,CAAC,SAAS,EAAE,GAAG,CAAC,KAAK,CAAC;AAC3E,QAAI,oBAAqC,YAAY,CAAC,OAAO,GAAG,EAAE;AAClE,QAAI,YAA+B,sBAAsB,CAAC,OAAO,GAAG,GAAG,IAAI,EAAE;AAC7E,QAAI,aAAgC,sBAAsB,CAAC,MAAM,GAAG,EAAC,EAAG,CAAC,KAAK,CAAC;AAM/E,UAAM,WAAgB,OAAO,YAAY,YAAY,SAAS,CAAC,SAAS,KAAK,CAAC,KAAK,CAAC,GAAG,MAAM,CAAC,SAAS,CAAC,KAAK,CAAC,GAAG,MAAM,KAAK,CAAC,CAAC,KAAK,IAAI,CAAC,KAAK,EAAE;AAC/I,aAAS,aAAa,OAAO,YAAY,mBAAmB,SAAS,CAAC,SAAS,KAAK,CAAC,KAAK,CAAC,GAAG,MAAM,CAAC,SAAS,CAAC,KAAK,CAAC,GAAG,MAAM,KAAK,CAAC,CAAC,KAAK,IAAI,CAAC,KAAK,EAAE;AACtJ,aAAS,aAAa,OAAO,YAAY,mBAAmB,SAAS,CAAC,SAAS,KAAK,CAAC,KAAK,CAAC,GAAG,MAAM,CAAC,SAAS,CAAC,KAAK,CAAC,GAAG,MAAM,KAAK,CAAC,CAAC,KAAK,IAAI,CAAC,KAAK,EAAE;AACtJ,aAAS,KAAK,OAAO,YAAY,WAAW,SAAS,CAAC,SAAS,KAAK,CAAC,GAAG,OAAO,CAAC,QAAgB,OAAO,CAAC,CAAC,GAAG,MAAM,CAAC,SAAS,CAAC,KAAK,CAAC,GAAG,KAAK,CAAC,GAAG,MAAM,CAAC,QAAgB,MAAM,GAAG,CAAC,EAAE,OAAO,CAAC,MAAW,KAAK,IAAI,CAAC,CAAC,KAAK,EAAE;AAGvN,UAAM,WAAW,YAAY,OAAO,CAAC,SAAU,KAAK,CAAC,KAAK,SAAS,KAAK,CAAC,KAAK,CAAE,IAAI,CAAC;AACrF,QAAI,YAAY,QAAQ,YAAY,GAAG;AACnC,YAAM,MAAM,MAAM,QAAQ;AAC1B,UAAI,OAAO,OAAO,YAAY;AAAE,cAAM,EAAE;AAAA,MAAG,WAAW,OAAO,QAAQ,OAAO,OAAO,UAAU;AAAE,YAAI,QAAQ;AAAA,MAAI;AAAA,IACnH;AAGA,gBAAY,UAAU,CAAC,SAA6B;AAChD,YAAM,WAAkB,OAAO,CAAC,GAC1B,SAAS,CAAC,QAAgB,OAAO,QAAQ,OAAO,CAAC,GACjD,MAAM,CAAC,QAAgB,MAAM,GAAG,CAAC,GACjC,SAAS,CAAC,MAAW,KAAK,IAAI;AAGpC,gBAAU,UAAU,CAAC,QAAa;AAC9B,YAAI,OAAO,OAAO,YAAY;AAAE,gBAAM,EAAE;AAAA,QAAG,WAAW,OAAO,QAAQ,OAAO,OAAO,UAAU;AAAE,cAAI,QAAQ;AAAA,QAAI;AAAA,MACnH,CAAC;AAAA,IACL,CAAC;AAGD,UAAM,2CAA2C,CAACC,QAAyB;AACvE,UAAIA,OAAM,MAAM;AAGhB,YAAM,wBAAwB,CAAC,SAAiB;AAC5C,eAAO,mBAAmB,OAAO,CAAC,SAAS,KAAK,CAAC,KAAK,IAAI,KAAK,MAAM,aAAa,MAAM,KAAK,QAAQ;AAAA,MACzG;AAGA,iBAAW,QAAQ,MAAM,KAAKA,KAAI,cAAc,EAAE,GAAG;AACjD;AAAA;AAAA,UACK,KAAK,OAAO,WAAW,IAAI,KAAK,KAAK,OAAO,WAAW,GAAG,KAAK,sBAAsB,KAAK,IAAc;AAAA,UAGzG,KAAK,OAAO,aAAa,IAAI,KAAK,KAAK,OAAO,WAAW,GAAG;AAAA,UAG5D,KAAK,MAAM,WAAW,GAAG,KAAK,KAAK,MAAM,WAAW,MAAM,KAAK,KAAK,QAAQ;AAAA,UAC9E;AAAE,UAAAA,KAAI,kBAAkB,KAAK,IAAc;AAAA,QAAG;AAAA,MACpD;AAAC,IACL;AAGA,6CAAyC,EAAE;AAC3C,QAAI,CAAC,MAAM,MAAM,EAAE,GAAG;AAAE,YAAM,MAAM,IAAI,EAAE,IAAI,QAAQ,CAAC;AAAA,IAAG;AAAC,EAC/D;AACA,SAAO,MAAM,MAAM,EAAE,KAAK;AAC9B;AAGA,MAAM,gBAAgB,CAAC,YAAY,WAAW;AAC1C,QAAM,QAAe,EAAC;AACtB,WAAS,IAAI,GAAG,IAAI,SAAS,QAAQ,KAAK;AACtC,UAAM,MAAM,UAAU,CAAC;AACvB,UAAM,MAAM,SAAS,CAAC;AACtB,UAAM,KAAK,EAAE,GAAG,CAAC;AACjB,UAAM,KAAK,GAAG;AAAA,EAClB;AACA,MAAI,OAAO,UAAU,GAAG,OAAO,QAAQ,QAAQ,CAAC,GAAG,MAAM,CAAC;AAG1D,QAAM,WAAW,SAAS,wBAAuB;AACjD,WAAS,OAAO,GAAG,OAAO,SAAS,CAAC,OAAQ,MAAM,IAAK,GAAG,MAAM,CAAC,IAAI,MAAc,QAAQ,IAAI,MAAM,CAAC,CAAC,GAAG,SAAS,CAAC,OAAQ,MAAM,IAAK,CAAC;AACxI,SAAO;AACX;AAGO,SAAS,KAAK,YAAY,QAAQ;AACrC,MAAI,SAAS,KAAK,CAAC,GAAG,UAAU,aAAa,GAAG,KAAK,SAAS,KAAK,EAAE,GAAG,QAAO,EAAG,WAAW,GAAG,GAAG;AAC/F,WAAO,YAAY,EAAE,eAAe,MAAM,EAAE,SAAS,GAAG,MAAM;AAAA,EAClE;AACA,SAAO,cAAc,SAAS,GAAG,MAAM;AAC3C;AAGA,MAAM,gBAAgB,CAAC,WAAiB;AACpC,SAAQ,UAAU,QAAQ,kBAAkB,eAAe,EAAE,kBAAkB,oBAAqB,kBAAkB,mBAAmB,UAAU,SAAS;AAChK;AAGA,MAAM,cAAc,CAAC,QAAc,MAAY,OAAY;AACvD,MAAI,MAAM,MAAM;AAAE,OAAG,cAAc;AAAA,EAAQ;AAG3C,MAAI,UAAU,QAAQ,IAAI,MAAM,IAAI,MAAM;AAC1C,MAAI,UAAU,OAAO,GAAG;AACpB,QAAI,SAAS,cAAc,UAAU,CAAC,SAAS,WAAW,MAAM,KAAK,WAAW,MAAM;AAClF,MAAC,MAAc,cAAe,SAAS,OAAO,MAAM,OAAO,SAAS,SAAS,YAAY,OAAO,SAAS,SAAS,eAAe,UAAU,SAAS,KAAK,IAAK,SAAS,QAAQ,OAAO;AAAA,IAC1L;AAAA,EACJ,OACA;AAAE,IAAC,MAAc,UAAS;AAAA,EAAG;AACjC;AAGO,SAAS,YAAY,EAAE,gBAAgB,MAAK,GAAI,EAAC,EAAG;AACvD,SAAO,SAAU,YAAY,QAAQ;AACjC,QAAI,QAAkB,EAAC;AACvB,UAAM,MAAa,EAAC,EAAG,MAAa,EAAC;AACrC,aAAS,IAAI,GAAG,IAAI,QAAQ,QAAQ,KAAK;AACrC,YAAM,KAAK,UAAU,CAAC,KAAK,EAAE;AAC7B,UAAI,IAAI,OAAO,QAAQ;AACnB,YAAI,QAAQ,CAAC,GAAG,MAAK,EAAG,WAAW,GAAG,GAAG;AACrC,gBAAM,MAAM,SAAS,SAAS,CAAC,CAAC;AAChC,gBAAM,KAAM,IAAI,OAAO,KAAM;AAC7B,cAAI,IAAI,IAAI,MAAM,KAAK,QAAQ,IAAI,EAAE,GAAG;AACxC,cAAI,IAAI,WAAW,MAAM,KAAK,WAAW,IAAI,SAAS,GAAG;AAAA,QAC7D,OAAO;AAEH,gBAAM,aAAa,oBAAoB,SAAS,UAAU,CAAC,KAAK,IAAI,UAAU,IAAI,CAAC,KAAK,EAAE;AAC1F,gBAAM,eAAe,sBAAsB,KAAK,QAAQ,CAAC,GAAG,QAAO,IAAK,EAAE,KAAK,QAAQ,CAAC,GAAG,QAAO,EAAG,WAAW,GAAG;AAGnH,gBAAM,gBAAgB,QAAQ,CAAC,GAAG,QAAO,EAAG,QAAQ,OAAO;AAC3D,gBAAM,cAAc,QAAQ,IAAI,CAAC,GAAG,QAAO,EAAG,QAAQ,OAAO,KAAK;AAGlE,gBAAM,iBAAkB,iBAAiB;AACzC,gBAAM,oBAAoB;AAG1B,gBAAM,UAAU,qBAAqB,mBAAmB;AACxD,cAAI,QAAQ;AACR,kBAAM,oBAAqB,qBAAqB,CAAE;AAClD,kBAAM,MAAM,IAAI;AAChB,kBAAM,MAAM,OAAO,SAAS,CAAC,KAAK,WAAW,SAAS,CAAC,GAAG,QAAO,IAAK,KAAK,SAAS,CAAC,KAAK,QAAU,oBAAoB,MAAM,GAAG,OAAO,KAAK,GAAG,MAAQ,EAAE;AAC1J,gBAAI,KAAK,SAAS,CAAC,CAAC;AAAA,UACxB,WACI,CAAC,YAAY;AACb,kBAAM,MAAM,IAAI;AAChB,kBAAM,MAAM,OAAO,SAAS,CAAC,KAAK,WAAW,SAAS,CAAC,GAAG,QAAO,IAAK,KAAK,SAAS,CAAC,KAAK,QAAS,YAAY,SAAS,CAAC,CAAC,IAAI,OAAO,SAAS,CAAC,CAAC,GAAG,QAAO,GAAI,SAAS,GAAG,QAAS,EAAE;AACrL,gBAAI,KAAK,SAAS,CAAC,CAAC;AAAA,UACxB;AAAA,QACJ;AAAA,MACJ;AAAA,IACJ;AAGA,UAAM,aAAa,mCAAmC,MAAM,KAAK,EAAE,EAAE,MAAM;AAC3E,UAA8B,SAAS,IAAI,WAAU,EAAG,MAAW,OAAO,gBAAgB,YAAY,WAAW;AAGjH,UAAM,aAAa,eAAe,uBAAuB,KAAK,UAAU,UAAU;AAClF,UAAM,WAAgB,aAAa,MAAM,IAAI,cAAc,UAAU,IAAI,YAAY,IAAI,QAAQ;AAGjG,UAAM,OAAO,SAAS,wBAAuB;AAC7C,UAAM,SAAS,MAAM,KAAK,QAAQ,UAAU,GAAG,OAAO,CAAC,MAAW;AAAE,aAAO,aAAa;AAAA,IAAM,CAAC,EAAE,IAAI,CAAC,SAAc;AAChH,UAAI,CAAC,cAAc,MAAM,UAAU,KAAK,MAAM,cAAc,MAAM;AAC9D,cAAM,UAAS;AACf,YAAI,QAAQ,MAAM;AAAE,gBAAM,SAAS,IAAI;AAAA,QAAG;AAAC,MAC/C;AACA,aAAO;AAAA,IACX,CAAC;AAGD,QAAI,cAAqB,EAAC;AAG1B,WAAO,QAAQ,CAAC,YAAiB;AAC7B,YAAM,SAAc,UAAU,SAAS,iBAAiB,SAAS,WAAW,UAAU,IAAI,IAAI;AAC9F,SAAG;AACC,cAAM,OAAY,QAAQ;AAC1B,oBAAY,KAAK,IAAI;AAAA,MACzB,SAAS,QAAQ,YAAW;AAAA,IAChC,CAAC;AAGD,iBAAa,SAAS,CAAC,SAAc,MAAM,YAAY,KAAK,YAAY,GAAG,UAAU,CAAC,SAAc;AAChG,UAAI,MAAM,WAAW,UAAU,WAAW,IAAI,KAAK,OAAO,UAAU,SAAS,MAAM,WAAW,QAAO,EAAG,QAAQ,CAAC,KAAK,IAAI,CAAC,GAAG;AAC1H,YAAI,KAAU,MAAM,SAAS,MAAM,WAAW,QAAO,EAAG,QAAQ,CAAC,KAAK,IAAI,KAAK,EAAE;AAGjF,YAAI,MAAM,QAAQ,OAAO,WAAc,OAAO,MAAM,WAAW,KAAK,OAAO,QAAO,IAAK,IAAI;AACvF,gBAAM,UAAS;AAAA,QACnB,OAAO;AACH,gBAAM,UAAU,MAAM;AACtB,cAAI,MAAM,QAAQ,EAAE,KAAK,cAAc,OAAO,cAAc,KAAK;AAC7D,0BAAc,SAAS,MAAM,KAAK,EAAE,IAAI,MAAM,OAAO,CAAC;AAAA,UAC1D,WACI,MAAM,MAAM;AACZ,0BAAc,SAAS,MAAM,EAAE;AAAA,UACnC;AAAA,QACJ;AAAA,MACJ;AAGA,UAAI,MAAM,aAAa;AACnB,cAAM,UAAS;AAAA,MACnB;AAAA,IACJ,CAAC;AAGD,iBAAa,OAAO,CAAC,SAAc,KAAK,YAAY,KAAK,YAAY,GAAG,MAAM,CAAC,SAAS;AACpF,qBAAe,MAAqB,GAAgB;AAAA,IACxD,CAAC;AAGD,WAAO,MAAM,KAAK,MAAM,UAAU,GAAG,SAAS,IAAI,OAAO,MAAM,aAAa,CAAC;AAAA,EACjF;AACJ;AAGO,MAAM,IAAI,CAAC,QAAa,WAAkB;AAE7C,MAAI,OAAO,OAAO,UAAU;AACxB,QAAI,KAAK,QAAO,EAAG,aAAa,GAAG,KAAK,KAAK,QAAO,EAAG,WAAW,GAAG,GAAG;AACpE,YAAM,SAAS,IAAI,WAAU,EAAG,MAAM,OAAO,gBAAgB,mCAAmC,KAAK,QAAQ,GAAG,WAAW;AAC3H,YAAM,QAAQ,IAAI,cAAc,UAAU,GAAG,WAAW,IAAI;AAE5D,UAAI,iBAAiB,iBAAiB;AAClC,cAAM,OAAO,SAAS,wBAAuB;AAC7C,aAAK,OAAO,GAAG,MAAM,KAAK,MAAM,cAAc,EAAE,CAAC;AACjD,eAAQ,MAAM,KAAK,KAAK,UAAU,GAAG,SAAS,IAAI,OAAO,MAAM,aAAa,CAAC;AAAA,MACjF;AACA,UAAI,iBAAiB,kBAAkB;AAAE,eAAO;AAAA,MAAO;AACvD,UAAI,OAAO,YAAY,SAAS,GAAG;AAAE,cAAM,OAAO,SAAS,wBAAuB;AAAG,aAAK,OAAO,GAAG,MAAM,KAAK,OAAO,cAAc,EAAE,CAAC;AAAG,eAAO;AAAA,MAAM;AACvJ,aAAO,OAAO,aAAa,CAAC,KAAM,IAAI,KAAK,GAAG;AAAA,IAClD;AACA,WAAO,IAAI,KAAK,GAAG;AAAA,EACvB,WACI,OAAO,OAAO,YAAY;AAAE,WAAO,EAAE,OAAO;AAAA,EAAG,WAC/C,MAAM,QAAQ,GAAG,KAAK,QAAQ;AAAE,WAAO,KAAK,KAAK,GAAG,MAAM;AAAA,EAAG,WAC7D,eAAe,MAAM;AAAE,WAAO;AAAA,EAAK;AACvC,SAAO,QAAQ,GAAG;AACtB;;ACzTA,IAAI,WAAoC;AAUjC,MAAM,qBAAqB,YAAkC;AAChE,MAAI;AACA,UAAM,QAAQ,MAAM,UAAS;AAC7B,WAAO,SAAS;AAAA,EACpB,QAAQ;AACJ,WAAO;AAAA,EACX;AACJ;;ACvBA;AACA,MAAM,gBAAgB,GAAG,GAAG;AAC5B,MAAM,gBAAgB,GAAG,IAAI;AAC7B,MAAM,KAAK,GAAG,GAAG;AAIjB,MAAM,GAAG,GAAG,GAAG;AAKf,MAAM,YAAY,GAAG,MAAM;AAC3B,MAAM,YAAY,GAAG,MAAM;AAC3B,MAAM,aAAa,GAAG,OAAO;AAC7B,MAAM,SAAS,GAAG,IAAI;AACtB,MAAM,YAAY,GAAG,IAAI;AAIzB,MAAM,UAAU,GAAG;AACnB,CAAC,KAAK,EAAE,KAGR,CAAC;AACD,MAAM,iBAAiB,GAAG,UAAU,CAAC,KAAK;;AAE1C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS,YAAY,CAAC,KAAK,EAAE;AAC7B,CAAC,OAAO,KAAK,CAAC,OAAO,CAAC,KAAK,EAAE,CAAC,EAAE,SAAS,CAAC,EAAE,SAAS,CAAC,CAAC,CAAC,CAAC,OAAO,CAAC,IAAI,EAAE,CAAC,EAAE,SAAS,CAAC,EAAE,YAAY,CAAC,CAAC,CAAC,CAAC,OAAO,CAAC,KAAK,EAAE,CAAC,EAAE,SAAS,CAAC,CAAC,CAAC,CAAC,CAAC,OAAO,CAAC,KAAK,EAAE,CAAC,EAAE,SAAS,CAAC,CAAC,CAAC,CAAC,CAAC,OAAO,CAAC,KAAK,EAAE,CAAC,EAAE,SAAS,CAAC,CAAC,CAAC,CAAC;AACrM;;AAmFA;AACA;AACA,SAAS,sBAAsB,CAAC,KAAK,EAAE;AACvC,CAAC,OAAO,KAAK,KAAK,YAAY,IAAI,KAAK,KAAK,aAAa,IAAI,KAAK,KAAK,YAAY;AACnF;;AAixBA;AACA;AACA,SAAS,cAAc,CAAC,KAAK,EAAE;AAC/B,CAAC,IAAI,KAAK,KAAK,IAAI,EAAE,OAAO,IAAI;AAChC,CAAC,IAAI,OAAO,KAAK,KAAK,QAAQ,IAAI,OAAO,KAAK,KAAK,SAAS,EAAE,OAAO,KAAK;AAC1E,CAAC,IAAI,OAAO,KAAK,KAAK,QAAQ,EAAE;AAChC,EAAE,IAAI,MAAM,CAAC,EAAE,CAAC,KAAK,EAAE,EAAE,CAAC,EAAE,OAAO,CAAC;AACpC,EAAE,IAAI,CAAC,MAAM,CAAC,QAAQ,CAAC,KAAK,CAAC,EAAE,OAAO,IAAI;AAC1C,EAAE,OAAO,KAAK;AACd,CAAC;AACD,CAAC,IAAI,OAAO,KAAK,KAAK,QAAQ,EAAE;AAChC,EAAE,IAAI,KAAK,IAAI,MAAM,CAAC,gBAAgB,IAAI,KAAK,IAAI,MAAM,CAAC,gBAAgB,EAAE,OAAO,MAAM,CAAC,KAAK,CAAC;AAChG,EAAE,OAAO,KAAK,CAAC,QAAQ,EAAE;AACzB,CAAC;AACD,CAAC,IAAI,KAAK,YAAY,IAAI,EAAE,OAAO,KAAK,CAAC,WAAW,EAAE;AACtD,CAAC,IAAI,KAAK,CAAC,OAAO,CAAC,KAAK,CAAC,EAAE,OAAO,KAAK,CAAC,GAAG,CAAC,cAAc,CAAC;AAC3D,CAAC,IAAI,KAAK,YAAY,GAAG,EAAE,OAAO,KAAK,CAAC,IAAI,CAAC,KAAK,CAAC,CAAC,GAAG,CAAC,cAAc,CAAC;AACvE,CAAC,IAAI,KAAK,YAAY,GAAG,EAAE,OAAO,MAAM,CAAC,WAAW,CAAC,KAAK,CAAC,IAAI,CAAC,KAAK,EAAE,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,KAAK,CAAC,MAAM,CAAC,CAAC,CAAC,EAAE,cAAc,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;AACnH,CAAC,IAAI,aAAa,CAAC,KAAK,CAAC,EAAE;AAC3B,EAAE,MAAM,UAAU,GAAG,EAAE;AACvB,EAAE,KAAK,MAAM,GAAG,IAAI,KAAK,EAAE,IAAI,MAAM,CAAC,SAAS,CAAC,cAAc,CAAC,IAAI,CAAC,KAAK,EAAE,GAAG,CAAC,EAAE,UAAU,CAAC,GAAG,CAAC,GAAG,cAAc,CAAC,KAAK,CAAC,GAAG,CAAC,CAAC;AAC7H,EAAE,OAAO,UAAU;AACnB,CAAC;AACD,CAAC,OAAO,IAAI;AACZ;AACA,SAAS,eAAe,CAAC,KAAK,EAAE;AAChC,CAAC,OAAO,KAAK,KAAK,IAAI,IAAI,OAAO,KAAK,KAAK,QAAQ,IAAI,OAAO,KAAK,KAAK,QAAQ,IAAI,OAAO,KAAK,KAAK,SAAS;AAC9G;AACA,SAAS,WAAW,CAAC,KAAK,EAAE;AAC5B,CAAC,OAAO,KAAK,CAAC,OAAO,CAAC,KAAK,CAAC;AAC5B;AACA,SAAS,YAAY,CAAC,KAAK,EAAE;AAC7B,CAAC,OAAO,KAAK,KAAK,IAAI,IAAI,OAAO,KAAK,KAAK,QAAQ,IAAI,CAAC,KAAK,CAAC,OAAO,CAAC,KAAK,CAAC;AAC5E;AACA,SAAS,aAAa,CAAC,KAAK,EAAE;AAC9B,CAAC,OAAO,MAAM,CAAC,IAAI,CAAC,KAAK,CAAC,CAAC,MAAM,KAAK,CAAC;AACvC;AACA,SAAS,aAAa,CAAC,KAAK,EAAE;AAC9B,CAAC,IAAI,KAAK,KAAK,IAAI,IAAI,OAAO,KAAK,KAAK,QAAQ,EAAE,OAAO,KAAK;AAC9D,CAAC,MAAM,SAAS,GAAG,MAAM,CAAC,cAAc,CAAC,KAAK,CAAC;AAC/C,CAAC,OAAO,SAAS,KAAK,IAAI,IAAI,SAAS,KAAK,MAAM,CAAC,SAAS;AAC5D;AACA,SAAS,mBAAmB,CAAC,KAAK,EAAE;AACpC,CAAC,OAAO,KAAK,CAAC,MAAM,KAAK,CAAC,IAAI,KAAK,CAAC,KAAK,CAAC,CAAC,IAAI,KAAK,eAAe,CAAC,IAAI,CAAC,CAAC;AAC1E;AACA,SAAS,eAAe,CAAC,KAAK,EAAE;AAChC,CAAC,OAAO,KAAK,CAAC,MAAM,KAAK,CAAC,IAAI,KAAK,CAAC,KAAK,CAAC,CAAC,IAAI,KAAK,WAAW,CAAC,IAAI,CAAC,CAAC;AACtE;AACA,SAAS,gBAAgB,CAAC,KAAK,EAAE;AACjC,CAAC,OAAO,KAAK,CAAC,MAAM,KAAK,CAAC,IAAI,KAAK,CAAC,KAAK,CAAC,CAAC,IAAI,KAAK,YAAY,CAAC,IAAI,CAAC,CAAC;AACvE;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS,kBAAkB,CAAC,GAAG,EAAE;AACjC,CAAC,OAAO,iBAAiB,CAAC,IAAI,CAAC,GAAG,CAAC;AACnC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS,mBAAmB,CAAC,GAAG,EAAE;AAClC,CAAC,OAAO,cAAc,CAAC,IAAI,CAAC,GAAG,CAAC;AAChC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS,cAAc,CAAC,KAAK,EAAE,SAAS,GAAG,iBAAiB,EAAE;AAC9D,CAAC,IAAI,CAAC,KAAK,EAAE,OAAO,KAAK;AACzB,CAAC,IAAI,KAAK,KAAK,KAAK,CAAC,IAAI,EAAE,EAAE,OAAO,KAAK;AACzC,CAAC,IAAI,sBAAsB,CAAC,KAAK,CAAC,IAAI,aAAa,CAAC,KAAK,CAAC,EAAE,OAAO,KAAK;AACxE,CAAC,IAAI,KAAK,CAAC,QAAQ,CAAC,GAAG,CAAC,EAAE,OAAO,KAAK;AACtC,CAAC,IAAI,KAAK,CAAC,QAAQ,CAAC,IAAI,CAAC,IAAI,KAAK,CAAC,QAAQ,CAAC,IAAI,CAAC,EAAE,OAAO,KAAK;AAC/D,CAAC,IAAI,SAAS,CAAC,IAAI,CAAC,KAAK,CAAC,EAAE,OAAO,KAAK;AACxC,CAAC,IAAI,UAAU,CAAC,IAAI,CAAC,KAAK,CAAC,EAAE,OAAO,KAAK;AACzC,CAAC,IAAI,KAAK,CAAC,QAAQ,CAAC,SAAS,CAAC,EAAE,OAAO,KAAK;AAC5C,CAAC,IAAI,KAAK,CAAC,UAAU,CAAC,gBAAgB,CAAC,EAAE,OAAO,KAAK;AACrD,CAAC,OAAO,IAAI;AACZ;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS,aAAa,CAAC,KAAK,EAAE;AAC9B,CAAC,OAAO,kCAAkC,CAAC,IAAI,CAAC,KAAK,CAAC,IAAI,QAAQ,CAAC,IAAI,CAAC,KAAK,CAAC;AAC9E;;AAiOA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS,eAAe,CAAC,GAAG,EAAE,KAAK,EAAE,QAAQ,EAAE,OAAO,EAAE,eAAe,EAAE,UAAU,EAAE,YAAY,EAAE;AACnG,CAAC,IAAI,OAAO,CAAC,UAAU,KAAK,MAAM,EAAE;AACpC,CAAC,IAAI,CAAC,YAAY,CAAC,KAAK,CAAC,EAAE;AAC3B,CAAC,MAAM,EAAE,QAAQ,EAAE,IAAI,EAAE,SAAS,EAAE,GAAG,qBAAqB,CAAC,GAAG,EAAE,KAAK,EAAE,YAAY,IAAI,OAAO,CAAC,YAAY,CAAC;AAC9G,CAAC,IAAI,QAAQ,CAAC,MAAM,GAAG,CAAC,EAAE;AAC1B,CAAC,IAAI,CAAC,QAAQ,CAAC,KAAK,CAAC,CAAC,GAAG,KAAK,mBAAmB,CAAC,GAAG,CAAC,CAAC,EAAE;AACzD,CAAC,MAAM,SAAS,GAAG,cAAc,CAAC,QAAQ,CAAC;AAC3C,CAAC,MAAM,YAAY,GAAG,UAAU,GAAG,CAAC,EAAE,UAAU,CAAC,EAAE,GAAG,CAAC,EAAE,SAAS,CAAC,CAAC,GAAG,SAAS;AAChF,CAAC,IAAI,QAAQ,CAAC,QAAQ,CAAC,SAAS,CAAC,EAAE;AACnC,CAAC,IAAI,eAAe,IAAI,eAAe,CAAC,GAAG,CAAC,YAAY,CAAC,EAAE;AAC3D,CAAC,OAAO;AACR,EAAE,SAAS;AACX,EAAE,SAAS,EAAE,IAAI;AACjB,EAAE,SAAS;AACX,EAAE,YAAY,EAAE,QAAQ,CAAC;AACzB,EAAE;AACF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS,qBAAqB,CAAC,QAAQ,EAAE,UAAU,EAAE,QAAQ,EAAE;AAC/D,CAAC,MAAM,QAAQ,GAAG,CAAC,QAAQ,CAAC;AAC5B,CAAC,IAAI,YAAY,GAAG,UAAU;AAC9B,CAAC,OAAO,QAAQ,CAAC,MAAM,GAAG,QAAQ,EAAE;AACpC,EAAE,IAAI,CAAC,YAAY,CAAC,YAAY,CAAC,EAAE;AACnC,EAAE,MAAM,IAAI,GAAG,MAAM,CAAC,IAAI,CAAC,YAAY,CAAC;AACxC,EAAE,IAAI,IAAI,CAAC,MAAM,KAAK,CAAC,EAAE;AACzB,EAAE,MAAM,OAAO,GAAG,IAAI,CAAC,CAAC,CAAC;AACzB,EAAE,MAAM,SAAS,GAAG,YAAY,CAAC,OAAO,CAAC;AACzC,EAAE,QAAQ,CAAC,IAAI,CAAC,OAAO,CAAC;AACxB,EAAE,YAAY,GAAG,SAAS;AAC1B,CAAC;AACD,CAAC,IAAI,CAAC,YAAY,CAAC,YAAY,CAAC,IAAI,aAAa,CAAC,YAAY,CAAC,EAAE,OAAO;AACxE,EAAE,QAAQ;AACV,EAAE,IAAI,EAAE,MAAM;AACd,EAAE,SAAS,EAAE;AACb,EAAE;AACF,CAAC,OAAO;AACR,EAAE,QAAQ;AACV,EAAE,IAAI,EAAE,YAAY;AACpB,EAAE,SAAS,EAAE;AACb,EAAE;AACF;AACA,SAAS,cAAc,CAAC,QAAQ,EAAE;AAClC,CAAC,OAAO,QAAQ,CAAC,IAAI,CAAC,GAAG,CAAC;AAC1B;;AAEA;AACA;AACA,SAAS,eAAe,CAAC,KAAK,EAAE,SAAS,EAAE;AAC3C,CAAC,IAAI,KAAK,KAAK,IAAI,EAAE,OAAO,YAAY;AACxC,CAAC,IAAI,OAAO,KAAK,KAAK,SAAS,EAAE,OAAO,MAAM,CAAC,KAAK,CAAC;AACrD,CAAC,IAAI,OAAO,KAAK,KAAK,QAAQ,EAAE,OAAO,MAAM,CAAC,KAAK,CAAC;AACpD,CAAC,OAAO,mBAAmB,CAAC,KAAK,EAAE,SAAS,CAAC;AAC7C;AACA,SAAS,mBAAmB,CAAC,KAAK,EAAE,SAAS,GAAG,iBAAiB,EAAE;AACnE,CAAC,IAAI,cAAc,CAAC,KAAK,EAAE,SAAS,CAAC,EAAE,OAAO,KAAK;AACnD,CAAC,OAAO,CAAC,EAAE,YAAY,CAAC,EAAE,YAAY,CAAC,KAAK,CAAC,CAAC,EAAE,YAAY,CAAC,CAAC;AAC9D;AACA,SAAS,SAAS,CAAC,GAAG,EAAE;AACxB,CAAC,IAAI,kBAAkB,CAAC,GAAG,CAAC,EAAE,OAAO,GAAG;AACxC,CAAC,OAAO,CAAC,EAAE,YAAY,CAAC,EAAE,YAAY,CAAC,GAAG,CAAC,CAAC,EAAE,YAAY,CAAC,CAAC;AAC5D;AACA,SAAS,uBAAuB,CAAC,MAAM,EAAE,SAAS,GAAG,iBAAiB,EAAE;AACxE,CAAC,OAAO,MAAM,CAAC,GAAG,CAAC,CAAC,CAAC,KAAK,eAAe,CAAC,CAAC,EAAE,SAAS,CAAC,CAAC,CAAC,IAAI,CAAC,SAAS,CAAC;AACxE;AACA,SAAS,YAAY,CAAC,MAAM,EAAE,OAAO,EAAE;AACvC,CAAC,MAAM,GAAG,GAAG,OAAO,EAAE,GAAG;AACzB,CAAC,MAAM,MAAM,GAAG,OAAO,EAAE,MAAM;AAC/B,CAAC,MAAM,SAAS,GAAG,OAAO,EAAE,SAAS,IAAI,KAAK;AAC9C,CAAC,IAAI,MAAM,GAAG,EAAE;AAChB,CAAC,IAAI,GAAG,EAAE,MAAM,IAAI,SAAS,CAAC,GAAG,CAAC;AAClC,CAAC,MAAM,IAAI,CAAC,CAAC,EAAE,MAAM,CAAC,EAAE,SAAS,KAAK,iBAAiB,GAAG,SAAS,GAAG,EAAE,CAAC,CAAC,CAAC;AAC3E,CAAC,IAAI,MAAM,EAAE;AACb,EAAE,MAAM,YAAY,GAAG,MAAM,CAAC,GAAG,CAAC,CAAC,CAAC,KAAK,SAAS,CAAC,CAAC,CAAC,CAAC;AACtD,EAAE,MAAM,IAAI,CAAC,CAAC,EAAE,YAAY,CAAC,IAAI,CAAC,SAAS,CAAC,CAAC,CAAC,CAAC;AAC/C,CAAC;AACD,CAAC,MAAM,IAAI,GAAG;AACd,CAAC,OAAO,MAAM;AACd;;AAEA;AACA;AACA,UAAU,eAAe,CAAC,KAAK,EAAE,OAAO,EAAE,KAAK,EAAE;AACjD,CAAC,IAAI,eAAe,CAAC,KAAK,CAAC,EAAE;AAC7B,EAAE,MAAM,gBAAgB,GAAG,eAAe,CAAC,KAAK,EAAE,OAAO,CAAC,SAAS,CAAC;AACpE,EAAE,IAAI,gBAAgB,KAAK,EAAE,EAAE,MAAM,gBAAgB;AACrD,EAAE;AACF,CAAC;AACD,CAAC,IAAI,WAAW,CAAC,KAAK,CAAC,EAAE,OAAO,gBAAgB,CAAC,MAAM,EAAE,KAAK,EAAE,KAAK,EAAE,OAAO,CAAC;AAC/E,MAAM,IAAI,YAAY,CAAC,KAAK,CAAC,EAAE,OAAO,iBAAiB,CAAC,KAAK,EAAE,KAAK,EAAE,OAAO,CAAC;AAC9E;AACA,UAAU,iBAAiB,CAAC,KAAK,EAAE,KAAK,EAAE,OAAO,EAAE,eAAe,EAAE,UAAU,EAAE,cAAc,EAAE;AAChG,CAAC,MAAM,IAAI,GAAG,MAAM,CAAC,IAAI,CAAC,KAAK,CAAC;AAChC,CAAC,IAAI,KAAK,KAAK,CAAC,IAAI,CAAC,eAAe,EAAE,eAAe,GAAG,IAAI,GAAG,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,QAAQ,CAAC,GAAG,CAAC,CAAC,CAAC;AACpG,CAAC,MAAM,qBAAqB,GAAG,cAAc,IAAI,OAAO,CAAC,YAAY;AACrE,CAAC,KAAK,MAAM,CAAC,GAAG,EAAE,GAAG,CAAC,IAAI,MAAM,CAAC,OAAO,CAAC,KAAK,CAAC,EAAE,OAAO,uBAAuB,CAAC,GAAG,EAAE,GAAG,EAAE,KAAK,EAAE,OAAO,EAAE,IAAI,EAAE,eAAe,EAAE,UAAU,EAAE,qBAAqB,CAAC;AACnK;AACA,UAAU,uBAAuB,CAAC,GAAG,EAAE,KAAK,EAAE,KAAK,EAAE,OAAO,EAAE,QAAQ,EAAE,eAAe,EAAE,UAAU,EAAE,YAAY,EAAE;AACnH,CAAC,MAAM,WAAW,GAAG,UAAU,GAAG,CAAC,EAAE,UAAU,CAAC,EAAE,GAAG,CAAC,EAAE,GAAG,CAAC,CAAC,GAAG,GAAG;AACnE,CAAC,MAAM,qBAAqB,GAAG,YAAY,IAAI,OAAO,CAAC,YAAY;AACnE,CAAC,IAAI,OAAO,CAAC,UAAU,KAAK,MAAM,IAAI,QAAQ,EAAE;AAChD,EAAE,MAAM,UAAU,GAAG,eAAe,CAAC,GAAG,EAAE,KAAK,EAAE,QAAQ,EAAE,OAAO,EAAE,eAAe,EAAE,UAAU,EAAE,qBAAqB,CAAC;AACvH,EAAE,IAAI,UAAU,EAAE;AAClB,GAAG,MAAM,EAAE,SAAS,EAAE,SAAS,EAAE,SAAS,EAAE,YAAY,EAAE,GAAG,UAAU;AACvE,GAAG,MAAM,gBAAgB,GAAG,SAAS,CAAC,SAAS,CAAC;AAChD,GAAG,IAAI,SAAS,KAAK,MAAM,EAAE;AAC7B,IAAI,IAAI,eAAe,CAAC,SAAS,CAAC,EAAE;AACpC,KAAK,MAAM,YAAY,CAAC,KAAK,EAAE,CAAC,EAAE,gBAAgB,CAAC,EAAE,EAAE,eAAe,CAAC,SAAS,EAAE,OAAO,CAAC,SAAS,CAAC,CAAC,CAAC,EAAE,OAAO,CAAC,MAAM,CAAC;AACvH,KAAK;AACL,IAAI,CAAC,MAAM,IAAI,WAAW,CAAC,SAAS,CAAC,EAAE;AACvC,KAAK,OAAO,gBAAgB,CAAC,SAAS,EAAE,SAAS,EAAE,KAAK,EAAE,OAAO,CAAC;AAClE,KAAK;AACL,IAAI,CAAC,MAAM,IAAI,YAAY,CAAC,SAAS,CAAC,IAAI,aAAa,CAAC,SAAS,CAAC,EAAE;AACpE,KAAK,MAAM,YAAY,CAAC,KAAK,EAAE,CAAC,EAAE,gBAAgB,CAAC,CAAC,CAAC,EAAE,OAAO,CAAC,MAAM,CAAC;AACtE,KAAK;AACL,IAAI;AACJ,GAAG;AACH,GAAG,IAAI,YAAY,CAAC,SAAS,CAAC,EAAE;AAChC,IAAI,MAAM,YAAY,CAAC,KAAK,EAAE,CAAC,EAAE,gBAAgB,CAAC,CAAC,CAAC,EAAE,OAAO,CAAC,MAAM,CAAC;AACrE,IAAI,MAAM,cAAc,GAAG,qBAAqB,GAAG,YAAY;AAC/D,IAAI,MAAM,UAAU,GAAG,UAAU,GAAG,CAAC,EAAE,UAAU,CAAC,EAAE,GAAG,CAAC,EAAE,SAAS,CAAC,CAAC,GAAG,SAAS;AACjF,IAAI,OAAO,iBAAiB,CAAC,SAAS,EAAE,KAAK,GAAG,CAAC,EAAE,OAAO,EAAE,eAAe,EAAE,UAAU,EAAE,cAAc,CAAC;AACxG,IAAI;AACJ,GAAG;AACH,EAAE;AACF,CAAC;AACD,CAAC,MAAM,UAAU,GAAG,SAAS,CAAC,GAAG,CAAC;AAClC,CAAC,IAAI,eAAe,CAAC,KAAK,CAAC,EAAE,MAAM,YAAY,CAAC,KAAK,EAAE,CAAC,EAAE,UAAU,CAAC,EAAE,EAAE,eAAe,CAAC,KAAK,EAAE,OAAO,CAAC,SAAS,CAAC,CAAC,CAAC,EAAE,OAAO,CAAC,MAAM,CAAC;AACrI,MAAM,IAAI,WAAW,CAAC,KAAK,CAAC,EAAE,OAAO,gBAAgB,CAAC,GAAG,EAAE,KAAK,EAAE,KAAK,EAAE,OAAO,CAAC;AACjF,MAAM,IAAI,YAAY,CAAC,KAAK,CAAC,EAAE;AAC/B,EAAE,MAAM,YAAY,CAAC,KAAK,EAAE,CAAC,EAAE,UAAU,CAAC,CAAC,CAAC,EAAE,OAAO,CAAC,MAAM,CAAC;AAC7D,EAAE,IAAI,CAAC,aAAa,CAAC,KAAK,CAAC,EAAE,OAAO,iBAAiB,CAAC,KAAK,EAAE,KAAK,GAAG,CAAC,EAAE,OAAO,EAAE,eAAe,EAAE,WAAW,EAAE,qBAAqB,CAAC;AACrI,CAAC;AACD;AACA,UAAU,gBAAgB,CAAC,GAAG,EAAE,KAAK,EAAE,KAAK,EAAE,OAAO,EAAE;AACvD,CAAC,IAAI,KAAK,CAAC,MAAM,KAAK,CAAC,EAAE;AACzB,EAAE,MAAM,YAAY,CAAC,KAAK,EAAE,YAAY,CAAC,CAAC,EAAE;AAC5C,GAAG,GAAG;AACN,GAAG,SAAS,EAAE,OAAO,CAAC;AACtB,GAAG,CAAC,EAAE,OAAO,CAAC,MAAM,CAAC;AACrB,EAAE;AACF,CAAC;AACD,CAAC,IAAI,mBAAmB,CAAC,KAAK,CAAC,EAAE;AACjC,EAAE,MAAM,YAAY,CAAC,KAAK,EAAE,qBAAqB,CAAC,KAAK,EAAE,OAAO,CAAC,SAAS,EAAE,GAAG,CAAC,EAAE,OAAO,CAAC,MAAM,CAAC;AACjG,EAAE;AACF,CAAC;AACD,CAAC,IAAI,eAAe,CAAC,KAAK,CAAC,EAAE;AAC7B,EAAE,IAAI,KAAK,CAAC,KAAK,CAAC,CAAC,GAAG,KAAK,mBAAmB,CAAC,GAAG,CAAC,CAAC,EAAE;AACtD,GAAG,OAAO,mCAAmC,CAAC,GAAG,EAAE,KAAK,EAAE,KAAK,EAAE,OAAO,CAAC;AACzE,GAAG;AACH,EAAE;AACF,CAAC;AACD,CAAC,IAAI,gBAAgB,CAAC,KAAK,CAAC,EAAE;AAC9B,EAAE,MAAM,MAAM,GAAG,oBAAoB,CAAC,KAAK,CAAC;AAC5C,EAAE,IAAI,MAAM,EAAE,OAAO,kCAAkC,CAAC,GAAG,EAAE,KAAK,EAAE,MAAM,EAAE,KAAK,EAAE,OAAO,CAAC;AAC3F,OAAO,OAAO,gCAAgC,CAAC,GAAG,EAAE,KAAK,EAAE,KAAK,EAAE,OAAO,CAAC;AAC1E,EAAE;AACF,CAAC;AACD,CAAC,OAAO,gCAAgC,CAAC,GAAG,EAAE,KAAK,EAAE,KAAK,EAAE,OAAO,CAAC;AACpE;AACA,UAAU,mCAAmC,CAAC,MAAM,EAAE,MAAM,EAAE,KAAK,EAAE,OAAO,EAAE;AAC9E,CAAC,MAAM,YAAY,CAAC,KAAK,EAAE,YAAY,CAAC,MAAM,CAAC,MAAM,EAAE;AACvD,EAAE,GAAG,EAAE,MAAM;AACb,EAAE,SAAS,EAAE,OAAO,CAAC;AACrB,EAAE,CAAC,EAAE,OAAO,CAAC,MAAM,CAAC;AACpB,CAAC,KAAK,MAAM,GAAG,IAAI,MAAM,EAAE,IAAI,mBAAmB,CAAC,GAAG,CAAC,EAAE;AACzD,EAAE,MAAM,SAAS,GAAG,qBAAqB,CAAC,GAAG,EAAE,OAAO,CAAC,SAAS,CAAC;AACjE,EAAE,MAAM,gBAAgB,CAAC,KAAK,GAAG,CAAC,EAAE,SAAS,EAAE,OAAO,CAAC,MAAM,CAAC;AAC9D,CAAC;AACD;AACA,SAAS,qBAAqB,CAAC,MAAM,EAAE,SAAS,EAAE,MAAM,EAAE;AAC1D,CAAC,MAAM,MAAM,GAAG,YAAY,CAAC,MAAM,CAAC,MAAM,EAAE;AAC5C,EAAE,GAAG,EAAE,MAAM;AACb,EAAE;AACF,EAAE,CAAC;AACH,CAAC,MAAM,WAAW,GAAG,uBAAuB,CAAC,MAAM,EAAE,SAAS,CAAC;AAC/D,CAAC,IAAI,MAAM,CAAC,MAAM,KAAK,CAAC,EAAE,OAAO,MAAM;AACvC,CAAC,OAAO,CAAC,EAAE,MAAM,CAAC,CAAC,EAAE,WAAW,CAAC,CAAC;AAClC;AACA,UAAU,kCAAkC,CAAC,MAAM,EAAE,IAAI,EAAE,MAAM,EAAE,KAAK,EAAE,OAAO,EAAE;AACnF,CAAC,MAAM,YAAY,CAAC,KAAK,EAAE,YAAY,CAAC,IAAI,CAAC,MAAM,EAAE;AACrD,EAAE,GAAG,EAAE,MAAM;AACb,EAAE,MAAM,EAAE,MAAM;AAChB,EAAE,SAAS,EAAE,OAAO,CAAC;AACrB,EAAE,CAAC,EAAE,OAAO,CAAC,MAAM,CAAC;AACpB,CAAC,OAAO,qBAAqB,CAAC,IAAI,EAAE,MAAM,EAAE,KAAK,GAAG,CAAC,EAAE,OAAO,CAAC;AAC/D;AACA,SAAS,oBAAoB,CAAC,IAAI,EAAE;AACpC,CAAC,IAAI,IAAI,CAAC,MAAM,KAAK,CAAC,EAAE;AACxB,CAAC,MAAM,QAAQ,GAAG,IAAI,CAAC,CAAC,CAAC;AACzB,CAAC,MAAM,SAAS,GAAG,MAAM,CAAC,IAAI,CAAC,QAAQ,CAAC;AACxC,CAAC,IAAI,SAAS,CAAC,MAAM,KAAK,CAAC,EAAE;AAC7B,CAAC,IAAI,cAAc,CAAC,IAAI,EAAE,SAAS,CAAC,EAAE,OAAO,SAAS;AACtD;AACA,SAAS,cAAc,CAAC,IAAI,EAAE,MAAM,EAAE;AACtC,CAAC,KAAK,MAAM,GAAG,IAAI,IAAI,EAAE;AACzB,EAAE,IAAI,MAAM,CAAC,IAAI,CAAC,GAAG,CAAC,CAAC,MAAM,KAAK,MAAM,CAAC,MAAM,EAAE,OAAO,KAAK;AAC7D,EAAE,KAAK,MAAM,GAAG,IAAI,MAAM,EAAE;AAC5B,GAAG,IAAI,EAAE,GAAG,IAAI,GAAG,CAAC,EAAE,OAAO,KAAK;AAClC,GAAG,IAAI,CAAC,eAAe,CAAC,GAAG,CAAC,GAAG,CAAC,CAAC,EAAE,OAAO,KAAK;AAC/C,EAAE;AACF,CAAC;AACD,CAAC,OAAO,IAAI;AACZ;AACA,UAAU,qBAAqB,CAAC,IAAI,EAAE,MAAM,EAAE,KAAK,EAAE,OAAO,EAAE;AAC9D,CAAC,KAAK,MAAM,GAAG,IAAI,IAAI,EAAE,MAAM,YAAY,CAAC,KAAK,EAAE,uBAAuB,CAAC,MAAM,CAAC,GAAG,CAAC,CAAC,GAAG,KAAK,GAAG,CAAC,GAAG,CAAC,CAAC,EAAE,OAAO,CAAC,SAAS,CAAC,EAAE,OAAO,CAAC,MAAM,CAAC;AAC7I;AACA,UAAU,gCAAgC,CAAC,MAAM,EAAE,KAAK,EAAE,KAAK,EAAE,OAAO,EAAE;AAC1E,CAAC,MAAM,YAAY,CAAC,KAAK,EAAE,YAAY,CAAC,KAAK,CAAC,MAAM,EAAE;AACtD,EAAE,GAAG,EAAE,MAAM;AACb,EAAE,SAAS,EAAE,OAAO,CAAC;AACrB,EAAE,CAAC,EAAE,OAAO,CAAC,MAAM,CAAC;AACpB,CAAC,KAAK,MAAM,IAAI,IAAI,KAAK,EAAE,OAAO,wBAAwB,CAAC,IAAI,EAAE,KAAK,GAAG,CAAC,EAAE,OAAO,CAAC;AACpF;AACA,UAAU,2BAA2B,CAAC,GAAG,EAAE,KAAK,EAAE,OAAO,EAAE;AAC3D,CAAC,IAAI,aAAa,CAAC,GAAG,CAAC,EAAE;AACzB,EAAE,MAAM,YAAY,CAAC,KAAK,EAAE,gBAAgB,EAAE,OAAO,CAAC,MAAM,CAAC;AAC7D,EAAE;AACF,CAAC;AACD,CAAC,MAAM,OAAO,GAAG,MAAM,CAAC,OAAO,CAAC,GAAG,CAAC;AACpC,CAAC,MAAM,CAAC,QAAQ,EAAE,UAAU,CAAC,GAAG,OAAO,CAAC,CAAC,CAAC;AAC1C,CAAC,MAAM,UAAU,GAAG,SAAS,CAAC,QAAQ,CAAC;AACvC,CAAC,IAAI,eAAe,CAAC,UAAU,CAAC,EAAE,MAAM,gBAAgB,CAAC,KAAK,EAAE,CAAC,EAAE,UAAU,CAAC,EAAE,EAAE,eAAe,CAAC,UAAU,EAAE,OAAO,CAAC,SAAS,CAAC,CAAC,CAAC,EAAE,OAAO,CAAC,MAAM,CAAC;AACnJ,MAAM,IAAI,WAAW,CAAC,UAAU,CAAC,EAAE,IAAI,mBAAmB,CAAC,UAAU,CAAC,EAAE,MAAM,gBAAgB,CAAC,KAAK,EAAE,qBAAqB,CAAC,UAAU,EAAE,OAAO,CAAC,SAAS,EAAE,QAAQ,CAAC,EAAE,OAAO,CAAC,MAAM,CAAC;AACrL,MAAM,IAAI,gBAAgB,CAAC,UAAU,CAAC,EAAE;AACxC,EAAE,MAAM,MAAM,GAAG,oBAAoB,CAAC,UAAU,CAAC;AACjD,EAAE,IAAI,MAAM,EAAE;AACd,GAAG,MAAM,gBAAgB,CAAC,KAAK,EAAE,YAAY,CAAC,UAAU,CAAC,MAAM,EAAE;AACjE,IAAI,GAAG,EAAE,QAAQ;AACjB,IAAI,MAAM,EAAE,MAAM;AAClB,IAAI,SAAS,EAAE,OAAO,CAAC;AACvB,IAAI,CAAC,EAAE,OAAO,CAAC,MAAM,CAAC;AACtB,GAAG,OAAO,qBAAqB,CAAC,UAAU,EAAE,MAAM,EAAE,KAAK,GAAG,CAAC,EAAE,OAAO,CAAC;AACvE,EAAE,CAAC,MAAM;AACT,GAAG,MAAM,gBAAgB,CAAC,KAAK,EAAE,CAAC,EAAE,UAAU,CAAC,CAAC,EAAE,UAAU,CAAC,MAAM,CAAC,EAAE,CAAC,EAAE,OAAO,CAAC,MAAM,CAAC;AACxF,GAAG,KAAK,MAAM,IAAI,IAAI,UAAU,EAAE,OAAO,2BAA2B,CAAC,IAAI,EAAE,KAAK,GAAG,CAAC,EAAE,OAAO,CAAC;AAC9F,EAAE;AACF,CAAC,CAAC,MAAM;AACR,EAAE,MAAM,gBAAgB,CAAC,KAAK,EAAE,CAAC,EAAE,UAAU,CAAC,CAAC,EAAE,UAAU,CAAC,MAAM,CAAC,EAAE,CAAC,EAAE,OAAO,CAAC,MAAM,CAAC;AACvF,EAAE,KAAK,MAAM,IAAI,IAAI,UAAU,EAAE,OAAO,wBAAwB,CAAC,IAAI,EAAE,KAAK,GAAG,CAAC,EAAE,OAAO,CAAC;AAC1F,CAAC;AACD,MAAM,IAAI,YAAY,CAAC,UAAU,CAAC,EAAE;AACpC,EAAE,MAAM,gBAAgB,CAAC,KAAK,EAAE,CAAC,EAAE,UAAU,CAAC,CAAC,CAAC,EAAE,OAAO,CAAC,MAAM,CAAC;AACjE,EAAE,IAAI,CAAC,aAAa,CAAC,UAAU,CAAC,EAAE,OAAO,iBAAiB,CAAC,UAAU,EAAE,KAAK,GAAG,CAAC,EAAE,OAAO,CAAC;AAC1F,CAAC;AACD,CAAC,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,OAAO,CAAC,MAAM,EAAE,CAAC,EAAE,EAAE;AAC1C,EAAE,MAAM,CAAC,GAAG,EAAE,KAAK,CAAC,GAAG,OAAO,CAAC,CAAC,CAAC;AACjC,EAAE,OAAO,uBAAuB,CAAC,GAAG,EAAE,KAAK,EAAE,KAAK,GAAG,CAAC,EAAE,OAAO,CAAC;AAChE,CAAC;AACD;AACA,UAAU,wBAAwB,CAAC,KAAK,EAAE,KAAK,EAAE,OAAO,EAAE;AAC1D,CAAC,IAAI,eAAe,CAAC,KAAK,CAAC,EAAE,MAAM,gBAAgB,CAAC,KAAK,EAAE,eAAe,CAAC,KAAK,EAAE,OAAO,CAAC,SAAS,CAAC,EAAE,OAAO,CAAC,MAAM,CAAC;AACrH,MAAM,IAAI,WAAW,CAAC,KAAK,CAAC,EAAE,IAAI,mBAAmB,CAAC,KAAK,CAAC,EAAE,MAAM,gBAAgB,CAAC,KAAK,EAAE,qBAAqB,CAAC,KAAK,EAAE,OAAO,CAAC,SAAS,CAAC,EAAE,OAAO,CAAC,MAAM,CAAC;AAC5J,MAAM;AACN,EAAE,MAAM,gBAAgB,CAAC,KAAK,EAAE,YAAY,CAAC,KAAK,CAAC,MAAM,EAAE,EAAE,SAAS,EAAE,OAAO,CAAC,SAAS,EAAE,CAAC,EAAE,OAAO,CAAC,MAAM,CAAC;AAC7G,EAAE,KAAK,MAAM,IAAI,IAAI,KAAK,EAAE,OAAO,wBAAwB,CAAC,IAAI,EAAE,KAAK,GAAG,CAAC,EAAE,OAAO,CAAC;AACrF,CAAC;AACD,MAAM,IAAI,YAAY,CAAC,KAAK,CAAC,EAAE,OAAO,2BAA2B,CAAC,KAAK,EAAE,KAAK,EAAE,OAAO,CAAC;AACxF;AACA,SAAS,YAAY,CAAC,KAAK,EAAE,OAAO,EAAE,UAAU,EAAE;AAClD,CAAC,OAAO,GAAG,CAAC,MAAM,CAAC,UAAU,GAAG,KAAK,CAAC,GAAG,OAAO;AAChD;AACA,SAAS,gBAAgB,CAAC,KAAK,EAAE,OAAO,EAAE,UAAU,EAAE;AACtD,CAAC,OAAO,YAAY,CAAC,KAAK,EAAE,gBAAgB,GAAG,OAAO,EAAE,UAAU,CAAC;AACnE;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS,MAAM,CAAC,KAAK,EAAE,OAAO,EAAE;AAChC,CAAC,OAAO,KAAK,CAAC,IAAI,CAAC,WAAW,CAAC,KAAc,CAAC,CAAC,CAAC,IAAI,CAAC,IAAI,CAAC;AAC1D;AAsBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS,WAAW,CAAC,KAAK,EAAE,OAAO,EAAE;AACrC,CAAC,OAAO,eAAe,CAAC,cAAc,CAAC,KAAK,CAAC,EAAE,cAAc,CAAQ,CAAC,EAAE,CAAC,CAAC;AAC1E;AAyFA,SAAS,cAAc,CAAC,OAAO,EAAE;AACjC,CAAC,OAAO;AACR,EAAE,MAAM,EAAqB,CAAC;AAC9B,EAAE,SAAS,EAAwB,iBAAiB;AACpD,EAAE,UAAU,EAAyB,KAAK;AAC1C,EAAE,YAAY,EAA2B,MAAM,CAAC;AAChD,EAAE;AACF;;ACzlDO,MAAM,eAAgK;AAAA,EACzK,QAAQ;AAAA,EACR,OAAO;AAAA,EACP,QAAQ;AAAA,EACR,cAAc;AAAA,EACd,eAAe;AAAA,EACf,aAAa;AAAA,EACb,SAAS;AAAA,EACT,eAAe;AAAA,EACf,aAAa;AAAA,EACb,QAAQ;AAAA,EACR,YAAY;AAAA,EACZ,QAAQ;AAAA,EACR,UAAU;AAAA,EACV,cAAc;AAClB;AAGO,MAAM,wBAAwB,CAAC,SAA2B;AAC7D,MAAI,CAAC,MAAM,OAAO;AAClB,QAAM,QAAQ,KAAK,aAAY;AAC/B,MAAI,MAAM,SAAS,OAAO,GAAG,OAAO;AACpC,MAAI,MAAM,SAAS,MAAM,GAAG,OAAO;AACnC,MAAI,MAAM,SAAS,YAAY,KAAK,MAAM,SAAS,YAAY,GAAG,OAAO;AACzE,MAAI,MAAM,SAAS,UAAU,KAAK,MAAM,SAAS,IAAI,GAAG,OAAO;AAC/D,MAAI,MAAM,SAAS,KAAK,GAAG,OAAO;AAClC,MAAI,MAAM,SAAS,WAAW,GAAG,OAAO;AACxC,MAAI,MAAM,SAAS,YAAY,GAAG,OAAO;AACzC,SAAO;AACX;AAGO,MAAM,4BAA4B,CAAC,YAA8B;AACpE,MAAI,CAAC,WAAW,OAAO,YAAY,UAAU,OAAO;AAEpD,QAAM,UAAU,QAAQ,MAAK;AAG7B,MAAK,QAAQ,WAAW,GAAG,KAAK,QAAQ,SAAS,GAAG,KAC/C,QAAQ,WAAW,GAAG,KAAK,QAAQ,SAAS,GAAG,GAAI;AACpD,QAAI;AAAE,WAAK,MAAM,OAAO;AAAG,aAAO;AAAA,IAAQ,QAAQ;AAAA,IAAuB;AAAA,EAC7E;AAGA,MAAI,IAAI,SAAS,SAAS,QAAO,IAAK,IAAI,QAAQ,OAAO,UAAU,cAAc,SAAS,aAAa,YAAY,cAAc,UAAc,OAAO,UAAU,cAAc,SAAS,aAAa,UAAU,UAAU,EAAG,GAAG,OAAO;AAGrO,MAAI,QAAQ,WAAW,aAAa,KAAK,QAAQ,SAAS,UAAU,GAAG,OAAO;AAG9E,MAAI,gDAAgD,KAAK,OAAO,GAAG,OAAO;AAG1E,MAAI,iEAAiE,KAAK,OAAO,GAAG,OAAO;AAG3F,MAAI,0CAA0C,KAAK,OAAO,GAAG,OAAO;AAEpE,SAAO;AACX;AAGO,MAAM,qBAAqB,CAAC,SAA4B;AAC3D,QAAM,UAAU,MAAM;AACtB,QAAM,WAAW,eAAe,MAAM,YAAY,YAAY;AAG9D,QAAM,gBAAgB,mBAAmB,OAAO;AAEhD,UAAQ;AAAU,IACd,KAAK;AACD,aAAO,GAAG,aAAa;;AAAA;;AAAA;;AAAA;;AAAA;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;;AAAA;;AAAA;AAAA;AAAA;;AAAA;;AAAA;AAAA;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,IAkD3B,KAAK;AACD,aAAO,GAAG,aAAa;;AAAA;;AAAA;;AAAA;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;;AAAA;;AAAA;AAAA;AAAA;AAAA;;AAAA;;AAAA;AAAA;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAiD/B,SAAO,iBAAiB;AAC5B;AAGA,MAAM,qBAAqB,CAAC,YAAyC;AACjE,MAAI,CAAC,SAAS,OAAO;AAErB,QAAM,QAAkB,EAAC;AAEzB,MAAI,QAAQ,WAAW;AACnB,UAAM,iBAAyC;AAAA,MAC3C,QAAQ;AAAA,MACR,QAAQ;AAAA,MACR,OAAO;AAAA,MACP,SAAS;AAAA,MACT,SAAS;AAAA,KACb;AACA,UAAM,KAAK,cAAc,eAAe,QAAQ,SAAS,KAAK,QAAQ,SAAS,EAAE;AAAA,EACrF;AAEA,MAAI,QAAQ,YAAY;AACpB,UAAM,KAAK,uBAAuB,QAAQ,UAAU,EAAE;AAAA,EAC1D;AAEA,MAAI,QAAQ,cAAc;AACtB,UAAM,KAAK,wEAAwE;AAAA,EACvF;AAEA,MAAI,QAAQ,SAAS,QAAQ;AACzB,UAAM,aAAa,QAAQ,QAAQ;AAAA,MAAI,OACnC,GAAG,EAAE,KAAK,IAAI,EAAE,QAAQ,IAAI,KAAK,UAAU,EAAE,KAAK,CAAC;AAAA,KACvD,CAAE,KAAK,IAAI;AACX,UAAM,KAAK,kBAAkB,UAAU,EAAE;AAAA,EAC7C;AAEA,MAAI,QAAQ,aAAa,QAAQ;AAC7B,UAAM,KAAK,iBAAiB,QAAQ,YAAY,KAAK,IAAI,CAAC,EAAE;AAAA,EAChE;AAEA,MAAI,QAAQ,UAAU;AAClB,UAAM,KAAK,mBAAmB,QAAQ,QAAQ,EAAE;AAAA,EACpD;AAEA,SAAO,MAAM,SAAS;AAAA,EAAa,MAAM,KAAK,IAAI,CAAC;;AAAA;AAAA,IAAc;AACrE;AAGO,MAAM,0BAA0B,CAAC,iBAAoD;AACxF,MAAI,CAAC,cAAc,QAAQ,OAAO;AAElC,QAAM,QAAQ,aAAa,IAAI,CAAC,MAAM,MAAM;AACxC,UAAM,UAAU,KAAK,YAAY,SAC3B,SAAS,KAAK,WAAW,IAAI,OAAK,GAAG,EAAE,KAAK,IAAI,EAAE,QAAQ,IAAI,KAAK,UAAU,EAAE,KAAK,CAAC,EAAE,EAAE,KAAK,OAAO,CAAC,KACtG;AAEN,YAAQ,KAAK;AAAQ,MACjB,KAAK;AACD,eAAO,GAAG,IAAI,CAAC,mBAAmB,KAAK,MAAM,QAAQ,KAAK,UAAU,KAAK,KAAK,CAAC,GAAG,OAAO;AAAA,MAC7F,KAAK;AACD,eAAO,GAAG,IAAI,CAAC,mBAAmB,KAAK,MAAM,IAAI,OAAO;AAAA,MAC5D,KAAK;AACD,eAAO,GAAG,IAAI,CAAC,iBAAiB,KAAK,MAAM,UAAU,KAAK,UAAU,KAAK,KAAK,CAAC,GAAG,OAAO;AAAA,MAC7F,KAAK;AACD,eAAO,GAAG,IAAI,CAAC,YAAY,KAAK,UAAU,KAAK,KAAK,CAAC,QAAQ,KAAK,MAAM,IAAI,OAAO;AAAA,MACvF,KAAK;AACD,eAAO,GAAG,IAAI,CAAC,cAAc,KAAK,MAAM,UAAU,KAAK,UAAU,KAAK,KAAK,CAAC,GAAG,OAAO;AAAA,MAC1F,KAAK;AACD,eAAO,GAAG,IAAI,CAAC,gBAAgB,KAAK,MAAM,YAAY,KAAK,WAAW,GAAG,OAAO;AAAA,MACpF;AACI,eAAO;AAAA;AACf,EACJ,CAAC,EAAE,OAAO,OAAO;AAEjB,SAAO,MAAM,SACP;AAAA;AAAA,EAAiC,MAAM,KAAK,IAAI,CAAC;AAAA,IACjD;AACV;AAGO,MAAM,2BAA2B;AAAA;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;;AAAA;AAAA;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAuBjC,MAAM,wBAAwB;AAAA;;AAAA;AAAA;AAAA;AAAA;AAAA;;AAAA;AAAA;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAsB9B,MAAM,sBAAsB;AAAA;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;;AAAA;AAAA;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;;ACzWnC,MAAM,2BAA2B;AAAA;AAAA,EAE7B;AAAA;AAAA,EAEA;AAAA;AAAA,EAEA;AAAA;AAAA,EAEA;AAAA;AAAA,EAEA;AACJ;AAKA,MAAM,eAAe,CAAC,SAAyB;AAC3C,MAAI,CAAC,QAAQ,OAAO,SAAS,UAAU,OAAO;AAE9C,SAAO,KAEF,QAAQ,WAAW,EAAE,EAErB,QAAQ,0BAA0B,EAAE,EAEpC,QAAQ,SAAS,IAAI,EACrB,QAAQ,OAAO,IAAI,EAEnB,MAAK;AACd;AAKA,MAAM,sBAAsB,CAAC,SAAyB;AAClD,MAAI,UAAU;AAGd,YAAU,QAAQ,QAAQ,gBAAgB,IAAI;AAI9C,YAAU,QAAQ,QAAQ,2BAA2B,CAAC,OAAO,IAAI,OAAO;AACpE,WAAO,MAAM,EAAE,MAAM,EAAE;AAAA,EAC3B,CAAC;AAGD,YAAU,QAAQ,QAAQ,iCAAiC,EAAE;AAE7D,SAAO;AACX;AAKO,MAAM,eAAe,CAAc,SAA4D;AAClG,MAAI,CAAC,MAAM,OAAO,EAAE,IAAI,OAAO,OAAO,eAAc;AAGpD,MAAI;AACA,UAAM,OAAO,KAAK,MAAM,IAAI;AAC5B,WAAO,EAAE,IAAI,MAAM,MAAK;AAAA,EAC5B,QAAQ;AAAA,EAAiB;AAGzB,MAAI;AACA,UAAM,OAAO,KAAK,MAAM,IAAI;AAC5B,WAAO,EAAE,IAAI,MAAM,MAAK;AAAA,EAC5B,QAAQ;AAAA,EAAiB;AAGzB,MAAI;AACA,UAAM,YAAY,oBAAoB,IAAI;AAC1C,UAAM,OAAO,KAAK,MAAM,SAAS;AACjC,WAAO,EAAE,IAAI,MAAM,MAAK;AAAA,EAC5B,QAAQ;AAAA,EAAiB;AAGzB,MAAI;AACA,UAAM,QAAQ,KAAK,MAAM,oCAAoC;AAC7D,QAAI,QAAQ,CAAC,GAAG;AACZ,YAAM,OAAO,KAAK,MAAM,MAAM,CAAC,CAAC;AAChC,aAAO,EAAE,IAAI,MAAM,MAAK;AAAA,IAC5B;AAAA,EACJ,QAAQ;AAAA,EAAiB;AAEzB,SAAO,EAAE,IAAI,OAAO,OAAO,4CAA2C;AAC1E;AASO,MAAM,4BAA4B,CAAc,aAAwD;AAC3G,MAAI,YAAY,MAAM;AAClB,WAAO,EAAE,IAAI,OAAO,OAAO,iCAAgC;AAAA,EAC/D;AAEA,MAAI,OAAO,aAAa,UAAU;AAE9B,QAAI,OAAO,aAAa,UAAU;AAC9B,aAAO,EAAE,IAAI,MAAM,MAAM,UAAe,QAAQ,UAAS;AAAA,IAC7D;AACA,WAAO,EAAE,IAAI,OAAO,OAAO,wBAAwB,OAAO,QAAQ,IAAG;AAAA,EACzE;AAEA,QAAM,UAAU,aAAa,QAAQ;AACrC,MAAI,CAAC,SAAS;AACV,WAAO,EAAE,IAAI,OAAO,OAAO,oCAAoC,KAAK,UAAS;AAAA,EACjF;AAGA,QAAM,eAAe,aAAgB,OAAO;AAC5C,MAAI,aAAa,IAAI;AACjB,WAAO,EAAE,IAAI,MAAM,MAAM,aAAa,MAAM,KAAK,UAAU,QAAQ,UAAS;AAAA,EAChF;AAGA,aAAW,WAAW,0BAA0B;AAC5C,UAAM,QAAQ,QAAQ,MAAM,OAAO;AACnC,QAAI,QAAQ,CAAC,GAAG;AACZ,YAAM,YAAY,aAAa,MAAM,CAAC,CAAC;AACvC,YAAM,SAAS,aAAgB,SAAS;AACxC,UAAI,OAAO,IAAI;AACX,eAAO;AAAA,UACH,IAAI;AAAA,UACJ,MAAM,OAAO;AAAA,UACb,KAAK;AAAA,UACL,QAAQ;AAAA,SACZ;AAAA,MACJ;AAAA,IACJ;AAAA,EACJ;AAGA,QAAM,gBAAgB,QAAQ,MAAM,2BAA2B;AAC/D,MAAI,gBAAgB,CAAC,GAAG;AACpB,UAAM,YAAY,oBAAoB,cAAc,CAAC,CAAC;AACtD,UAAM,SAAS,aAAgB,SAAS;AACxC,QAAI,OAAO,IAAI;AACX,aAAO;AAAA,QACH,IAAI;AAAA,QACJ,MAAM,OAAO;AAAA,QACb,KAAK;AAAA,QACL,QAAQ;AAAA,OACZ;AAAA,IACJ;AAAA,EACJ;AAGA,SAAO;AAAA,IACH,IAAI;AAAA,IACJ,OAAO;AAAA,IACP,KAAK;AAAA,GACT;AACJ;AASO,MAAM,sBAAsB,CAC/B,UACA,cAAsB,WACkH;AACxI,QAAM,SAAS,0BAA6B,QAAQ;AAEpD,MAAI,OAAO,MAAM,OAAO,SAAS,QAAW;AACxC,WAAO;AAAA,MACH,KAAK,OAAO,OAAO;AAAA,MACnB,IAAI;AAAA,MACJ,MAAM,OAAO;AAAA,MACb,QAAQ,OAAO;AAAA,MACf,cAAc,OAAO,WAAW;AAAA,MAChC,OAAO,OAAO,SAAS;AAAA,KAC3B;AAAA,EACJ;AAGA,SAAO;AAAA,IACH,KAAK,OAAO,OAAO;AAAA,IACnB,IAAI;AAAA,IACJ,MAAM,EAAE,CAAC,WAAW,GAAG,OAAO,OAAO,OAAO,QAAQ,GAAE;AAAA,IACtD,QAAQ;AAAA,IACR,cAAc;AAAA,IACd,OAAO,OAAO,SAAS;AAAA,GAC3B;AACJ;AA+CO,MAAM,2BAA2B;AAAA;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;;AAAA;AAAA;;ACpPxC,MAAM,UAAU,MAAM,OAAQ,WAAmB,SAAS;AAC1D,MAAM,UAAU,MAAM,OAAQ,WAAmB,SAAS;AAOnD,MAAM,2BAA2B;AAAA,EACpC,KAAK,KAAK;AAAA;AAAA,EACV,QAAQ,IAAI,KAAK;AAAA;AAAA,EACjB,MAAM,KAAK,KAAK;AAAA;AACpB;AAEO,MAAM,sBAAsB;AAC5B,MAAM,cAAc;AAK3B,SAAS,iBAAiB,QAA4E;AAClG,MAAI;AAEA,UAAM,WAAa,WAAmB,iBAAyB,MAC/C,QAAQ,8BAA8B,EAAE,sBAAqB,EAAG,MAChE,QAAQ,uBAAuB,EAAE,gBAAe,EAAG;AAEnE,UAAM,kBAAkB,UAAU;AAClC,UAAM,aAAa,UAAU,cAAc;AAE3C,UAAM,WAAW,kBAAkB,MAAM,KAAK,yBAAyB,MAAM,KAAK;AAElF,WAAO,EAAE,SAAS,YAAW;AAAA,EACjC,QAAQ;AAEJ,WAAO;AAAA,MACH,SAAS,yBAAyB,MAAM;AAAA,MACxC,YAAY;AAAA,KAChB;AAAA,EACJ;AACJ;AAGA,MAAM,WAAW,CAAC,UAA8B;AAE5C,MAAI,OAAQ,WAAmB,WAAW,aAAa;AACnD,WAAQ,WAAmB,OAAO,KAAK,KAAK,EAAE,SAAS,QAAQ;AAAA,EACnE;AAGA,QAAM,aAAa,OAAO;AAC1B,MAAI,MAAM,SAAS,YAAY;AAC3B,QAAI,SAAS;AACb,aAAS,IAAI,GAAG,IAAI,MAAM,QAAQ,KAAK,YAAY;AAC/C,YAAM,QAAQ,MAAM,MAAM,GAAG,IAAI,UAAU;AAC3C,UAAIC,UAAS;AACb,eAAS,IAAI,GAAG,IAAI,MAAM,QAAQ,KAAK;AACnC,QAAAA,WAAU,OAAO,aAAa,MAAM,CAAC,CAAC;AAAA,MAC1C;AACA,gBAAW,OAAO,SAAS,aAAa,KAAKA,OAAM,IAAI;AAAA,IAC3D;AACA,WAAO;AAAA,EACX;AAGA,MAAI,SAAS;AACb,WAAS,IAAI,GAAG,IAAI,MAAM,QAAQ,KAAK,UAAU,OAAO,aAAa,MAAM,CAAC,CAAC;AAE7E,SAAO,OAAO,SAAS,aAAa,KAAK,MAAM,IAAI;AACvD;AAyBO,MAAM,gBAAgB,OAAO,SAAoB;AACpD,QAAM,WAAW,SAAQ,GAAK,WAAmB,OAAO;AACxD,QAAM,WAAW,SAAQ,GAAK,WAAmB,OAAO;AACxD,QAAM,eACD,YAAY,MAAM,sBAAsB,YACxC,YAAY,MAAM,sBAAsB;AAE7C,MAAI,cAAc;AACd,UAAM,WAAW,MAAM,YAAY,QAAQ;AAC3C,UAAMC,iBAAgB,KAAK,OAAO;AAGlC,QAAI,WAAWA,gBAAe;AAC1B,cAAQ,KAAK,mCAAmC,QAAQ,YAAYA,cAAa,QAAQ;AACzF,aAAO;AAAA,QACH,QAAQ;AAAA,QACR,QAAQ,qBAAqB,WAAW,OAAO,MAAM,QAAQ,CAAC,CAAC,yBAAyBA,iBAAgB,OAAO,MAAM,QAAQ,CAAC,CAAC;AAAA,OACnI;AAAA,IACJ;AAEA,QAAI,eAAe,MAAM,YAAY,YAAY,MAAM,iBAAkB,MAAM,YAAY,MAAM,aAAa,QAAQ,GAAI;AACtH,UAAI;AACA,cAAM,YAAY,QAAQ,MAAM,YAAY,IAAI;AAChD,cAAM,cAAc,MAAM,MAAM,YAAY,aAAY;AACxD,YAAI,CAAC,aAAa;AACd,gBAAM,IAAI,MAAM,oCAAoC;AAAA,QACxD;AACA,cAAM,QAAQ,IAAI,WAAW,WAAW;AACxC,cAAMC,OAAM,YAAY,SAAS,KAAK;AACtC,eAAO;AAAA,UACH,QAAQ;AAAA,UACR,UAAU;AAAA,UACV,aAAaA;AAAA,SACjB;AAAA,MACJ,SAAS,OAAO;AACZ,gBAAQ,MAAM,iDAAiD,KAAK;AACpE,eAAO;AAAA,UACH,QAAQ;AAAA,UACR,QAAQ,kCAAkC,KAAK;AAAA,SACnD;AAAA,MACJ;AAAA,IACJ;AAGA,QAAI;AACA,YAAM,OAAO,MAAM,MAAM,YAAY,QAAO;AAC5C,UAAI,MAAM;AACN,eAAO;AAAA,UACH,QAAQ;AAAA,UACR,QAAQ;AAAA,SACZ;AAAA,MACJ;AAAA,IACJ,SAAS,OAAO;AACZ,cAAQ,MAAM,6CAA6C,KAAK;AAChE,aAAO;AAAA,QACH,QAAQ;AAAA,QACR,QAAQ,8BAA8B,KAAK;AAAA,OAC/C;AAAA,IACJ;AAAA,EACJ,WAAW,OAAO,MAAM,cAAc,UAAU;AAE5C,UAAM,gBAAgB,MAAM,YAAY,0BAA0B,KAAK,UAAU;AAGjF,QACK,MAAM,YAAY,aAAa,aAAa,KAAK,MAAM,YAAY,WAAW,UAAU,KACzF,IAAI,SAAS,MAAM,YAAY,QAAO,IAAK,IAAI,QAAQ,OAAO,UAAU,cAAc,SAAS,aAAa,YAAY,cAAc,UAAc,OAAO,UAAU,cAAc,SAAS,aAAa,UAAU,UAAU,EAAG,KAC/N,eAAe,aAAa,KAAK,eACpC;AACE,aAAO;AAAA,QACH,QAAQ;AAAA,QACR,aAAa,MAAM;AAAA,QACnB,UAAU;AAAA,OACd;AAAA,IACJ;AAGA,WAAO;AAAA,MACH,QAAQ;AAAA,MACR,QAAQ,MAAM;AAAA,KAClB;AAAA,EACJ;AAGA,MAAI,SAAS,MAAM;AACnB,MAAI;AACA,aAAU,OAAO,MAAM,cAAc,WAAY,MAAM,aAAa,OAAO,MAAM,UAAU;AAAA,EAC/F,SAAS,GAAG;AACR,YAAQ,KAAK,CAAC;AAAA,EAClB;AAGA,SAAO;AAAA,IACH,QAAQ,eAAe,MAAM,YAAY,YAAY,KAAK;AAAA,IAC1D,QAAQ;AAAA,GACZ;AACJ;AAGO,MAAM,aAAa;AAAA,EACd;AAAA,EACA;AAAA,EACA,SAAiB;AAAA,EACjB,QAAgB;AAAA,EAChB,aAA6B;AAAA,EAE3B,UAAiB,EAAC;AAAA,EAClB,WAAkB,EAAC;AAAA,EACnB,4BAA8B,KAAI;AAAA,EAClC,UAA8B;AAAA,EAC9B,kCAAoC,KAAI;AAAA;AAAA,EAGlD,YAAY,QAAgB,QAAgB,WAAmB,OAAe;AAC1E,SAAK,SAAS,UAAU;AACxB,SAAK,SAAS,UAAU,KAAK;AAC7B,SAAK,YAAY,aAAa;AAC9B,SAAK,QAAQ,SAAS,KAAK;AAAA,EAC/B;AAAA;AAAA,EAGA,WAAW,SAA6B;AACpC,SAAK,UAAU;AACf,WAAO;AAAA,EACX;AAAA;AAAA,EAGA,MAAM,OAAO,aAAqB,QAAgB,WAAmB,WAAmB;AACpF,SAAK,MAAM,IAAI,QAAQ,QAAO,EAAG;AAAA,MAC7B,QAAQ;AAAA,MACR,gBAAgB;AAAA,MAChB,cAAc;AAAA,MACd,WAAW;AAAA,QACP,iBAAiB,UAAU,SAAS,IAAI,SAAS;AAAA,OACrD;AAAA,MACA,oBAAoB;AAAA,KACvB;AACD,WAAO,KAAK,MAAM,IAAI,QAAQ,QAAQ;AAAA,EAC1C;AAAA;AAAA,EAGA,MAAM,oBACF,YACA,WAA4B,MAC5B,mBAAkC,MACtB;AACZ,iBAAa,sBAAsB,YAAY,IAAI,KAAK;AAExD,UAAM,YAAuB,EAAE,YAAY,UAAU,SAAS,KAAK,SAAQ;AAC3E,UAAM,aAAa,MAAM,cAAc,SAAS;AAEhD,WAAO;AAAA,MACH,MAAM;AAAA,MACN,MAAM;AAAA,MACN,SAAS;AAAA,QACL,EAAE,MAAM,cAAc,MAAM,iBAAiB,mBAAmB,SAAS,GAAE;AAAA,QAC3E,mBAAmB,EAAE,MAAM,QAAQ,MAAM,8BAA8B,kBAAiB,GAAI;AAAA,QAC5F,EAAE,MAAM,cAAc,MAAM,qCAAoC;AAAA,QAChE,EAAE,GAAG,YAAW;AAAA,QAChB,EAAE,MAAM,cAAc,MAAM;AAAkC,OAClE,EAAG,SAAS,CAAC,SAAS,SAAS,IAAI;AAAA,KACvC;AAAA,EACJ;AAAA;AAAA,EAGA,MAAM,gBACF,YACA,WAA4B,MAC5B,cAA6B,MAC/B;AACE,SAAK,QAAQ,KAAK,MAAM,KAAK;AAAA,MACzB;AAAA,MACA,aAAa,sBAAsB,YAAY,IAAI,KAAK;AAAA,KAC3D;AACD,QAAI,aAAa;AACb,WAAK,QAAQ,KAAK,MAAM,KAAK,cAAc,WAAW,CAAC;AAAA,IAC3D;AACA,WAAO,KAAK,QAAQ,KAAK,QAAQ,SAAS,CAAC;AAAA,EAC/C;AAAA;AAAA,EAGA,MAAM,mBAAmB,cAAmB,YAAqB;AAC7D,SAAK,UAAU;AAAA,MACX,GAAG,KAAK;AAAA,MACR;AAAA,MACA,YAAY,cAAc,KAAK,SAAS;AAAA,KAC5C;AAEA,UAAM,KAAK,eAAe,oBAAoB,OAAO,YAAY,CAAC;AAAA,CAAM;AACxE,WAAO;AAAA,EACX;AAAA;AAAA,EAGA,MAAM,eAAe,UAAkB;AACnC,UAAM,SAAS,OAAO;AAAA,MAClB,MAAM;AAAA,MACN,MAAM;AAAA,MACN,SAAS,CAAC,EAAE,MAAM,cAAc,MAAM,iCAAgC,EAAG,EAAE,MAAM,cAAc,MAAM,UAAU;AAAA,KAClH;AACD,WAAO,MAAM,UAAU,MAAM,SAAS,SAAS,CAAC;AAAA,EACpD;AAAA;AAAA,EAGA,MAAM,cAAc,QAAgB;AAChC,UAAM,SAAS,OAAO;AAAA,MAClB,MAAM;AAAA,MACN,MAAM;AAAA,MACN,SAAS,CAAC,EAAE,MAAM,cAAc,MAAM,QAAQ;AAAA,KACjD;AACD,WAAO,MAAM,UAAU,MAAM,SAAS,SAAS,CAAC;AAAA,EACpD;AAAA;AAAA,EAGA,oBAAoB,aAA4B,MAAM;AAClD,SAAK,aAAc,KAAK,aAAc,cAAc,KAAK;AACzD,WAAO;AAAA,EACX;AAAA;AAAA,EAGA,MAAM,YACF,SAAoC,OACpC,YAAuC,OACvC,iBAAgC,MAChC,UAA0B,EAAC,EACL;AACtB,eAAW;AACX,kBAAc;AAGd,UAAM,oCAAoB,KAAI;AAC9B,eAAW,QAAQ,KAAK,SAAS;AAC7B,UAAI,CAAC,MAAM;AACX,UAAI;AACA,cAAM,MAAM,OAAO,SAAS,WAAW,KAAK,UAAU,IAAI,IAAI,OAAO,IAAI;AACzE,YAAI,CAAC,cAAc,IAAI,GAAG,GAAG;AACzB,wBAAc,IAAI,KAAK,IAAI;AAAA,QAC/B;AAAA,MACJ,SAAS,GAAG;AACR,sBAAc,IAAI,KAAK,QAAO,CAAE,YAAY,IAAI;AAAA,MACpD;AAAA,IACJ;AACA,UAAM,gBAAgB,MAAM,KAAK,cAAc,QAAQ;AAIvD,UAAM,mBAAmB,SAAS,mBAAmB,SAC/C,2BACA;AAEN,UAAM,cAAmB;AAAA,MACrB,OAAO,KAAK;AAAA,MACZ,OAAO,MAAM,KAAK,MAAM,OAAO,UAAS,IAAK,EAAE,GAAG,SAAS,CAAC,SAAc,CAAC,CAAC,IAAI;AAAA,MAChF,OAAO;AAAA,MACP,WAAW,EAAE,UAAU,QAAO;AAAA,MAC9B,MAAM,EAAE,WAAqB;AAAA,MAC7B,mBAAmB,SAAS,aAAa;AAAA,MACzC,sBAAuB,KAAK,aAAc,kBAAkB,MAAM;AAAA,MAClE,cAAc;AAAA,KAClB;AAGA,QAAI,SAAS,gBAAgB,QAAW;AACpC,kBAAY,cAAc,QAAQ;AAAA,IACtC;AAGA,UAAM,EAAE,SAAS,WAAW,YAAW,GAAI,iBAAiB,MAAM;AAClE,YAAQ,IAAI,4BAA4B,GAAG,MAAM,MAAM,YAAY;AACnE,YAAQ,IAAI,0BAA0B,CAAC,CAAC,MAAM,MAAM;AACpD,YAAQ,IAAI,0BAA0B,GAAG,SAAS,OAAO,MAAM,UAAU;AACzE,YAAQ,IAAI,sBAAsB,UAAU;AAC5C,YAAQ,IAAI,4BAA4B,KAAK,UAAU,WAAW,EAAE,QAAQ,YAAY;AAExF,QAAI,YAA0B;AAE9B,aAAS,UAAU,GAAG,WAAW,YAAY,WAAW;AACpD,UAAI,UAAU,GAAG;AACb,gBAAQ,IAAI,uBAAuB,OAAO,IAAI,UAAU,UAAU,WAAW,UAAU;AACvF,cAAM,IAAI,QAAQ,aAAW,WAAW,SAAS,WAAW,CAAC;AAAA,MACjE;AAEA,UAAI;AACA,cAAM,aAAa,IAAI,iBAAgB;AACvC,cAAM,YAAY,WAAW,MAAM;AAC/B,kBAAQ,KAAK,+BAA+B,SAAS,eAAe,UAAU,CAAC,GAAG;AAClF,qBAAW,OAAM;AAAA,QACrB,GAAG,SAAS;AAEZ,cAAM,WAAW,MAAM,MAAM,GAAG,MAAM,MAAM,cAAc;AAAA,UACtD,QAAQ;AAAA,UACR,UAAU;AAAA;AAAA,UAEV,QAAQ,WAAW;AAAA,UACnB,SAAS;AAAA,YACL,gBAAgB;AAAA,YAChB,GAAI,MAAM,SAAS,EAAE,iBAAiB,UAAU,MAAM,MAAM,IAAG,GAAI;AAAC,WACxE;AAAA,UACA,MAAM,KAAK,UAAU,WAAW;AAAA,SACnC;AAED,qBAAa,SAAS;AAGtB,gBAAQ,IAAI,0BAA0B,SAAS,QAAQ,YAAY,UAAU,CAAC,GAAG;AAEjF,YAAI,SAAS,WAAW,KAAK;AACzB,gBAAM,QAAQ,MAAM,UAAU,QAAO,EAAG,QAAQ,CAAC,MAAM;AACnD,oBAAQ,MAAM,yCAAyC,CAAC;AACxD,mBAAO;AAAA,UACX,CAAC;AACD,gBAAMC,gBAAe,OAAO,OAAO,WAAW,OAAO,WAAW,QAAQ,SAAS,MAAM;AACvF,sBAAY,IAAI,MAAM,cAAc,SAAS,MAAM,MAAMA,aAAY,EAAE;AACvE,kBAAQ,MAAM,oBAAoBA,aAAY;AAG9C,cAAI,SAAS,UAAU,OAAO,SAAS,SAAS,KAAK;AACjD,kBAAM;AAAA,UACV;AAGA;AAAA,QACJ;AAGA,eAAO,MAAM,KAAK,0BAA0B,QAAQ;AAAA,MAExD,SAAS,GAAG;AACR,oBAAY,aAAa,QAAQ,IAAI,IAAI,MAAM,OAAO,CAAC,CAAC;AACxD,gBAAQ,MAAM,iCAAiC,UAAU,CAAC,MAAM,UAAU,OAAO;AAGjF,YAAI,UAAU,SAAS,gBAAiB,UAAU,QAAQ,SAAS,QAAQ,GAAI;AAC3E;AAAA,QACJ;AAAA,MAGJ;AAAA,IACJ;AAGA,UAAM,eAAe,YAAY,UAAU,UAAU;AACrD,YAAQ,MAAM,oCAAoC,YAAY;AAC9D,UAAM,IAAI,MAAM,wBAAwB,aAAa,CAAC,cAAc,YAAY,EAAE;AAAA,EACtF;AAAA;AAAA;AAAA;AAAA,EAKA,MAAc,0BAA0B,UAA4C;AAEhF,UAAM,OAAO,MAAM,UAAU,QAAO,EAAG,QAAQ,CAAC,MAAM;AAClD,cAAQ,KAAK,8CAA8C,CAAC;AAC5D,aAAO;AAAA,IACX,CAAC;AACD,QAAI,CAAC,MAAM,OAAO;AAGlB,SAAK,YAAY,IAAK,KAAK,aAAc,MAAM,MAAM,MAAM,eAAe,KAAK,YAAc,IAAI;AACjG,UAAM,UAAU,OAAO,GAAI,MAAM,WAAW,EAAG;AAC/C,UAAM,SAAS,SAAS,GAAG,MAAM,SAAS,MAAM;AAChD,SAAK,SAAS,KAAK,GAAI,MAAM,UAAU,EAAG;AAG1C,UAAM,cAAc,CAAC,MAA0B;AAC3C,UAAI;AACA,YAAI,CAAC,GAAG,OAAO;AACf,YAAI,OAAO,MAAM,UAAU,OAAO;AAClC,YAAI,EAAE,eAAe,MAAM,QAAQ,EAAE,WAAW,KAAK,EAAE,YAAY,QAAQ;AACvE,iBAAO,EAAE,YAAY,KAAK,MAAM;AAAA,QACpC;AACA,cAAM,UAAU,EAAE,UAAU,EAAC;AAC7B,cAAM,QAAkB,EAAC;AACzB,mBAAW,OAAO,SAAS;AACvB,gBAAM,UAAU,KAAK,WAAW,EAAC;AACjC,cAAI,CAAC,SAAS;AACd,qBAAW,QAAQ,SAAS;AACxB,gBAAI,OAAO,MAAM,SAAS,UAAU,MAAM,KAAK,KAAK,IAAI;AAAA,qBAC/C,MAAM,MAAM,aAAa,KAAK,KAAK,KAAK,KAAK;AAAA,UAC1D;AAAA,QACJ;AACA,YAAI,MAAM,QAAQ,OAAO,MAAM,KAAK,MAAM;AAAA,MAC9C,SAAS,GAAG;AACR,gBAAQ,KAAK,gCAAgC,CAAC;AAAA,MAClD;AACA,aAAO;AAAA,IACX;AAEA,UAAM,OAAO,YAAY,IAAI;AAC7B,QAAI,QAAQ,MAAM,OAAO;AAGzB,QAAI;AACA,aAAO,KAAK,MAAM,MAAM,UAAU,IAAI;AAAA,IAC1C,QAAQ;AAAA,IAAa;AACrB,WAAO;AAAA,EACX;AAAA;AAAA;AAAA,EAKA,MAAM,mBACF,cACA,oBACA,eAA0C,EAAC,EACnB;AACxB,QAAI;AACA,WAAK,WAAW;AAAA,QACZ,WAAW;AAAA,QACX;AAAA,OACH;AAED,YAAM,KAAK,eAAe,wBAAwB;AAClD,YAAM,KAAK,eAAe,sBAAsB,OAAO,YAAY,CAAC;AAAA,CAAM;AAE1E,UAAI,aAAa,QAAQ;AACrB,cAAM,KAAK,eAAe,wBAAwB,YAAY,CAAC;AAAA,MACnE;AAEA,YAAM,KAAK,cAAc,kBAAkB;AAE3C,YAAM,MAAM,MAAM,KAAK,YAAY,QAAQ,UAAU,MAAM;AAAA,QACvD,gBAAgB;AAAA,QAChB,aAAa;AAAA,OAChB;AAID,YAAM,cAAc,0BAA+B,GAAG;AACtD,UAAI,CAAC,YAAY,IAAI;AACjB,gBAAQ,KAAK,2BAA2B,YAAY,OAAO,QAAQ,YAAY,GAAG;AAClF,eAAO,EAAE,IAAI,OAAO,OAAO,YAAY,SAAS,+BAA8B;AAAA,MAClF;AAEA,aAAO;AAAA,QACH,IAAI;AAAA,QACJ,MAAM,YAAY,MAAM,mBAAmB,YAAY;AAAA,QACvD,YAAY,KAAK;AAAA,OACrB;AAAA,IACJ,SAAS,GAAG;AACR,cAAQ,MAAM,gCAAgC,CAAC;AAC/C,aAAO,EAAE,IAAI,OAAO,OAAO,OAAO,CAAC,GAAE;AAAA,IACzC;AAAA,EACJ;AAAA;AAAA,EAGA,MAAM,oBACF,SACA,SACA,cAAwB,EAAC,EACC;AAC1B,QAAI;AACA,WAAK,WAAW;AAAA,QACZ,WAAW;AAAA,QACX;AAAA,QACA;AAAA,OACH;AAED,YAAM,KAAK,eAAe,qBAAqB;AAC/C,YAAM,KAAK,eAAe,eAAe,OAAO,OAAO,CAAC;AAAA,CAAM;AAE9D,YAAM,aAAa,QAAQ;AAAA,QAAI,OAC3B,WAAW,EAAE,KAAK,IAAI,EAAE,QAAQ,IAAI,KAAK,UAAU,EAAE,KAAK,CAAC;AAAA,OAC/D,CAAE,KAAK,IAAI;AAEX,YAAM,KAAK,cAAc;AAAA;AAAA,EAEnC,UAAU;AAAA,EACV,YAAY,SAAS;AAAA,gBAAmB,YAAY,KAAK,IAAI,CAAC,KAAK,EAAE;;AAAA;AAAA,aAG1D;AAED,YAAM,MAAM,MAAM,KAAK,YAAY,UAAU,OAAO,MAAM;AAAA,QACtD,gBAAgB;AAAA,QAChB,aAAa;AAAA,OAChB;AAID,YAAM,cAAc,0BAA+B,GAAG;AACtD,UAAI,CAAC,YAAY,IAAI;AACjB,gBAAQ,KAAK,2BAA2B,YAAY,OAAO,QAAQ,YAAY,GAAG;AAClF,eAAO,EAAE,IAAI,OAAO,OAAO,YAAY,SAAS,+BAA8B;AAAA,MAClF;AAEA,aAAO;AAAA,QACH,IAAI;AAAA,QACJ,MAAM,YAAY,MAAM,kBAAkB,YAAY;AAAA,QACtD,YAAY,KAAK;AAAA,OACrB;AAAA,IACJ,SAAS,GAAG;AACR,cAAQ,MAAM,iCAAiC,CAAC;AAChD,aAAO,EAAE,IAAI,OAAO,OAAO,OAAO,CAAC,GAAE;AAAA,IACzC;AAAA,EACJ;AAAA;AAAA,EAGA,MAAM,cACF,SACA,WACA,gBAAsF,kBAC9D;AACxB,QAAI;AACA,WAAK,WAAW;AAAA,QACZ,WAAW;AAAA,QACX,cAAc;AAAA,OACjB;AAED,YAAM,KAAK,eAAe,mBAAmB;AAC7C,YAAM,KAAK,eAAe,qBAAqB,OAAO,OAAO,CAAC;AAAA,CAAM;AACpE,YAAM,KAAK,eAAe,qBAAqB,OAAO,SAAS,CAAC;AAAA,CAAM;AAEtE,YAAM,KAAK,cAAc;AAAA,0DACqB,aAAa;AAAA;AAAA;AAAA;AAAA;;AAAA;AAAA,aAO1D;AAED,YAAM,MAAM,MAAM,KAAK,YAAY,QAAQ,UAAU,MAAM;AAAA,QACvD,gBAAgB;AAAA,QAChB,aAAa;AAAA,OAChB;AAID,YAAM,cAAc,0BAA+B,GAAG;AACtD,UAAI,CAAC,YAAY,IAAI;AACjB,gBAAQ,KAAK,2BAA2B,YAAY,OAAO,QAAQ,YAAY,GAAG;AAClF,eAAO,EAAE,IAAI,OAAO,OAAO,YAAY,SAAS,+BAA8B;AAAA,MAClF;AAEA,aAAO;AAAA,QACH,IAAI;AAAA,QACJ,MAAM,YAAY,MAAM,iBAAiB,YAAY;AAAA,QACrD,YAAY,KAAK;AAAA,OACrB;AAAA,IACJ,SAAS,GAAG;AACR,cAAQ,MAAM,2BAA2B,CAAC;AAC1C,aAAO,EAAE,IAAI,OAAO,OAAO,OAAO,CAAC,GAAE;AAAA,IACzC;AAAA,EACJ;AAAA;AAAA,EAGA,MAAM,cACF,iBACA,cACA,sBAA8B,KAC0B;AACxD,QAAI;AACA,WAAK,WAAW;AAAA,QACZ,WAAW;AAAA,OACd;AAED,YAAM,KAAK,eAAe,uBAAuB,OAAO,eAAe,CAAC;AAAA,CAAM;AAC9E,YAAM,KAAK,eAAe,oBAAoB,OAAO,YAAY,CAAC;AAAA,CAAM;AAGxE,YAAM,KAAK,cAAc;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;;AAAA,wCASG,mBAAmB;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,aAU9C;AAED,YAAM,MAAM,MAAM,KAAK,YAAY,UAAU,UAAU,MAAM;AAAA,QACzD,gBAAgB;AAAA,QAChB,aAAa;AAAA,OAChB;AAID,YAAM,cAAc,0BAA+B,GAAG;AACtD,UAAI,CAAC,YAAY,IAAI;AACjB,gBAAQ,KAAK,2BAA2B,YAAY,OAAO,QAAQ,YAAY,GAAG;AAClF,eAAO,EAAE,IAAI,OAAO,OAAO,YAAY,SAAS,+BAA8B;AAAA,MAClF;AAEA,aAAO;AAAA,QACH,IAAI;AAAA,QACJ,MAAM,YAAY,MAAM,iBAAiB,EAAC;AAAA,QAC1C,YAAY,KAAK;AAAA,OACrB;AAAA,IACJ,SAAS,GAAG;AACR,cAAQ,MAAM,2BAA2B,CAAC;AAC1C,aAAO,EAAE,IAAI,OAAO,OAAO,OAAO,CAAC,GAAE;AAAA,IACzC;AAAA,EACJ;AAAA;AAAA,EAGA,MAAM,aACF,OACA,WACA,YAAoB,IACM;AAC1B,UAAM,UAAiB,EAAC;AACxB,UAAM,SAAmB,EAAC;AAE1B,aAAS,IAAI,GAAG,IAAI,MAAM,QAAQ,KAAK,WAAW;AAC9C,YAAM,QAAQ,MAAM,MAAM,GAAG,IAAI,SAAS;AAE1C,YAAM,KAAK,eAAe,kBAAkB,OAAO,KAAK,CAAC;AAAA,CAAM;AAE/D,YAAM,KAAK,cAAc;AAAA,wBACb,MAAM,MAAM;AAAA,EAClC,SAAS;;AAAA;AAAA;AAAA,aAIE;AAED,YAAM,MAAM,MAAM,KAAK,YAAY,UAAU,OAAO,MAAM;AAAA,QACtD,gBAAgB;AAAA,OACnB;AAED,UAAI,KAAK;AAEL,cAAM,cAAc,0BAA+B,GAAG;AACtD,YAAI,YAAY,MAAM,YAAY,MAAM;AACpC,kBAAQ,KAAK,GAAI,YAAY,MAAM,aAAa,EAAG;AACnD,cAAI,YAAY,MAAM,QAAQ,QAAQ;AAClC,mBAAO,KAAK,GAAG,YAAY,KAAK,OAAO,IAAI,CAAC,MAAW,GAAG,SAAS,eAAe,CAAC;AAAA,UACvF;AAAA,QACJ,OAAO;AACH,kBAAQ,KAAK,yBAAyB,YAAY,KAAK;AAAA,QAC3D;AAAA,MACJ;AAAA,IACJ;AAEA,WAAO;AAAA,MACH,IAAI,OAAO,WAAW;AAAA,MACtB,MAAM;AAAA,MACN,OAAO,OAAO,SAAS,OAAO,KAAK,IAAI,IAAI;AAAA,MAC3C,YAAY,KAAK;AAAA,KACrB;AAAA,EACJ;AAAA;AAAA,EAGA,eAAe;AACX,SAAK,QAAQ,OAAO,GAAG,KAAK,QAAQ,MAAM;AAC1C,WAAO;AAAA,EACX;AAAA;AAAA,EAGA,gBAAgB;AAAE,WAAO,MAAM;AAAA,EAAY;AAAA,EAC3C,cAAc;AAAE,WAAO,MAAM;AAAA,EAAU;AAAA,EACvC,aAAa;AAAE,WAAO,MAAM;AAAA,EAAS;AAAA,EACrC,aAAa;AAAE,WAAO,MAAM;AAAA,EAAS;AAAA;AAAA,EAGrC,YAAY,YAAoB;AAAE,WAAO,MAAM,aAAa,MAAM,UAAU;AAAA,EAAG;AACnF;AAKO,MAAM,oBAAoB,CAC7B,QACA,QACA,UACe;AACf,SAAO,IAAI;AAAA,IACP;AAAA,IACA,UAAU;AAAA,IACV;AAAA,IACA,SAAS;AAAA,GACb;AACJ;;ACtxBO,MAAM,yBAAyB,CAAC,iBAAyB,sBAAsC;AAClG,MAAI,CAAC,mBAAmB,MAAK,EAAG,OAAO;AAEvC,SAAO,GAAG,eAAe;;AAAA;;AAAA;AAAA,EAK3B,kBAAkB,MAAM;;AAAA;;AAAA;AAAA;AAM1B;AAKO,MAAM,qBAAqB;AAAA;;AAAA;AAAA;;AAAA;AAAA;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;;AAAA;AAAA;AA+C3B,MAAM,wBAAwB,MAAc;AAC/C,SAAO,MAAM,KAAK,KAAK,IAAI,KAAK,QAAO,CAAE,SAAS,EAAE,EAAE,MAAM,GAAG,CAAC,CAAC;AACrE;AAKO,MAAM,gCAAiE;AAAA,EAC1E;AAAA,IACI,OAAO;AAAA,IACP,aAAa;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;;AAAA;AAAA,IAiBb,SAAS;AAAA,IACT,OAAO;AAAA,GACX;AAAA,EACA;AAAA,IACI,OAAO;AAAA,IACP,aAAa;AAAA;AAAA;AAAA;;AAAA;AAAA;AAAA;AAAA;;AAAA;AAAA;AAAA;AAAA,IAab,SAAS;AAAA,IACT,OAAO;AAAA,GACX;AAAA,EACA;AAAA,IACI,OAAO;AAAA,IACP,aAAa;;AAAA;AAAA;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;;AAAA;AAAA;AAAA;AAAA;AAAA;;AAAA;AAAA,IA0Bb,SAAS;AAAA,IACT,OAAO;AAAA,GACX;AAAA,EACA;AAAA,IACI,OAAO;AAAA,IACP,aAAa;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;;AAAA;AAAA,IAWb,SAAS;AAAA,IACT,OAAO;AAAA,GACX;AAAA,EACA;AAAA,IACI,OAAO;AAAA,IACP,aAAa;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;;AAAA;AAAA;AAAA,IAWb,SAAS;AAAA,IACT,OAAO;AAAA,GACX;AAAA,EACA;AAAA,IACI,OAAO;AAAA,IACP,aAAa;;AAAA;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;;AAAA;AAAA;AAAA;AAAA,IAsBb,SAAS;AAAA,IACT,OAAO;AAAA,GACX;AAAA,EACA;AAAA,IACI,OAAO;AAAA,IACP,aAAa;AAAA,IACb,SAAS;AAAA,IACT,OAAO;AAAA,GACX;AAAA,EACA;AAAA,IACI,OAAO;AAAA,IACP,aAAa;AAAA,IACb,SAAS;AAAA,IACT,OAAO;AAAA,GACX;AAAA,EACA;AAAA,IACI,OAAO;AAAA,IACP,aAAa;AAAA,IACb,SAAS;AAAA,IACT,OAAO;AAAA,GACX;AAAA,EACA;AAAA,IACI,OAAO;AAAA,IACP,aAAa;AAAA,IACb,SAAS;AAAA,IACT,OAAO;AAAA,GACX;AAAA,EACA;AAAA,IACI,OAAO;AAAA,IACP,aAAa;AAAA,IACb,SAAS;AAAA,IACT,OAAO;AAAA;AAEf;;ACSO,MAAM,iBAAiB,MAA0C;AACpE,MAAI;AAEA,QAAI,OAAO,WAAW,eAAe,QAAQ,SAAS,IAAI;AACtD,aAAO;AAAA,IACX;AAGA,QAAI,OAAO,SAAS,eAAe,8BAA8B,MAAM;AACnE,aAAO;AAAA,IACX;AAGA,QAAI,OAAO,cAAc,eAAe,gBAAgB,WAAW;AAC/D,aAAO;AAAA,IACX;AAEA,WAAO;AAAA,EACX,QAAQ;AACJ,WAAO;AAAA,EACX;AACJ;AAGO,MAAM,iBAAiB,YAAY;AACtC,QAAM,WAAW,gBAAe;AAChC,UAAQ,IAAI,2BAA2B,QAAQ;AAE/C,MAAI;AACA,QAAI,aAAa,OAAO;AACpB,cAAQ,IAAI,8BAA8B;AAE1C,YAAM,WAAW,MAAM,cAAa;AACpC,cAAQ,IAAI,6BAA6B,CAAC,CAAC,UAAU,UAAU,KAAK,sBAAsB,cAAc;AACxG,aAAO;AAAA,IACX,OAAO;AACH,cAAQ,IAAI,2CAA2C;AAEvD,YAAM,WAAW,MAAM,oBAAmB;AAC1C,cAAQ,IAAI,iCAAiC,CAAC,CAAC,UAAU,UAAU,KAAK,sBAAsB,cAAc;AAC5G,aAAO;AAAA,IACX;AAAA,EACJ,SAAS,GAAG;AACR,YAAQ,MAAM,qDAAqD,QAAQ,KAAK,CAAC;AACjF,WAAO;AAAA,EACX;AACJ;AAGO,MAAM,6BAA6B,YAA6B;AACnE,MAAI;AAEA,UAAM,EAAE,0BAAyB,GAAI,6EAAM,gDAA8B;AACzE,WAAO,MAAM,0BAAyB;AAAA,EAC1C,QAAQ;AAEJ,QAAI;AACA,YAAM,EAAE,0BAAyB,GAAI,6EAAM,gDAA8B;AACzE,aAAO,MAAM,0BAAyB;AAAA,IAC1C,QAAQ;AACJ,aAAO;AAAA,IACX;AAAA,EACJ;AACJ;AAGA,MAAM,wBAA0D;AAAA,EAC5D,MAAM;AAAA;AAAA,EACN,IAAI;AAAA,EACJ,IAAI;AACR;AAEA,MAAM,wBAAwB;AAGvB,MAAM,yBAAyB,YAA6B;AAC/D,MAAI;AACA,UAAM,WAAW,MAAM,gBAAe;AACtC,UAAM,OAAO,UAAU,IAAI,oBAAoB;AAC/C,UAAM,YAAY,UAAU,IAAI,oBAAoB;AAEpD,QAAI,cAAc,sBAAsB,IAAI,KAAK;AACjD,QAAI,aAAa,SAAS,QAAQ;AAC9B,qBAAe;AAAA,IACnB;AACA,WAAO;AAAA,EACX,QAAQ;AACJ,WAAO;AAAA,EACX;AACJ;AAGO,MAAM,sBAAsB,YAA6B;AAC5D,MAAI;AACA,UAAM,WAAW,MAAM,gBAAe;AACtC,WAAO,UAAU,IAAI,sBAAsB,qBAAqB;AAAA,EACpE,QAAQ;AACJ,WAAO;AAAA,EACX;AACJ;AA6CA,MAAM,gBAAgB;AACtB,MAAM,kBAAkB;AAuIjB,MAAM,+BAA+B;AAAA;;AAAA;AAAA;AAAA;AAAA;;AAAA;AAAA;AAAA;AAAA;;AAAA;AAAA;AAAA;;AAAA;AAAA;AAuBrC,MAAM,yBAAyB;AAAA;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;;AAAA;AAAA;AAAA;AAAA;;AAAA;AAAA;AAmB/B,MAAM,0BAA0B;AAAA;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;;AAAA;AAAA;AAAA;AAAA;AAAA;;AAAA;AAAA;AAwBhC,MAAM,iBAAiB,OAAO,WAAoD;AACrF,UAAQ,IAAI,2CAA2C,KAAQ;AAC/D,QAAM,WAAW,MAAM,cAAa;AACpC,UAAQ,IAAI,yBAAyB,CAAC,CAAC,UAAU,UAAU,KAAK,wBAAwB,gBAAgB;AAExG,QAAM,SAA2B,UAAU,IAAI;AAC/C,UAAQ,IAAI,2BAA2B,CAAC,CAAC,MAAM;AAE/C,MAAI,CAAC,QAAQ;AACT,YAAQ,MAAM,wCAAwC;AACtD,WAAO;AAAA,EACX;AAEA,QAAM,UAA6B,UAAU,IAAI,WAAW;AAC5D,QAAM,QAAyB,UAAU,IAAI,SAAS;AACtD,UAAQ,IAAI,wCAAwC,SAAS,UAAU,KAAK;AAE5E,SAAO;AAAA,IACH;AAAA,IACA;AAAA,IACA;AAAA,GACJ;AACJ;AASO,MAAM,0BAA0B,OACnC,OACA,cACA,cACA,QACA,YAC0D;AAC1D,QAAM,YAAY,MAAM,cAAa,GAAI;AAEzC,QAAM,QAAQ,QAAQ,UAAU,UAAU;AAC1C,MAAI,CAAC,OAAO;AACR,UAAM,SAAS,EAAE,IAAI,OAAO,OAAO,uBAAsB;AACzD,mBAAe,MAAM;AACrB,WAAO;AAAA,EACX;AACA,MAAI,CAAC,OAAO;AACR,UAAM,SAAS,EAAE,IAAI,OAAO,OAAO,qBAAoB;AACvD,mBAAe,MAAM;AACrB,WAAO;AAAA,EACX;AAGA,MAAI,oBAAoB;AACxB,UAAQ,IAAI,oDAAoD,CAAC,CAAC,SAAS,iBAAiB;AAC5F,UAAQ,IAAI,yCAAyC,SAAS,oBAAoB;AAElF,MAAI,SAAS,mBAAmB;AAC5B,YAAQ,IAAI,mDAAmD;AAC/D,wBAAoB,uBAAuB,cAAc,QAAQ,iBAAiB;AAAA,EACtF,WAAW,SAAS,yBAAyB,OAAO;AAChD,YAAQ,IAAI,8DAA8D;AAC1E,UAAM,oBAAoB,MAAM,4BAA2B;AAC3D,YAAQ,IAAI,uCAAuC,oBAAoB,IAAI,kBAAkB,UAAU,GAAG,EAAE,CAAC,SAAS,QAAQ;AAC9H,QAAI,mBAAmB;AACnB,0BAAoB,uBAAuB,cAAc,iBAAiB;AAC1E,cAAQ,IAAI,mDAAmD;AAAA,IACnE;AAAA,EACJ,OAAO;AACH,YAAQ,IAAI,0DAA0D;AAAA,EAC1E;AAGA,QAAM,MAAM,kBAAkB,OAAO,QAAQ,WAAW,UAAU,WAAW,iBAAiB,QAAQ,SAAS,UAAU,SAAS,aAAa;AAG/I,MAAI,cAAa;AACjB,QAAM,IAAI,cAAc,iBAAiB;AAGzC,MAAI,MAAM,QAAQ,KAAK,MAAM,QAAQ,CAAC,GAAG,SAAS,aAAa,QAAQ,CAAC,IAAI,MAAM,IAAI;AAElF,UAAM,KAAK,cAAa,EAAG,OAAO,GAAG,KAAK;AAAA,EAC9C,OAAO;AAEH,UAAM,KAAK,kBAAkB,KAAK;AAAA,EACtC;AAGA,MAAI;AACJ,MAAI;AACJ,MAAI;AACA,eAAW,MAAM,KAAK,cAAc,OAAO,KAAK;AAAA,EACpD,SAAS,GAAG;AACR,YAAQ,OAAO,CAAC;AAAA,EACpB;AAEA,QAAM,SAAS;AAAA,IACX,IAAI,CAAC,CAAC,YAAY,CAAC;AAAA,IACnB,MAAM,UAAU,QAAO,IAAK;AAAA,IAC5B,OAAO,UAAU,WAAW,SAAY;AAAA,GAC5C;AAEA,iBAAe,MAAM;AACrB,SAAO;AACX;AAweO,MAAM,iBAAiB,OAC1B,OACA,YAC6B;AAC7B,UAAQ,IAAI,0CAA0C,OAAO,YAAY,GAAG,GAAG,KAAK,KAAK;AAEzF,QAAM,MAAM,MAAM,gBAAe;AACjC,UAAQ,IAAI,8BAA8B,CAAC,CAAC,GAAG;AAE/C,MAAI,CAAC,KAAK;AACN,YAAQ,MAAM,iEAAiE;AAC/E,WAAO,EAAE,IAAI,OAAO,iBAAiB,IAAI,mBAAmB,EAAC,EAAG,cAAc,IAAI,gBAAgB,MAAM,YAAY,GAAG,aAAa,WAAW,oBAAoB,GAAG,QAAQ,CAAC,0BAA0B,GAAG,UAAU,EAAC,EAAE;AAAA,EAC7N;AAEA,QAAM,YAAY,KAAK,KAAI;AAE3B,MAAI;AAEA,UAAM,sBAAsB,MAAM,wBAAuB;AACzD,UAAM,WAAW,MAAM,qBAAoB;AAC3C,UAAM,cAAc,+BAA+B,sBAAsB;AAGzE,QAAI,oBAAoB;AACxB,QAAI,SAAS,mBAAmB;AAC5B,0BAAoB,QAAQ;AAAA,IAChC,WAAW,SAAS,sBAAsB;AACtC,0BAAoB,MAAM,4BAA2B;AAAA,IACzD;AAEA,QAAI,mBAAmB;AACnB,YAAM,IAAI,cAAc,iBAAiB;AAAA,IAC7C;AAGA,UAAM,IAAI,cAAc,WAAW;AAGnC,UAAM,IAAI,eAAe,KAAK;AAG9B,YAAQ,IAAI,6DAA6D;AACzE,UAAM,cAAc,MAAM,IAAI,YAAY,QAAQ,QAAQ;AAC1D,UAAM,iBAAiB,KAAK,KAAI,GAAI;AAEpC,YAAQ,IAAI,+BAA+B,CAAC,CAAC,aAAa,aAAa,YAAY,GAAG,GAAG,KAAK,YAAY;AAE1G,QAAI,aAAa;AACb,cAAQ,IAAI,6BAA6B;AACzC,aAAO;AAAA,QACH,IAAI;AAAA,QACJ,iBAAiB,CAAC,WAAW;AAAA,QAC7B,mBAAmB,CAAC,YAAY,QAAQ;AAAA,QACxC,cAAc;AAAA,QACd,gBAAgB;AAAA,QAChB,YAAY;AAAA,QACZ,aAAa;AAAA,QACb,oBAAoB;AAAA,QACpB,QAAQ,EAAC;AAAA,QACT,UAAU;AAAC,OACf;AAAA,IACJ,OAAO;AACH,cAAQ,MAAM,2DAA2D;AACzE,aAAO;AAAA,QACH,IAAI;AAAA,QACJ,iBAAiB,EAAC;AAAA,QAClB,mBAAmB,EAAC;AAAA,QACpB,cAAc;AAAA,QACd,gBAAgB;AAAA,QAChB,YAAY;AAAA,QACZ,aAAa;AAAA,QACb,oBAAoB;AAAA,QACpB,QAAQ,CAAC,wBAAwB;AAAA,QACjC,UAAU;AAAC,OACf;AAAA,IACJ;AAAA,EACJ,SAAS,GAAG;AACR,WAAO;AAAA,MACH,IAAI;AAAA,MACJ,iBAAiB,EAAC;AAAA,MAClB,mBAAmB,EAAC;AAAA,MACpB,cAAc;AAAA,MACd,gBAAgB;AAAA,MAChB,YAAY;AAAA,MACZ,aAAa;AAAA,MACb,oBAAoB,KAAK,KAAI,GAAI;AAAA,MACjC,QAAQ,CAAC,OAAO,CAAC,CAAC;AAAA,MAClB,UAAU;AAAC,KACf;AAAA,EACJ;AACJ;AAGO,MAAM,YAAY,OACrB,OACA,YAC6B;AAC7B,QAAM,MAAM,MAAM,gBAAe;AACjC,MAAI,CAAC,KAAK,OAAO,EAAE,IAAI,OAAO,iBAAiB,EAAC,EAAG,mBAAmB,EAAC,EAAG,cAAc,IAAI,gBAAgB,MAAM,YAAY,GAAG,aAAa,WAAW,oBAAoB,GAAG,QAAQ,CAAC,0BAA0B,GAAG,UAAU,EAAC,EAAE;AAEnO,QAAM,YAAY,KAAK,KAAI;AAE3B,MAAI;AAEA,UAAM,sBAAsB,MAAM,wBAAuB;AACzD,UAAM,WAAW,MAAM,qBAAoB;AAC3C,UAAM,cAAc,yBAAyB,sBAAsB;AAGnE,QAAI,oBAAoB;AACxB,QAAI,SAAS,mBAAmB;AAC5B,0BAAoB,QAAQ;AAAA,IAChC,WAAW,SAAS,sBAAsB;AACtC,0BAAoB,MAAM,4BAA2B;AAAA,IACzD;AAEA,QAAI,mBAAmB;AACnB,YAAM,IAAI,cAAc,iBAAiB;AAAA,IAC7C;AAGA,UAAM,IAAI,cAAc,WAAW;AAGnC,UAAM,IAAI,eAAe,KAAK;AAG9B,UAAM,cAAc,MAAM,IAAI,YAAY,QAAQ,QAAQ;AAC1D,UAAM,iBAAiB,KAAK,KAAI,GAAI;AAEpC,QAAI,aAAa;AACb,aAAO;AAAA,QACH,IAAI;AAAA,QACJ,iBAAiB,CAAC,WAAW;AAAA,QAC7B,mBAAmB,CAAC,QAAQ,aAAa;AAAA,QACzC,cAAc;AAAA,QACd,gBAAgB;AAAA,QAChB,YAAY;AAAA,QACZ,aAAa;AAAA,QACb,oBAAoB;AAAA,QACpB,QAAQ,EAAC;AAAA,QACT,UAAU;AAAC,OACf;AAAA,IACJ,OAAO;AACH,aAAO;AAAA,QACH,IAAI;AAAA,QACJ,iBAAiB,EAAC;AAAA,QAClB,mBAAmB,EAAC;AAAA,QACpB,cAAc;AAAA,QACd,gBAAgB;AAAA,QAChB,YAAY;AAAA,QACZ,aAAa;AAAA,QACb,oBAAoB;AAAA,QACpB,QAAQ,CAAC,yBAAyB;AAAA,QAClC,UAAU;AAAC,OACf;AAAA,IACJ;AAAA,EACJ,SAAS,GAAG;AACR,WAAO;AAAA,MACH,IAAI;AAAA,MACJ,iBAAiB,EAAC;AAAA,MAClB,mBAAmB,EAAC;AAAA,MACpB,cAAc;AAAA,MACd,gBAAgB;AAAA,MAChB,YAAY;AAAA,MACZ,aAAa;AAAA,MACb,oBAAoB,KAAK,KAAI,GAAI;AAAA,MACjC,QAAQ,CAAC,OAAO,CAAC,CAAC;AAAA,MAClB,UAAU;AAAC,KACf;AAAA,EACJ;AACJ;AAGO,MAAM,aAAa,OACtB,OACA,YAC6B;AAC7B,QAAM,MAAM,MAAM,gBAAe;AACjC,MAAI,CAAC,KAAK,OAAO,EAAE,IAAI,OAAO,iBAAiB,EAAC,EAAG,mBAAmB,EAAC,EAAG,cAAc,IAAI,gBAAgB,MAAM,YAAY,GAAG,aAAa,WAAW,oBAAoB,GAAG,QAAQ,CAAC,0BAA0B,GAAG,UAAU,EAAC,EAAE;AAEnO,QAAM,YAAY,KAAK,KAAI;AAE3B,MAAI;AAEA,UAAM,sBAAsB,MAAM,wBAAuB;AACzD,UAAM,WAAW,MAAM,qBAAoB;AAC3C,UAAM,cAAc,0BAA0B,sBAAsB;AAGpE,QAAI,oBAAoB;AACxB,QAAI,SAAS,mBAAmB;AAC5B,0BAAoB,QAAQ;AAAA,IAChC,WAAW,SAAS,sBAAsB;AACtC,0BAAoB,MAAM,4BAA2B;AAAA,IACzD;AAEA,QAAI,mBAAmB;AACnB,YAAM,IAAI,cAAc,iBAAiB;AAAA,IAC7C;AAGA,UAAM,IAAI,cAAc,WAAW;AAGnC,UAAM,IAAI,eAAe,KAAK;AAG9B,UAAM,cAAc,MAAM,IAAI,YAAY,QAAQ,QAAQ;AAC1D,UAAM,iBAAiB,KAAK,KAAI,GAAI;AAEpC,QAAI,aAAa;AACb,aAAO;AAAA,QACH,IAAI;AAAA,QACJ,iBAAiB,CAAC,WAAW;AAAA,QAC7B,mBAAmB,CAAC,OAAO,UAAU,YAAY;AAAA,QACjD,cAAc;AAAA,QACd,gBAAgB;AAAA,QAChB,YAAY;AAAA,QACZ,aAAa;AAAA,QACb,oBAAoB;AAAA,QACpB,QAAQ,EAAC;AAAA,QACT,UAAU;AAAC,OACf;AAAA,IACJ,OAAO;AACH,aAAO;AAAA,QACH,IAAI;AAAA,QACJ,iBAAiB,EAAC;AAAA,QAClB,mBAAmB,EAAC;AAAA,QACpB,cAAc;AAAA,QACd,gBAAgB;AAAA,QAChB,YAAY;AAAA,QACZ,aAAa;AAAA,QACb,oBAAoB;AAAA,QACpB,QAAQ,CAAC,uBAAuB;AAAA,QAChC,UAAU;AAAC,OACf;AAAA,IACJ;AAAA,EACJ,SAAS,GAAG;AACR,WAAO;AAAA,MACH,IAAI;AAAA,MACJ,iBAAiB,EAAC;AAAA,MAClB,mBAAmB,EAAC;AAAA,MACpB,cAAc;AAAA,MACd,gBAAgB;AAAA,MAChB,YAAY;AAAA,MACZ,aAAa;AAAA,MACb,oBAAoB,KAAK,KAAI,GAAI;AAAA,MACjC,QAAQ,CAAC,OAAO,CAAC,CAAC;AAAA,MAClB,UAAU;AAAC,KACf;AAAA,EACJ;AACJ;AAYO,MAAM,mBAAmB;AAAA,EAS5B;AAAA,EAGA,uBAkBJ;;AC/7CA,MAAM,aAAa;AAEZ,MAAM,wBAAwB,YAA0C;AAC3E,QAAM,WAAW,MAAM,cAAa;AACpC,SAAO,UAAU,IAAI,sBAAsB,EAAC;AAChD;AAEO,MAAM,uBAAuB,YAA+C;AAC/E,MAAI;AACA,UAAM,WAAW,MAAM,cAAa;AACpC,UAAM,eAAe,UAAU,IAAI,sBAAsB,EAAC;AAC1D,UAAM,WAAW,UAAU,IAAI;AAE/B,YAAQ,IAAI,yDAAyD,QAAQ;AAC7E,YAAQ,IAAI,mEAAmE,aAAa,MAAM;AAElG,QAAI,CAAC,UAAU;AACX,cAAQ,IAAI,iDAAiD;AAC7D,aAAO;AAAA,IACX;AAEA,UAAM,SAAS,aAAa,KAAK,OAAK,EAAE,OAAO,QAAQ;AACvD,QAAI,QAAQ;AACR,cAAQ,IAAI,kDAAkD,OAAO,KAAK;AAAA,IAC9E,OAAO;AACH,cAAQ,KAAK,uEAAuE,QAAQ;AAC5F,cAAQ,IAAI,uCAAuC,aAAa,IAAI,OAAK,EAAE,EAAE,CAAC;AAAA,IAClF;AAEA,WAAO,UAAU;AAAA,EACrB,SAAS,GAAG;AACR,YAAQ,MAAM,uDAAuD,CAAC;AACtE,WAAO;AAAA,EACX;AACJ;AAEO,MAAM,2BAA2B,YAA6B;AACjE,QAAM,cAAc,MAAM,sBAAqB;AAC/C,QAAM,OAAO,aAAa,eAAe;AACzC,UAAQ,IAAI,kDAAkD,OAAO,IAAI,KAAK,UAAU,GAAG,EAAE,CAAC,SAAS,SAAS;AAChH,SAAO;AACX;AAEO,MAAM,uBAAuB,OAAO,OAAqC;AAC5E,QAAM,WAAW,MAAM,cAAa;AACpC,QAAM,UAAuB;AAAA,IACzB,GAAG;AAAA,IACH,IAAI;AAAA,MACA,GAAG,SAAS;AAAA,MACZ,qBAAqB,MAAM;AAAA;AAC/B,GACJ;AACA,QAAM,aAAa,OAAO;AAC9B;AAEO,MAAM,iBAAiB,OAAO,OAAe,gBAAoD;AACpG,QAAM,WAAW,MAAM,cAAa;AACpC,QAAM,eAAe,UAAU,IAAI,sBAAsB,EAAC;AAE1D,QAAM,iBAAoC;AAAA,IACtC,IAAI,YAAW;AAAA,IACf,OAAO,MAAM,MAAK,IAAK;AAAA,IACvB,aAAa,YAAY,MAAK;AAAA,IAC9B,SAAS;AAAA,IACT,OAAO,aAAa;AAAA,GACxB;AAEA,QAAM,UAAuB;AAAA,IACzB,GAAG;AAAA,IACH,IAAI;AAAA,MACA,GAAG,SAAS;AAAA,MACZ,oBAAoB,CAAC,GAAG,cAAc,cAAc;AAAA;AACxD,GACJ;AAEA,QAAM,aAAa,OAAO;AAC1B,SAAO;AACX;AAKO,MAAM,kBAAkB,OAC3B,UAC+B;AAC/B,MAAI,CAAC,MAAM,QAAQ,OAAO,EAAC;AAE3B,QAAM,WAAW,MAAM,cAAa;AACpC,QAAM,eAAe,UAAU,IAAI,sBAAsB,EAAC;AAE1D,QAAM,kBAAuC,MAAM,IAAI,CAAC,MAAM,WAAW;AAAA,IACrE,IAAI,YAAW;AAAA,IACf,OAAO,KAAK,MAAM,MAAK,IAAK;AAAA,IAC5B,aAAa,KAAK,YAAY,MAAK;AAAA,IACnC,SAAS,KAAK,WAAW;AAAA,IACzB,OAAO,aAAa,SAAS;AAAA,GACjC,CAAE;AAEF,QAAM,UAAuB;AAAA,IACzB,GAAG;AAAA,IACH,IAAI;AAAA,MACA,GAAG,SAAS;AAAA,MACZ,oBAAoB,CAAC,GAAG,cAAc,GAAG,eAAe;AAAA;AAC5D,GACJ;AAEA,QAAM,aAAa,OAAO;AAC1B,SAAO;AACX;AAEO,MAAM,oBAAoB,OAAO,IAAY,YAAsE;AACtH,QAAM,WAAW,MAAM,cAAa;AACpC,QAAM,eAAe,UAAU,IAAI,sBAAsB,EAAC;AAC1D,QAAM,QAAQ,aAAa,UAAU,OAAK,EAAE,OAAO,EAAE;AAErD,MAAI,UAAU,IAAI,OAAO;AAEzB,eAAa,KAAK,IAAI,EAAE,GAAG,aAAa,KAAK,GAAG,GAAG,SAAQ;AAE3D,QAAM,UAAuB;AAAA,IACzB,GAAG;AAAA,IACH,IAAI;AAAA,MACA,GAAG,SAAS;AAAA,MACZ,oBAAoB;AAAA;AACxB,GACJ;AAEA,QAAM,aAAa,OAAO;AAC1B,SAAO;AACX;AAEO,MAAM,oBAAoB,OAAO,OAAiC;AACrE,QAAM,WAAW,MAAM,cAAa;AACpC,QAAM,eAAe,UAAU,IAAI,sBAAsB,EAAC;AAC1D,QAAM,WAAW,aAAa,OAAO,OAAK,EAAE,OAAO,EAAE;AAErD,MAAI,SAAS,WAAW,aAAa,QAAQ,OAAO;AAGpD,QAAM,cAAc,SAAS,IAAI,wBAAwB,KAAK,KAAM,SAAS,IAAI,uBAAuB;AAExG,QAAM,UAAuB;AAAA,IACzB,GAAG;AAAA,IACH,IAAI;AAAA,MACA,GAAG,SAAS;AAAA,MACZ,oBAAoB;AAAA,MACpB,qBAAqB;AAAA;AACzB,GACJ;AAEA,QAAM,aAAa,OAAO;AAC1B,SAAO;AACX","names":["isValidParent","theirParent","byOldEl","attr","el","binary","MAX_FILE_SIZE","URL","errorMessage"],"ignoreList":[4],"sources":["../../../../modules/projects/lur.e/src/lure/node/Mapped.ts","../../../../modules/projects/lur.e/src/lure/node/Normalizer.ts","../../../../modules/projects/lur.e/src/lure/node/Syntax.ts","../../src/core/config/RuntimeSettings.ts","../../../../node_modules/@toon-format/toon/dist/index.mjs","../../src/core/service/model/GPT-Config.ts","../../src/core/utils/AIResponseParser.ts","../../src/core/service/model/GPT-Responses.ts","../../src/core/service/InstructionUtils.ts","../../src/core/service/AI-ops/RecognizeData.ts","../../src/core/service/CustomInstructions.ts"],"sourcesContent":["import { iterated } from \"fest/object\";\nimport { $mapped } from \"../core/Binding\";\nimport { getNode, appendFix, removeNotExists } from \"../context/Utils\";\nimport { makeUpdater, reformChildren } from \"../context/ReflectChildren\";\nimport { canBeInteger, isObservable, isPrimitive, isHasPrimitives } from \"fest/core\";\nimport { isValidParent } from \"fest/dom\";\n\n//\ninterface MappedOptions {\n    uniquePrimitives?: boolean;\n    removeNotExistsWhenHasPrimitives?: boolean;\n    boundParent?: Node | null;\n    preMap?: boolean;\n}\n\n//\nconst asArray = (children)=>{\n    if (children instanceof Map || children instanceof Set) {\n        children = Array.from(children?.values?.());\n    }\n    return children;\n}\n\n//\nclass Mp {\n    #observable?: any[];\n    #fragments: DocumentFragment;\n    #mapCb: any;\n    #reMap: WeakMap<any, any>;\n    #pmMap: Map<any, any>;\n    #updater: any = null;\n    #internal: any = null;\n    #options: MappedOptions = {} as MappedOptions;\n    #stub = document.createComment(\"\");\n\n    //\n    #boundParent: Node | null = null;\n\n    //\n    makeUpdater(basisParent: Node | null = null) {\n        if (basisParent) {\n            this.#internal?.(); this.#internal = null; this.#updater = null;\n            this.#updater ??= makeUpdater(basisParent, this.mapper.bind(this), Array.isArray(this.#observable));\n            this.#internal ??= iterated?.(this.#observable, this._onUpdate.bind(this));\n        }\n    }\n\n    //\n    get boundParent() {\n        return this.#boundParent;\n    }\n    set boundParent(value: Node | null) {\n        if (value instanceof HTMLElement && isValidParent(value) && value != this.#boundParent) {\n            this.#boundParent = value; this.makeUpdater(value); const element = this.element;\n            //if (element && element instanceof DocumentFragment) { appendFix(this.#boundParent, element); };\n        }\n    }\n\n    //\n    constructor(observable, mapCb: any = (el) => el, options: Node | null | MappedOptions = /*{ removeNotExistsWhenHasPrimitives: true, uniquePrimitives: true, preMap: true } as MappedOptions*/ null) {\n        // swap arguments (JSX compatibility)\n        if (isObservable(mapCb) && ((typeof observable == \"function\" || typeof observable == \"object\") && !isObservable(observable))) {\n            [observable, mapCb] = [mapCb, observable] as [any, any];\n        }\n\n        // may be unified with options, if isn't exists (JSX compatibility)\n        if (!options && (mapCb != null && typeof mapCb == \"object\") && !isObservable(mapCb)) {\n            options = mapCb as MappedOptions;\n        }\n\n        //\n        this.#stub = document.createComment(\"\");\n        this.#reMap = new WeakMap();\n        this.#pmMap = new Map<any, any>(); // make 'mapper' compatible with React syntax ('mapper' property instead of function)\n        this.#mapCb = (mapCb != null ? (typeof mapCb == \"function\" ? mapCb : (typeof mapCb == \"object\" ? mapCb?.mapper : null)) : null) ?? ((el) => el);\n        this.#observable = (isObservable(observable) ? observable : (observable?.iterator ?? mapCb?.iterator ?? observable)) ?? [];\n        this.#fragments = document.createDocumentFragment();\n\n        //\n        const $baseOptions = { removeNotExistsWhenHasPrimitives: true, uniquePrimitives: true, preMap: true } as MappedOptions;\n        const $newOptions = (isValidParent(options as any) ? null : (options as MappedOptions|null)) || {};\n        this.#options = Object.assign($baseOptions, $newOptions);\n\n        //\n        this.boundParent = isValidParent(this.#options?.boundParent as any) ?? (isValidParent(options as any) ?? null);\n        if (!this.boundParent) {\n            if (this.#options.preMap) {\n                reformChildren(\n                    this.#fragments, this.#observable,\n                    this.mapper.bind(this)\n                );\n                if (this.#fragments.childNodes.length === 0) {\n                    this.#fragments.appendChild(this.#stub);\n                }\n            }\n        }\n    }\n\n    //\n    get [$mapped]() { return true; }\n\n    //\n    elementForPotentialParent(requestor: any) {\n        Promise.try(() => {\n            const element = getNode(this.#observable?.[0], this.mapper.bind(this), 0);\n            if (!element || !requestor || element?.contains?.(requestor) || requestor == element) {\n                return;\n            }\n            if (requestor instanceof HTMLElement && isValidParent(requestor)) {\n                if (Array.from(requestor?.children).find((node) => node === element)) {\n                    this.boundParent = requestor;\n                } else {\n                    const observer = new MutationObserver((records) => {\n                        for (const record of records) {\n                            if (record.type === \"childList\") {\n                                if (record.addedNodes.length > 0) {\n                                    const connectedNode = Array.from((record.addedNodes as any) || []).find((node) => node === element);\n                                    if (connectedNode) {\n                                        this.boundParent = requestor;\n                                        observer.disconnect();\n                                    }\n                                }\n                            }\n                        }\n                    });\n                    observer.observe(requestor, { childList: true });\n                }\n            }\n        })?.catch?.(console.warn.bind(console));\n\n        //\n        return this.element;\n    }\n\n    //\n    get children() { return asArray(this.#observable); }\n\n    //\n    get self(): HTMLElement | DocumentFragment | Text | null {\n        const existsNode = getNode(this.#observable?.[0], this.mapper.bind(this), 0);\n        const theirParent = isValidParent(existsNode?.parentElement) ? existsNode?.parentElement : this.boundParent;\n        this.boundParent ??= isValidParent(theirParent) ?? this.boundParent;\n\n        //\n        queueMicrotask(() => {\n            const theirParent = isValidParent(existsNode?.parentElement) ? existsNode?.parentElement : this.boundParent;\n            this.boundParent ??= isValidParent(theirParent) ?? this.boundParent;\n        });\n\n        //\n        return (theirParent ?? this.boundParent ?? (reformChildren(\n            this.#fragments, this.#observable,\n            this.mapper.bind(this)\n        )));\n    }\n\n    //\n    get element(): HTMLElement | DocumentFragment | Text | null {\n        const children = this.#fragments?.childNodes?.length > 0 ? this.#fragments : getNode(this.#observable?.[0], this.mapper.bind(this), 0);\n        const theirParent = isValidParent(children?.parentElement) ? children?.parentElement : this.boundParent;\n        this.boundParent ??= isValidParent(theirParent) ?? this.boundParent;\n\n        //\n        queueMicrotask(() => {\n            const theirParent = isValidParent(children?.parentElement) ? children?.parentElement : this.boundParent;\n            this.boundParent ??= isValidParent(theirParent) ?? this.boundParent;\n        });\n\n        //\n        return children;\n    }\n\n    //\n    get mapper() {\n        return (...args) => {\n            if (args?.[0] instanceof Node) { return args?.[0]; };\n\n            // unsupported\n            if (args?.[0] instanceof Promise || typeof (args?.[0] as any)?.then == \"function\") { return null; };\n\n            //\n            if (\n                (args?.[1] == null || args?.[1] < 0 || (typeof args?.[1] != \"number\" || !canBeInteger(args?.[1] as any))) &&\n                (Array.isArray(this.#observable) || ((this.#observable as any) instanceof Set))\n            ) { return; }\n\n            //\n            if (args?.[0] != null && (typeof args?.[0] == \"object\" || typeof args?.[0] == \"function\" || typeof args?.[0] == \"symbol\")) // @ts-ignore\n                { return this.#reMap.getOrInsert(args?.[0], this.#mapCb(...args)); }\n\n            // prevalence of Set typed\n            if (args?.[0] != null && this.#observable instanceof Set) // @ts-ignore\n                { return this.#pmMap.getOrInsert(args?.[0], this.#mapCb(...args)); }\n\n            // prevalence of Map typed\n            if (args?.[0] != null && this.#observable instanceof Map) {\n                // unique value in map\n                if (typeof args?.[0] == \"object\" || typeof args?.[0] == \"function\" || typeof args?.[0] == \"symbol\") // @ts-ignore\n                    { return this.#reMap.getOrInsert(args?.[0], this.#mapCb(...args)); } else\n                // unique key in map (objects)\n                if (typeof args?.[1] == \"object\" || typeof args?.[1] == \"function\" || typeof args?.[1] == \"symbol\") // @ts-ignore\n                    { return this.#reMap.getOrInsert(args?.[1], this.#mapCb(...args)); } else // @ts-ignore\n                    { return this.#pmMap.getOrInsert(args?.[1], this.#mapCb(...args)); }\n            }\n\n            // array may has same values twice, no viable solution...\n            if (args?.[0] != null) {\n                if (this.#options?.uniquePrimitives && isPrimitive(args?.[0])) // @ts-ignore\n                    { return this.#pmMap.getOrInsert(args?.[0], this.#mapCb(...args)); } else\n                    { return this.#mapCb(...args); }\n            }\n        }\n    }\n\n    //\n    _onUpdate(newEl, idx, oldEl, op: string | null = \"\") {\n        // keep cache clear from garbage (unique primitives mode)\n        if ((op == \"@remove\" || op == \"@set\") && isPrimitive(oldEl) && oldEl != newEl && this.#options?.uniquePrimitives)\n            { this.#pmMap.delete(oldEl); }\n\n        //\n        const __mapped = asArray(this.#observable); const __keys = Array.from(this.#observable?.keys?.() || []);\n        if (Array.isArray(__mapped) && (this.#options?.removeNotExistsWhenHasPrimitives ? (isHasPrimitives(__mapped) || isPrimitive(oldEl)) : false) && __mapped?.length < 1)\n            { removeNotExists(this.boundParent, __mapped?.map?.((nd, index) => getNode(nd, this.mapper, __keys?.[index] ?? index, this.boundParent)) || []); }\n\n        //\n        const isEmpty = !__mapped || __mapped.length === 0;\n\n        // Don't give (rights) to remove last remain element (DOM), and (instead of) replace it just by `#stub`\n        if (op === \"@remove\" && isEmpty) {\n            const byOldEl = getNode(oldEl, this.mapper, Number.isInteger(idx) ? idx : -1);\n            if (this.#stub.parentNode !== this.boundParent) {\n                if (byOldEl && this.boundParent && byOldEl.parentNode === this.boundParent) {\n                    this.boundParent.replaceChild(this.#stub, byOldEl);\n                } else if (this.boundParent && !this.boundParent.hasChildNodes()) {\n                    this.boundParent.appendChild(this.#stub);\n                }\n            }\n        }\n\n        //\n        const byOldEl = getNode(oldEl, this.mapper, Number.isInteger(idx) ? idx : -1);\n        const try0 = Array.from(((byOldEl?.parentNode ?? this.boundParent) as any)?.childNodes || [])?.indexOf?.(byOldEl);\n        const try1 = __mapped?.indexOf?.(newEl);\n        const byNewEl = getNode(newEl, this.mapper, Number.isInteger(idx) ? idx : (try1 < 0 ? idx : try1), this.boundParent);\n\n        //\n        const res = this.#updater?.(\n            byNewEl, Number.isInteger(idx) ? idx : (try0 < 0 ? try1 : try0),\n            byOldEl,\n            op || (Array.isArray(this.#observable) ? \"@add\" : \"\"),\n            this.boundParent);\n\n        //\n        if (!isEmpty && this.#stub.isConnected) { this.#stub.remove(); }\n        return res;\n    }\n\n    // generator and iterator\n    *[Symbol.iterator]() {\n        let i=0;\n        if (this.#observable) {\n            for (let el of this.#observable)\n                { yield this.mapper(el, i++); }\n        }\n        return;\n    }\n}\n\n//\nexport const M = (observable, mapCb?, boundParent: Node | null | MappedOptions = null) => {\n    return new Mp(observable, mapCb, boundParent);\n};\n\n//\nexport default M;\n","\n//\nexport function getIndentColumns(line: string, tabWidth = 4): number {\n    let col = 0;\n    for (let i = 0; i < line.length; i++) {\n        const ch = line[i];\n        if (ch === ' ') col += 1;\n        else if (ch === '\\t') col += tabWidth - (col % tabWidth);\n        else break;\n    }\n    return col;\n}\n\n//\nexport function stripIndentColumns(line: string, columns: number, tabWidth = 4): string {\n    let col = 0, i = 0;\n    while (i < line.length && col < columns) {\n        const ch = line[i];\n        if (ch === ' ') { col += 1; i++; }\n        else if (ch === '\\t') { col += tabWidth - (col % tabWidth); i++; }\n        else break;\n    }\n    return line.slice(i);\n}\n\n//\nexport function pickEOL(s: string): string {\n    if (s.includes('\\r\\n')) return '\\r\\n';\n    if (s.includes('\\r')) return '\\r';\n    return '\\n';\n}\n\n//\nexport function gcd(a: number, b: number): number {\n    a = Math.abs(a); b = Math.abs(b);\n    while (b) [a, b] = [b, a % b];\n    return a;\n}\n\n//\nexport function detectIndentStep(\n    text: string,\n    { ignoreFirstLine = true, tabWidth = 4 } = {}\n): { min: number; step: number; allEven: boolean; allDiv4: boolean } {\n    const lines = text.split(/\\r\\n|\\n|\\r/);\n    const start = ignoreFirstLine ? 1 : 0;\n\n    const indents: number[] = [];\n    for (let i = start; i < lines.length; i++) {\n        const ln = lines[i];\n        if (ln.trim() === '') continue;\n        indents.push(getIndentColumns(ln, tabWidth));\n    }\n    if (indents.length === 0) return { min: 0, step: 0, allEven: true, allDiv4: true };\n\n    const min = Math.min(...indents);\n    const shifted = indents.map(v => v - min).filter(v => v > 0);\n    let step = 0;\n    for (const v of shifted) step = step ? gcd(step, v) : v;\n\n    const allEven = indents.every(v => v % 2 === 0);\n    const allDiv4 = indents.every(v => v % 4 === 0);\n\n    //  :  4,  2,  1\n    if (step === 0) {\n        //   ;    \n        step = allDiv4 ? 4 : allEven ? 2 : 1;\n    } else {\n        if (step % 4 === 0) step = 4;\n        else if (step % 2 === 0) step = 2;\n        else step = 1;\n    }\n\n    return { min, step, allEven, allDiv4 };\n}\n\n//\nexport function adjustIndentToGrid(\n    line: string,\n    step: number,\n    mode: 'floor' | 'nearest' | 'ceil' = 'floor',\n    tabWidth = 4\n): string {\n    if (!step || step <= 1) return line; //     1n\n    const cur = getIndentColumns(line, tabWidth);\n    if (cur === 0) return line; //  \n    let target: number;\n    if (mode === 'nearest') target = Math.round(cur / step) * step;\n    else if (mode === 'ceil') target = Math.ceil(cur / step) * step;\n    else target = Math.floor(cur / step) * step;\n\n    const delta = cur - target;\n    if (delta > 0) {\n        //    delta \n        return stripIndentColumns(line, delta, tabWidth);\n    } else if (delta < 0) {\n        //   (  )  \n        return ' '.repeat(-delta) + line;\n    }\n    return line;\n}\n\n//\nexport function normalizeStartTagWhitespace(\n    html: string,\n    { scope = 'void-only' as 'void-only' | 'input-only' | 'all' } = {}\n): string {\n    if (!html || typeof html !== 'string') return html;\n\n    const VOID = new Set([\n        'area', 'base', 'br', 'col', 'embed', 'hr', 'img', 'input', 'link', 'meta',\n        'param', 'source', 'track', 'wbr'\n    ]);\n\n    let out = '';\n    let i = 0;\n    const n = html.length;\n\n    while (i < n) {\n        const ch = html[i];\n        if (ch !== '<') { out += ch; i++; continue; }\n\n        //  <!-- ... -->\n        if (html.startsWith('<!--', i)) {\n            const end = html.indexOf('-->', i + 4);\n            if (end === -1) { out += html.slice(i); break; }\n            out += html.slice(i, end + 3);\n            i = end + 3;\n            continue;\n        }\n        // DOCTYPE/DECL/CDATA/PI\n        if (html[i + 1] === '!' || html[i + 1] === '?') {\n            const end = html.indexOf('>', i + 2);\n            if (end === -1) { out += html.slice(i); break; }\n            out += html.slice(i, end + 1);\n            i = end + 1;\n            continue;\n        }\n        //  \n        if (html[i + 1] === '/') {\n            const end = html.indexOf('>', i + 2);\n            if (end === -1) { out += html.slice(i); break; }\n            out += html.slice(i, end + 1);\n            i = end + 1;\n            continue;\n        }\n\n        //  \n        let j = i + 1;\n        //    \"<\"\n        while (j < n && /\\s/.test(html[j])) j++;\n        const nameStart = j;\n        while (j < n && /[A-Za-z0-9:-]/.test(html[j])) j++;\n        const tagName = html.slice(nameStart, j).toLowerCase();\n        //      \n        let k = j;\n        let quote: '\"' | \"'\" | null = null;\n        while (k < n) {\n            const c = html[k];\n            if (quote) {\n                if (c === quote) quote = null;\n                k++;\n            } else {\n                if (c === '\"' || c === \"'\") { quote = c as '\"' | \"'\"; k++; }\n                else if (c === '>') { break; }\n                else { k++; }\n            }\n        }\n        if (k >= n) { out += html.slice(i); break; }\n        const rawTag = html.slice(i, k + 1); //  '>'\n\n        const shouldNormalize =\n            scope === 'all' ||\n            (scope === 'input-only' && tagName === 'input') ||\n            (scope === 'void-only' && VOID.has(tagName));\n\n        if (!shouldNormalize) {\n            out += rawTag;\n            i = k + 1;\n            continue;\n        }\n\n        //     ( )\n        let res = '';\n        let q: '\"' | \"'\" | null = null;\n        let ws = false;\n        for (let p = 0; p < rawTag.length; p++) {\n            const c = rawTag[p];\n            if (q) {\n                res += c;\n                if (c === q) q = null;\n                continue;\n            }\n            if (c === '\"' || c === \"'\") { q = c as '\"' | \"'\"; res += c; ws = false; continue; }\n            if (c === '\\n' || c === '\\r' || c === '\\t' || c === ' ') {\n                if (!ws) { res += ' '; ws = true; }\n                continue;\n            }\n            res += c;\n            ws = false;\n        }\n        //    '>'  '/>'\n        res = res.replace(/\\s*(\\/?)\\s*>$/, '$1>');\n\n        out += res;\n        i = k + 1;\n    }\n\n    return out;\n}\n\n//\nexport function collapseInterTagWhitespaceSmart(\n    html: string,\n    { preserveCommentGaps = true } = {}\n): string {\n    if (!html || typeof html !== 'string') return html;\n\n    if (!preserveCommentGaps) {\n        //  \n        return html.replace(/>\\s+</g, '><');\n    }\n\n    //  - \n    const SENT = '\\u0001';\n\n    let s = html;\n\n    // 1)  -   :\n    //    <!-- -->  <!-- -->,  <!-- -->  <tag,  <tag>  <!-- -->\n    //    [^\\S\\r\\n]+     (  )\n    s = s\n        .replace(/-->([^\\S\\r\\n]+)<!--/g, `-->${SENT}<!--`)\n        .replace(/-->([^\\S\\r\\n]+)</g, `-->${SENT}<`)\n        .replace(/>([^\\S\\r\\n]+)<!--/g, `>${SENT}<!--`);\n\n    // 2)     (   )\n    s = s.replace(/>\\s+</g, '><');\n\n    // 3)    ,   \n    s = s.replace(new RegExp(SENT, 'g'), ' ');\n\n    return s;\n}\n\n//\nexport function cleanupInterTagWhitespaceAndIndent(\n    html: string,\n    {\n        normalizeIndent = true,          //    \n        ignoreFirstLine = true,          //      \n        tabWidth = 4,                    //    \n        alignStep = 'auto' as 'auto' | 1 | 2 | 4, //  2n/4n/1n\n        quantize = 'none' as 'none' | 'floor' | 'nearest' | 'ceil', //   \n    } = {}\n): string {\n    if (!html || typeof html !== 'string' || html.indexOf('<') === -1) return html;\n    html = html?.trim?.();\n\n    //\n    const placeholders: string[] = [];\n    const protectedHtml = html.replace(\n        /<(pre|textarea|script|style)\\b[\\s\\S]*?<\\/\\1>/gi,\n        (m) => {\n            const i = placeholders.push(m) - 1;\n            return `\\u0000${i}\\u0000`;\n        }\n    );\n\n    const eol = pickEOL(protectedHtml);\n    const lines = protectedHtml.split(/\\r\\n|\\n|\\r/);\n    const start = ignoreFirstLine ? 1 : 0;\n\n    // 1)     \n    const { min, step: autoStep } = detectIndentStep(protectedHtml, { ignoreFirstLine, tabWidth });\n\n    // 2) Dedent:    \n    if (normalizeIndent && min > 0) {\n        for (let i = start; i < lines.length; i++) {\n            const ln = lines[i];\n            if (ln.trim() === '') continue;\n            lines[i] = stripIndentColumns(ln, min, tabWidth);\n        }\n    }\n\n    // 3)    2n/4n  \n    let step = alignStep === 'auto' ? autoStep : alignStep;\n    if (quantize !== 'none' && step > 1) {\n        for (let i = start; i < lines.length; i++) {\n            const ln = lines[i];\n            if (ln.trim() === '') continue;\n            lines[i] = adjustIndentToGrid(ln, step, quantize, tabWidth);\n        }\n    }\n\n    // 4)     / \n    let working = lines.join(eol);\n\n    // 5) ...dedent/\n    working = normalizeStartTagWhitespace(working, { scope: 'void-only' });\n\n    // 6)   \n    working = collapseInterTagWhitespaceSmart(working);\n\n    // 7)   \n    const cleaned = working.replace(/\\u0000(\\d+)\\u0000/g, (_, i) => placeholders[+i]);\n    return cleaned?.trim?.();\n}\n\n//\nexport function checkInsideTagBlock(contextParts: string[], ...str: string[]) {\n    const current = str?.[0] ?? \"\";\n    const idx = contextParts.indexOf(current);\n    // Fallback simple heuristic if index not found\n    if (idx < 0) {\n        const tail = (str?.join?.(\"\") ?? \"\");\n        return /<([A-Za-z\\/!?])[\\w\\W]*$/.test(tail) && !/>[\\w\\W]*$/.test(tail);\n    }\n\n    // Scan all static parts up to and including the current part\n    const prefix = contextParts.slice(0, idx + 1).join(\"\");\n    let inTag = false, inSingle = false, inDouble = false;\n\n    for (let i = 0; i < prefix.length; i++) {\n        const ch = prefix[i];\n        const next = prefix[i + 1] ?? '';\n\n        if (!inTag) {\n            if (ch === '<') {\n                // Treat as a tag only if followed by a likely opener: letter, '/', '!', or '?'\n                if (/[A-Za-z\\/!?]/.test(next)) {\n                    inTag = true; inSingle = false; inDouble = false;\n                }\n            }\n            continue;\n        }\n\n        if (!inSingle && !inDouble) {\n            if (ch === '\"') { inDouble = true; continue; }\n            if (ch === \"'\") { inSingle = true; continue; }\n            if (ch === '>') { inTag = false; continue; }\n        } else if (inDouble) {\n            if (ch === '\"') { inDouble = false; continue; }\n        } else if (inSingle) {\n            if (ch === \"'\") { inSingle = false; continue; }\n        }\n    }\n\n    return inTag;\n}\n","import { bindEvent, hasValue, isPrimitive } from \"fest/core\";\nimport { getNode } from \"../context/Utils\";\nimport { E } from \"./Bindings\";\nimport { M } from \"./Mapped\";\nimport { isElement } from \"fest/dom\";\nimport { checkInsideTagBlock, cleanupInterTagWhitespaceAndIndent } from \"./Normalizer\";\n\n//\nconst EMap = new WeakMap(), parseTag = (str) => { const match = str.match(/^([a-zA-Z0-9\\-]+)?(?:#([a-zA-Z0-9\\-_]+))?((?:\\.[a-zA-Z0-9\\-_]+)*)$/); if (!match) return { tag: str, id: null, className: null }; const [, tag = 'div', id, classStr] = match; const className = classStr ? classStr.replace(/\\./g, ' ').trim() : null; return { tag, id, className }; }\nconst preserveWhitespaceTags = new Set([\"PRE\", \"TEXTAREA\", \"SCRIPT\", \"STYLE\"]);\n\n//\nconst parseIndex = (value: string | any | null): number => {\n    if (typeof value != \"string\" || !value?.trim?.()) return -1;\n    const match = value.match(/^#{(\\d+)}$/);\n    return match ? parseInt(match?.[1] ?? \"-1\") : -1;\n}\n\n//\nconst connectElement = (el: HTMLElement | null, atb: any[], psh: any[], mapped: WeakMap<HTMLElement, any>) => {\n    if (!el) return el;\n    if (el != null) {\n        const entriesIdc: [string, number][] = [];\n        const addEntryIfExists = (name: string): [string, any] => {\n            const attr = Array.from(el?.attributes || []).find((attr) => (attr.name == name && attr.value?.includes?.(\"#{\")));\n            if (attr) {\n                const pair: [string, any] = [name, parseIndex(attr?.value) ?? -1];\n                entriesIdc.push(pair); return pair;\n            }\n            return [name, -1];\n        }\n\n        //\n        const specialEntryNames = [\"dataset\", \"style\", \"classList\", \"visible\", \"aria\", \"value\", \"ref\"];\n        specialEntryNames.forEach((name) => addEntryIfExists(name));\n\n        //\n        const makeEntries = (startsWith: string[] | string, except: string[] | string): [string, any][] => {\n            const entries: [string, any][] = [];\n            for (const attr of Array.from(el?.attributes || [])) {\n                // needs review startsWith with \"\" i.e. attributes itself, just #{}\n                const allowedNoPrefix: boolean = (Array.isArray(startsWith) ? startsWith?.some?.((str: string)=>str==\"\") : (startsWith == \"\"));\n                const prefix: string = (Array.isArray(startsWith) ? startsWith.find((start) => attr.name?.startsWith?.(start)) : (startsWith = attr.name?.startsWith?.(startsWith) ? startsWith : \"\") as string) ?? \"\";\n                const trueAttributeName = attr.name.trim()?.replace?.(prefix, \"\");\n                const isPlaceholder = attr.value?.includes?.(\"#{\") && attr.value?.includes?.(\"}\");\n                const atbIndex = parseIndex(attr?.value);\n                const excepted: boolean = (Array.isArray(except) ? except?.some?.((str: string)=>trueAttributeName?.startsWith?.(str)) : (except == trueAttributeName));\n\n                if (isPlaceholder && ((prefix == \"\" && allowedNoPrefix) || prefix != \"\") && atbIndex >= 0 && !excepted) {\n                    entries.push([trueAttributeName, atbIndex]);\n                }\n            }\n            return entries;\n        }\n\n        //\n        const makeCumulativeEntries = (startsWith: string[] | string, except: string[] | string, specific: string[] | string = \"\") => {\n            const entriesMap = new Map<string, any[]>();\n            for (const attr of Array.from(el?.attributes || [])) {\n                const allowedNoPrefix: boolean = (Array.isArray(startsWith) ? startsWith?.some?.((str: string)=>str==\"\") : (startsWith == \"\"));\n                const prefix: string = (Array.isArray(startsWith) ? startsWith.find((start) => attr.name?.startsWith?.(start)) : (startsWith = attr.name?.startsWith?.(startsWith) ? startsWith : \"\") as string) ?? \"\";\n                const trueAttributeName = attr.name.trim()?.replace?.(prefix, \"\");\n                const isPlaceholder = attr.value?.includes?.(\"#{\") && attr.value?.includes?.(\"}\");\n                const atbIndex = parseIndex(attr?.value) ?? -1;\n\n                const excepted: boolean = (Array.isArray(except) ? except?.some?.((str: string)=>trueAttributeName?.startsWith?.(str)) : (except == trueAttributeName));\n                const isSpecific: boolean = (Array.isArray(specific) ? specific?.some?.((str: string)=>attr.name === str) : (attr.name === specific)) && specific !== \"\";\n\n                if (isPlaceholder && (((prefix == \"\" && allowedNoPrefix) || prefix != \"\") || isSpecific) && atbIndex >= 0 && !excepted) {\n                    const key = isSpecific ? attr.name : trueAttributeName;\n                    if (!entriesMap.has(key)) {\n                        entriesMap.set(key, []);\n                    }\n                    entriesMap.get(key)?.push(atbIndex);\n                }\n            }\n            return Array.from(entriesMap.entries());\n        }\n\n        //\n        let attributesEntries: [string, any][] = makeEntries([\"attr:\", \"\"], [\"ref\"]);\n        let propertiesEntries: [string, any][] = makeEntries([\"prop:\"], []);\n        let onEntries: [string, any[]][] = makeCumulativeEntries([\"on:\", \"@\"], [], \"\");\n        let refEntries: [string, any[]][] = makeCumulativeEntries([\"ref:\"], [], [\"ref\"]);\n\n        // remove entries that are already in properties or on\n        //attributesEntries = attributesEntries?.filter?.((pair) => !(propertiesEntries?.some?.((p) => p[0] == pair[0]) || onEntries?.some?.((p) => p[0] == pair[0]) || refEntries?.some?.((p) => p[0] == pair[0]))) ?? [];\n\n        //\n        const bindings: any = Object.fromEntries(entriesIdc?.filter?.((pair) => pair[1] >= 0)?.map?.((pair) => [pair[0], atb?.[pair[1]] ?? null]) ?? []);\n        bindings.attributes = Object.fromEntries(attributesEntries?.filter?.((pair) => pair[1] >= 0)?.map?.((pair) => [pair[0], atb?.[pair[1]] ?? null]) ?? []);\n        bindings.properties = Object.fromEntries(propertiesEntries?.filter?.((pair) => pair[1] >= 0)?.map?.((pair) => [pair[0], atb?.[pair[1]] ?? null]) ?? []);\n        bindings.on = Object.fromEntries(onEntries?.filter?.((pair) => pair[1]?.some?.((idx: number) => idx >= 0))?.map?.((pair) => [pair[0], pair[1]?.map?.((idx: number) => atb?.[idx]).filter((v: any) => v != null)]) ?? []);\n\n        //\n        const refIndex = entriesIdc?.find?.((pair) => (pair[0] == \"ref\" && pair[1] >= 0))?.[1];\n        if (refIndex != null && refIndex >= 0) {\n            const ref = atb?.[refIndex];\n            if (typeof ref == \"function\") { ref?.(el); } else if (ref != null && typeof ref == \"object\") { ref.value = el; }\n        }\n\n        //\n        refEntries?.forEach?.((pair: [string, number[]]) => {\n            const handlers: any[] = pair?.[1]\n                ?.filter?.((idx: number) => idx != null && idx >= 0)\n                ?.map?.((idx: number) => atb?.[idx])\n                ?.filter?.((v: any) => v != null);\n\n            //\n            handlers?.forEach?.((ref: any) => {\n                if (typeof ref == \"function\") { ref?.(el); } else if (ref != null && typeof ref == \"object\") { ref.value = el; }\n            });\n        });\n\n        //\n        const clearPlaceholdersFromAttributesOfElement = (el: HTMLElement | null)=>{\n            if (el == null) return;\n\n            //\n            const attributeIsInRegistry = (name: string) => {\n                return attributesEntries?.some?.((pair) => pair[0] == name) || name?.startsWith?.(\"ref:\") || name == \"ref\";\n            }\n\n            // needs by splice or remove, DOM element.attributes is a live collection\n            for (const attr of Array.from(el?.attributes || [])) {\n                if ( // relaxed syntax for placeholder, if in registry\n                    (attr.value?.includes?.(\"#{\") && attr.value?.includes?.(\"}\") && attributeIsInRegistry(attr.name as string)) ||\n\n                    // stricter check of placeholder, if none in registry\n                    attr.value?.startsWith?.(\"#{\") && attr.value?.endsWith?.(\"}\") ||\n\n                    // if attribute name contains colon, it is a property\n                    attr.name?.includes?.(\":\") || attr.name?.includes?.(\"ref:\") || attr.name == \"ref\"\n                ) { el?.removeAttribute?.(attr.name as string); }\n            };\n        }\n\n        //\n        clearPlaceholdersFromAttributesOfElement(el);\n        if (!EMap?.has?.(el)) { EMap?.set?.(el, E(el, bindings)); };\n    };\n    return EMap?.get?.(el) ?? el;\n}\n\n//\nconst linearBuilder = (strings, ...values) => {\n    const nodes: any[] = [];\n    for (let i = 0; i < strings?.length; i++) {\n        const str = strings?.[i];\n        const val = values?.[i];\n        nodes.push(H(str));\n        nodes.push(val);\n    }\n    if (nodes?.length <= 1) return getNode(nodes?.[0], null, 0);\n\n    // TODO! fix parent node bound support\n    const fragment = document.createDocumentFragment();\n    fragment.append(...nodes?.filter?.((nd) => (nd != null))?.map?.((en, i: number) => getNode(en, null, i))?.filter?.((nd) => (nd != null)));\n    return fragment;\n}\n\n//\nexport function html(strings, ...values) {\n    if (strings?.at?.(0)?.trim?.()?.startsWith?.(\"<\") && strings?.at?.(-1)?.trim?.()?.endsWith?.(\">\")) {\n        return htmlBuilder({ createElement: null })(strings, ...values);\n    }\n    return linearBuilder(strings, ...values);\n};\n\n//\nconst isValidParent = (parent: Node) => {\n    return (parent != null && parent instanceof HTMLElement && !(parent instanceof DocumentFragment || (parent instanceof HTMLBodyElement && parent != document.body)));\n}\n\n//\nconst replaceNode = (parent: Node, node: Node, el: any) => {\n    if (el != null) { el.boundParent = parent; }\n\n    //\n    let newNode = getNode(el, null, -1, parent);\n    if (isElement(newNode)) {\n        if (newNode?.parentNode != parent && !newNode?.contains?.(parent) && newNode != null) {\n            (node as any)?.replaceWith?.((hasValue(newNode) && (typeof newNode?.value == \"object\" || typeof newNode?.value == \"function\") && isElement(newNode?.value)) ? newNode?.value : newNode);\n        }\n    } else\n    { (node as any)?.remove?.(); }\n}\n\n//\nexport function htmlBuilder({ createElement = null } = {}) {\n    return function (strings, ...values) {\n        let parts: string[] = [];\n        const psh: any[] = [], atb: any[] = [];\n        for (let i = 0; i < strings.length; i++) {\n            parts.push(strings?.[i] || \"\");\n            if (i < values.length) {\n                if (strings[i]?.trim()?.endsWith?.(\"<\")) {\n                    const dat = parseTag(values?.[i]);\n                    parts.push((dat.tag || \"div\"));\n                    if (dat.id) parts.push(` id=\"${dat.id}\"`);\n                    if (dat.className) parts.push(` class=\"${dat.className}\"`);\n                } else {\n                    // sequences such as inside of `<...>`\n                    const $inTagOpen = checkInsideTagBlock(strings, strings?.[i] || \"\", strings?.[i + 1] || \"\");\n                    const $afterEquals = /[\\w:\\-\\.\\]]\\s*=\\s*$/.test(strings[i]?.trim?.() ?? \"\") || strings[i]?.trim?.()?.endsWith?.(\"=\");\n\n                    //\n                    const $isQuoteBegin = strings[i]?.trim?.()?.match?.(/['\"]$/);\n                    const $isQuoteEnd = strings[i + 1]?.trim?.()?.match?.(/^['\"]/) ?? $isQuoteBegin;\n\n                    //\n                    const $betweenQuotes = ($isQuoteBegin && $isQuoteEnd);\n                    const $attributePattern = $afterEquals;\n\n                    //\n                    const isAttr = ($attributePattern || $betweenQuotes) && $inTagOpen;\n                    if (isAttr) {\n                        const $needsToQuoteWrap = ($attributePattern && !($betweenQuotes));\n                        const ati = atb.length;\n                        parts.push((typeof values?.[i] == \"string\" ? values?.[i]?.trim?.() != \"\" : values?.[i] != null) ? (($needsToQuoteWrap ? `\"#{${ati}}\"` : `#{${ati}}`)) : \"\");\n                        atb.push(values?.[i]);\n                    } else\n                    if (!$inTagOpen) {\n                        const psi = psh.length;\n                        parts.push((typeof values?.[i] == \"string\" ? values?.[i]?.trim?.() != \"\" : values?.[i] != null) ? (isPrimitive(values?.[i]) ? String(values?.[i])?.trim?.() : `<!--o:${psi}-->`) : \"\");\n                        psh.push(values?.[i]);\n                    }\n                }\n            }\n        }\n\n        //\n        const sourceCode = cleanupInterTagWhitespaceAndIndent(parts.join(\"\").trim());\n        const mapped = new WeakMap(), parser = new DOMParser(), doc: any = parser.parseFromString(sourceCode, \"text/html\");\n\n        //\n        const isTemplate = doc instanceof HTMLTemplateElement || doc?.matches?.(\"template\");\n        const sources: any = (isTemplate ? doc : doc.querySelector(\"template\"))?.content ?? (doc.body ?? doc);\n\n        //\n        const frag = document.createDocumentFragment();\n        const bucket = Array.from(sources.childNodes)?.filter((e: any) => { return e instanceof Node; }).map((node: any) => {\n            if (!isValidParent(node?.parentNode) && node?.parentNode != frag) {\n                node?.remove?.();\n                if (node != null) { frag?.append?.(node); };\n            }\n            return node;\n        });\n\n        //\n        let walkedNodes: any[] = [];\n\n        //\n        bucket.forEach((nodeSet: any) => {\n            const walker: any = nodeSet ? document.createTreeWalker(nodeSet, NodeFilter.SHOW_ALL, null) : null;\n            do {\n                const node: any = walker?.currentNode;\n                walkedNodes.push(node);\n            } while (walker?.nextNode?.());\n        });\n\n        //\n        walkedNodes?.filter?.((node: any) => node?.nodeType == Node.COMMENT_NODE)?.forEach?.((node: any) => {\n            if (node?.nodeValue?.trim?.()?.includes?.(\"o:\") && Number.isInteger(parseInt(node?.nodeValue?.trim?.()?.slice?.(2) ?? \"-1\"))) {\n                let el: any = psh?.[parseInt(node?.nodeValue?.trim?.()?.slice?.(2) ?? \"-1\") ?? -1];\n\n                // make iteratable array and set\n                if (el == null || el === undefined || (typeof el == \"string\" ? el : null)?.trim?.() == \"\") {\n                    node?.remove?.();\n                } else {\n                    const $parent = node?.parentNode;\n                    if (Array.isArray(el) || el instanceof Map || el instanceof Set) {\n                        replaceNode?.($parent, node, el = M(el, null, $parent));\n                    } else\n                    if (el != null) {\n                        replaceNode?.($parent, node, el);\n                    }\n                }\n            }\n\n            // remove comment node if it is connected\n            if (node?.isConnected) {\n                node?.remove?.();\n            }\n        });\n\n        //\n        walkedNodes?.filter((node: any) => node.nodeType == Node.ELEMENT_NODE)?.map?.((node) => {\n            connectElement(node as HTMLElement, atb, psh, mapped);\n        });\n\n        // Final whitespace cleanup to ensure :empty works even after dynamic insertions\n        return Array.from(frag?.childNodes)?.length > 1 ? frag : frag?.childNodes?.[0];\n    };\n}\n\n//\nexport const H = (str: any, ...values: any[]) => {\n    //if (typeof str == \"object\" && hasValue(str)) return C(str);\n    if (typeof str == \"string\") {\n        if (str?.trim?.()?.startsWith?.(\"<\") && str?.trim?.()?.endsWith?.(\">\")) {\n            const parser = new DOMParser(), doc = parser.parseFromString(cleanupInterTagWhitespaceAndIndent(str?.trim?.()), \"text/html\");\n            const basis = doc.querySelector(\"template\")?.content ?? doc.body;\n            // Normalize and clean whitespace-only text nodes between tags\n            if (basis instanceof HTMLBodyElement) {\n                const frag = document.createDocumentFragment();\n                frag.append(...Array.from(basis.childNodes ?? []));\n                return (Array.from(frag.childNodes)?.length > 1 ? frag : frag?.childNodes?.[0]);\n            }\n            if (basis instanceof DocumentFragment) { return basis; }\n            if (basis?.childNodes?.length > 1) { const frag = document.createDocumentFragment(); frag.append(...Array.from(basis?.childNodes ?? [])); return frag; }\n            return basis?.childNodes?.[0] ?? (new Text(str));\n        }\n        return new Text(str);\n    } else\n    if (typeof str == \"function\") { return H(str?.()); } else\n    if (Array.isArray(str) && values) { return html(str, ...values); } else\n    if (str instanceof Node) { return str; };\n    return getNode(str);\n}\n\n//\nexport default H;\n","import { loadSettings } from \"./Settings\";\r\nimport type { AppSettings } from \"./SettingsTypes.ts\";\r\nimport { DEFAULT_SETTINGS } from \"./SettingsTypes.ts\";\r\n\r\nexport type RuntimeSettingsProvider = () => Promise<AppSettings> | AppSettings;\r\n\r\nlet provider: RuntimeSettingsProvider = loadSettings;//async () => DEFAULT_SETTINGS;\r\n\r\n/**\r\n * Allows non-browser runtimes (Node/Deno backend) to supply settings without IndexedDB/chrome storage.\r\n * Frontend apps can also set this to bridge to their existing settings storage.\r\n */\r\nexport const setRuntimeSettingsProvider = (next: RuntimeSettingsProvider) => {\r\n    provider = next;\r\n};\r\n\r\nexport const getRuntimeSettings = async (): Promise<AppSettings> => {\r\n    try {\r\n        const value = await provider();\r\n        return value || DEFAULT_SETTINGS;\r\n    } catch {\r\n        return DEFAULT_SETTINGS;\r\n    }\r\n};\r\n","//#region src/constants.ts\nconst LIST_ITEM_MARKER = \"-\";\nconst LIST_ITEM_PREFIX = \"- \";\nconst COMMA = \",\";\nconst COLON = \":\";\nconst SPACE = \" \";\nconst PIPE = \"|\";\nconst DOT = \".\";\nconst OPEN_BRACKET = \"[\";\nconst CLOSE_BRACKET = \"]\";\nconst OPEN_BRACE = \"{\";\nconst CLOSE_BRACE = \"}\";\nconst NULL_LITERAL = \"null\";\nconst TRUE_LITERAL = \"true\";\nconst FALSE_LITERAL = \"false\";\nconst BACKSLASH = \"\\\\\";\nconst DOUBLE_QUOTE = \"\\\"\";\nconst NEWLINE = \"\\n\";\nconst CARRIAGE_RETURN = \"\\r\";\nconst TAB = \"\t\";\nconst DELIMITERS = {\n\tcomma: COMMA,\n\ttab: TAB,\n\tpipe: PIPE\n};\nconst DEFAULT_DELIMITER = DELIMITERS.comma;\n\n//#endregion\n//#region src/shared/string-utils.ts\n/**\n* Escapes special characters in a string for encoding.\n*\n* @remarks\n* Handles backslashes, quotes, newlines, carriage returns, and tabs.\n*/\nfunction escapeString(value) {\n\treturn value.replace(/\\\\/g, `${BACKSLASH}${BACKSLASH}`).replace(/\"/g, `${BACKSLASH}${DOUBLE_QUOTE}`).replace(/\\n/g, `${BACKSLASH}n`).replace(/\\r/g, `${BACKSLASH}r`).replace(/\\t/g, `${BACKSLASH}t`);\n}\n/**\n* Unescapes a string by processing escape sequences.\n*\n* @remarks\n* Handles `\\n`, `\\t`, `\\r`, `\\\\`, and `\\\"` escape sequences.\n*/\nfunction unescapeString(value) {\n\tlet unescaped = \"\";\n\tlet i = 0;\n\twhile (i < value.length) {\n\t\tif (value[i] === BACKSLASH) {\n\t\t\tif (i + 1 >= value.length) throw new SyntaxError(\"Invalid escape sequence: backslash at end of string\");\n\t\t\tconst next = value[i + 1];\n\t\t\tif (next === \"n\") {\n\t\t\t\tunescaped += NEWLINE;\n\t\t\t\ti += 2;\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tif (next === \"t\") {\n\t\t\t\tunescaped += TAB;\n\t\t\t\ti += 2;\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tif (next === \"r\") {\n\t\t\t\tunescaped += CARRIAGE_RETURN;\n\t\t\t\ti += 2;\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tif (next === BACKSLASH) {\n\t\t\t\tunescaped += BACKSLASH;\n\t\t\t\ti += 2;\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tif (next === DOUBLE_QUOTE) {\n\t\t\t\tunescaped += DOUBLE_QUOTE;\n\t\t\t\ti += 2;\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tthrow new SyntaxError(`Invalid escape sequence: \\\\${next}`);\n\t\t}\n\t\tunescaped += value[i];\n\t\ti++;\n\t}\n\treturn unescaped;\n}\n/**\n* Finds the index of the closing double quote, accounting for escape sequences.\n*/\nfunction findClosingQuote(content, start) {\n\tlet i = start + 1;\n\twhile (i < content.length) {\n\t\tif (content[i] === BACKSLASH && i + 1 < content.length) {\n\t\t\ti += 2;\n\t\t\tcontinue;\n\t\t}\n\t\tif (content[i] === DOUBLE_QUOTE) return i;\n\t\ti++;\n\t}\n\treturn -1;\n}\n/**\n* Finds the index of a character outside of quoted sections.\n*/\nfunction findUnquotedChar(content, char, start = 0) {\n\tlet inQuotes = false;\n\tlet i = start;\n\twhile (i < content.length) {\n\t\tif (content[i] === BACKSLASH && i + 1 < content.length && inQuotes) {\n\t\t\ti += 2;\n\t\t\tcontinue;\n\t\t}\n\t\tif (content[i] === DOUBLE_QUOTE) {\n\t\t\tinQuotes = !inQuotes;\n\t\t\ti++;\n\t\t\tcontinue;\n\t\t}\n\t\tif (content[i] === char && !inQuotes) return i;\n\t\ti++;\n\t}\n\treturn -1;\n}\n\n//#endregion\n//#region src/shared/literal-utils.ts\nfunction isBooleanOrNullLiteral(token) {\n\treturn token === TRUE_LITERAL || token === FALSE_LITERAL || token === NULL_LITERAL;\n}\n/**\n* Checks if a token represents a valid numeric literal.\n*\n* @remarks\n* Rejects numbers with leading zeros (except `\"0\"` itself or decimals like `\"0.5\"`).\n*/\nfunction isNumericLiteral(token) {\n\tif (!token) return false;\n\tif (token.length > 1 && token[0] === \"0\" && token[1] !== \".\") return false;\n\tconst numericValue = Number(token);\n\treturn !Number.isNaN(numericValue) && Number.isFinite(numericValue);\n}\n\n//#endregion\n//#region src/decode/parser.ts\nfunction parseArrayHeaderLine(content, defaultDelimiter) {\n\tconst trimmed = content.trimStart();\n\tlet bracketStart = -1;\n\tif (trimmed.startsWith(DOUBLE_QUOTE)) {\n\t\tconst closingQuoteIndex = findClosingQuote(trimmed, 0);\n\t\tif (closingQuoteIndex === -1) return;\n\t\tif (!trimmed.slice(closingQuoteIndex + 1).startsWith(OPEN_BRACKET)) return;\n\t\tconst keyEndIndex = content.length - trimmed.length + closingQuoteIndex + 1;\n\t\tbracketStart = content.indexOf(OPEN_BRACKET, keyEndIndex);\n\t} else bracketStart = content.indexOf(OPEN_BRACKET);\n\tif (bracketStart === -1) return;\n\tconst bracketEnd = content.indexOf(CLOSE_BRACKET, bracketStart);\n\tif (bracketEnd === -1) return;\n\tlet colonIndex = bracketEnd + 1;\n\tlet braceEnd = colonIndex;\n\tconst braceStart = content.indexOf(OPEN_BRACE, bracketEnd);\n\tif (braceStart !== -1 && braceStart < content.indexOf(COLON, bracketEnd)) {\n\t\tconst foundBraceEnd = content.indexOf(CLOSE_BRACE, braceStart);\n\t\tif (foundBraceEnd !== -1) braceEnd = foundBraceEnd + 1;\n\t}\n\tcolonIndex = content.indexOf(COLON, Math.max(bracketEnd, braceEnd));\n\tif (colonIndex === -1) return;\n\tlet key;\n\tif (bracketStart > 0) {\n\t\tconst rawKey = content.slice(0, bracketStart).trim();\n\t\tkey = rawKey.startsWith(DOUBLE_QUOTE) ? parseStringLiteral(rawKey) : rawKey;\n\t}\n\tconst afterColon = content.slice(colonIndex + 1).trim();\n\tconst bracketContent = content.slice(bracketStart + 1, bracketEnd);\n\tlet parsedBracket;\n\ttry {\n\t\tparsedBracket = parseBracketSegment(bracketContent, defaultDelimiter);\n\t} catch {\n\t\treturn;\n\t}\n\tconst { length, delimiter } = parsedBracket;\n\tlet fields;\n\tif (braceStart !== -1 && braceStart < colonIndex) {\n\t\tconst foundBraceEnd = content.indexOf(CLOSE_BRACE, braceStart);\n\t\tif (foundBraceEnd !== -1 && foundBraceEnd < colonIndex) fields = parseDelimitedValues(content.slice(braceStart + 1, foundBraceEnd), delimiter).map((field) => parseStringLiteral(field.trim()));\n\t}\n\treturn {\n\t\theader: {\n\t\t\tkey,\n\t\t\tlength,\n\t\t\tdelimiter,\n\t\t\tfields\n\t\t},\n\t\tinlineValues: afterColon || void 0\n\t};\n}\nfunction parseBracketSegment(seg, defaultDelimiter) {\n\tlet content = seg;\n\tlet delimiter = defaultDelimiter;\n\tif (content.endsWith(TAB)) {\n\t\tdelimiter = DELIMITERS.tab;\n\t\tcontent = content.slice(0, -1);\n\t} else if (content.endsWith(PIPE)) {\n\t\tdelimiter = DELIMITERS.pipe;\n\t\tcontent = content.slice(0, -1);\n\t}\n\tconst length = Number.parseInt(content, 10);\n\tif (Number.isNaN(length)) throw new TypeError(`Invalid array length: ${seg}`);\n\treturn {\n\t\tlength,\n\t\tdelimiter\n\t};\n}\n/**\n* Parses a delimited string into values, respecting quoted strings and escape sequences.\n*\n* @remarks\n* Uses a state machine that tracks:\n* - `inQuotes`: Whether we're inside a quoted string (to ignore delimiters)\n* - `valueBuffer`: Accumulates characters for the current value\n* - Escape sequences: Handled within quoted strings\n*/\nfunction parseDelimitedValues(input, delimiter) {\n\tconst values = [];\n\tlet valueBuffer = \"\";\n\tlet inQuotes = false;\n\tlet i = 0;\n\twhile (i < input.length) {\n\t\tconst char = input[i];\n\t\tif (char === BACKSLASH && i + 1 < input.length && inQuotes) {\n\t\t\tvalueBuffer += char + input[i + 1];\n\t\t\ti += 2;\n\t\t\tcontinue;\n\t\t}\n\t\tif (char === DOUBLE_QUOTE) {\n\t\t\tinQuotes = !inQuotes;\n\t\t\tvalueBuffer += char;\n\t\t\ti++;\n\t\t\tcontinue;\n\t\t}\n\t\tif (char === delimiter && !inQuotes) {\n\t\t\tvalues.push(valueBuffer.trim());\n\t\t\tvalueBuffer = \"\";\n\t\t\ti++;\n\t\t\tcontinue;\n\t\t}\n\t\tvalueBuffer += char;\n\t\ti++;\n\t}\n\tif (valueBuffer || values.length > 0) values.push(valueBuffer.trim());\n\treturn values;\n}\nfunction mapRowValuesToPrimitives(values) {\n\treturn values.map((v) => parsePrimitiveToken(v));\n}\nfunction parsePrimitiveToken(token) {\n\tconst trimmed = token.trim();\n\tif (!trimmed) return \"\";\n\tif (trimmed.startsWith(DOUBLE_QUOTE)) return parseStringLiteral(trimmed);\n\tif (isBooleanOrNullLiteral(trimmed)) {\n\t\tif (trimmed === TRUE_LITERAL) return true;\n\t\tif (trimmed === FALSE_LITERAL) return false;\n\t\tif (trimmed === NULL_LITERAL) return null;\n\t}\n\tif (isNumericLiteral(trimmed)) {\n\t\tconst parsedNumber = Number.parseFloat(trimmed);\n\t\treturn Object.is(parsedNumber, -0) ? 0 : parsedNumber;\n\t}\n\treturn trimmed;\n}\nfunction parseStringLiteral(token) {\n\tconst trimmedToken = token.trim();\n\tif (trimmedToken.startsWith(DOUBLE_QUOTE)) {\n\t\tconst closingQuoteIndex = findClosingQuote(trimmedToken, 0);\n\t\tif (closingQuoteIndex === -1) throw new SyntaxError(\"Unterminated string: missing closing quote\");\n\t\tif (closingQuoteIndex !== trimmedToken.length - 1) throw new SyntaxError(\"Unexpected characters after closing quote\");\n\t\treturn unescapeString(trimmedToken.slice(1, closingQuoteIndex));\n\t}\n\treturn trimmedToken;\n}\nfunction parseUnquotedKey(content, start) {\n\tlet parsePosition = start;\n\twhile (parsePosition < content.length && content[parsePosition] !== COLON) parsePosition++;\n\tif (parsePosition >= content.length || content[parsePosition] !== COLON) throw new SyntaxError(\"Missing colon after key\");\n\tconst key = content.slice(start, parsePosition).trim();\n\tparsePosition++;\n\treturn {\n\t\tkey,\n\t\tend: parsePosition\n\t};\n}\nfunction parseQuotedKey(content, start) {\n\tconst closingQuoteIndex = findClosingQuote(content, start);\n\tif (closingQuoteIndex === -1) throw new SyntaxError(\"Unterminated quoted key\");\n\tconst key = unescapeString(content.slice(start + 1, closingQuoteIndex));\n\tlet parsePosition = closingQuoteIndex + 1;\n\tif (parsePosition >= content.length || content[parsePosition] !== COLON) throw new SyntaxError(\"Missing colon after key\");\n\tparsePosition++;\n\treturn {\n\t\tkey,\n\t\tend: parsePosition\n\t};\n}\nfunction parseKeyToken(content, start) {\n\tconst isQuoted = content[start] === DOUBLE_QUOTE;\n\treturn {\n\t\t...isQuoted ? parseQuotedKey(content, start) : parseUnquotedKey(content, start),\n\t\tisQuoted\n\t};\n}\nfunction isArrayHeaderContent(content) {\n\treturn content.trim().startsWith(OPEN_BRACKET) && findUnquotedChar(content, COLON) !== -1;\n}\nfunction isKeyValueContent(content) {\n\treturn findUnquotedChar(content, COLON) !== -1;\n}\n\n//#endregion\n//#region src/decode/scanner.ts\nfunction createScanState() {\n\treturn {\n\t\tlineNumber: 0,\n\t\tblankLines: []\n\t};\n}\nfunction parseLineIncremental(raw, state, indentSize, strict) {\n\tstate.lineNumber++;\n\tconst lineNumber = state.lineNumber;\n\tlet indent = 0;\n\twhile (indent < raw.length && raw[indent] === SPACE) indent++;\n\tconst content = raw.slice(indent);\n\tif (!content.trim()) {\n\t\tconst depth$1 = computeDepthFromIndent(indent, indentSize);\n\t\tstate.blankLines.push({\n\t\t\tlineNumber,\n\t\t\tindent,\n\t\t\tdepth: depth$1\n\t\t});\n\t\treturn;\n\t}\n\tconst depth = computeDepthFromIndent(indent, indentSize);\n\tif (strict) {\n\t\tlet whitespaceEndIndex = 0;\n\t\twhile (whitespaceEndIndex < raw.length && (raw[whitespaceEndIndex] === SPACE || raw[whitespaceEndIndex] === TAB)) whitespaceEndIndex++;\n\t\tif (raw.slice(0, whitespaceEndIndex).includes(TAB)) throw new SyntaxError(`Line ${lineNumber}: Tabs are not allowed in indentation in strict mode`);\n\t\tif (indent > 0 && indent % indentSize !== 0) throw new SyntaxError(`Line ${lineNumber}: Indentation must be exact multiple of ${indentSize}, but found ${indent} spaces`);\n\t}\n\treturn {\n\t\traw,\n\t\tindent,\n\t\tcontent,\n\t\tdepth,\n\t\tlineNumber\n\t};\n}\nfunction* parseLinesSync(source, indentSize, strict, state) {\n\tfor (const raw of source) {\n\t\tconst parsedLine = parseLineIncremental(raw, state, indentSize, strict);\n\t\tif (parsedLine !== void 0) yield parsedLine;\n\t}\n}\nasync function* parseLinesAsync(source, indentSize, strict, state) {\n\tfor await (const raw of source) {\n\t\tconst parsedLine = parseLineIncremental(raw, state, indentSize, strict);\n\t\tif (parsedLine !== void 0) yield parsedLine;\n\t}\n}\nfunction computeDepthFromIndent(indentSpaces, indentSize) {\n\treturn Math.floor(indentSpaces / indentSize);\n}\n\n//#endregion\n//#region src/decode/validation.ts\n/**\n* Asserts that the actual count matches the expected count in strict mode.\n*/\nfunction assertExpectedCount(actual, expected, itemType, options) {\n\tif (options.strict && actual !== expected) throw new RangeError(`Expected ${expected} ${itemType}, but got ${actual}`);\n}\n/**\n* Validates that there are no extra list items beyond the expected count.\n*/\nfunction validateNoExtraListItems(nextLine, itemDepth, expectedCount) {\n\tif (nextLine?.depth === itemDepth && nextLine.content.startsWith(LIST_ITEM_PREFIX)) throw new RangeError(`Expected ${expectedCount} list array items, but found more`);\n}\n/**\n* Validates that there are no extra tabular rows beyond the expected count.\n*/\nfunction validateNoExtraTabularRows(nextLine, rowDepth, header) {\n\tif (nextLine?.depth === rowDepth && !nextLine.content.startsWith(LIST_ITEM_PREFIX) && isDataRow(nextLine.content, header.delimiter)) throw new RangeError(`Expected ${header.length} tabular rows, but found more`);\n}\n/**\n* Validates that there are no blank lines within a specific line range in strict mode.\n*/\nfunction validateNoBlankLinesInRange(startLine, endLine, blankLines, strict, context) {\n\tif (!strict) return;\n\tconst firstBlank = blankLines.find((blank) => blank.lineNumber > startLine && blank.lineNumber < endLine);\n\tif (firstBlank) throw new SyntaxError(`Line ${firstBlank.lineNumber}: Blank lines inside ${context} are not allowed in strict mode`);\n}\n/**\n* Checks if a line is a data row (vs a key-value pair) in a tabular array.\n*/\nfunction isDataRow(content, delimiter) {\n\tconst colonPos = content.indexOf(COLON);\n\tconst delimiterPos = content.indexOf(delimiter);\n\tif (colonPos === -1) return true;\n\tif (delimiterPos !== -1 && delimiterPos < colonPos) return true;\n\treturn false;\n}\n\n//#endregion\n//#region src/decode/decoders.ts\nvar StreamingLineCursor = class {\n\tbuffer = [];\n\tgenerator;\n\tdone = false;\n\tlastLine;\n\tscanState;\n\tconstructor(generator, scanState) {\n\t\tthis.generator = generator;\n\t\tthis.scanState = scanState;\n\t}\n\tgetBlankLines() {\n\t\treturn this.scanState.blankLines;\n\t}\n\tasync peek() {\n\t\tif (this.buffer.length > 0) return this.buffer[0];\n\t\tif (this.done) return;\n\t\tconst result = await this.generator.next();\n\t\tif (result.done) {\n\t\t\tthis.done = true;\n\t\t\treturn;\n\t\t}\n\t\tthis.buffer.push(result.value);\n\t\treturn result.value;\n\t}\n\tasync next() {\n\t\tconst line = await this.peek();\n\t\tif (line !== void 0) {\n\t\t\tthis.buffer.shift();\n\t\t\tthis.lastLine = line;\n\t\t}\n\t\treturn line;\n\t}\n\tasync advance() {\n\t\tawait this.next();\n\t}\n\tcurrent() {\n\t\treturn this.lastLine;\n\t}\n\tasync atEnd() {\n\t\treturn await this.peek() === void 0;\n\t}\n\tpeekSync() {\n\t\tif (this.buffer.length > 0) return this.buffer[0];\n\t\tif (this.done) return;\n\t\tconst result = this.generator.next();\n\t\tif (result.done) {\n\t\t\tthis.done = true;\n\t\t\treturn;\n\t\t}\n\t\tthis.buffer.push(result.value);\n\t\treturn result.value;\n\t}\n\tnextSync() {\n\t\tconst line = this.peekSync();\n\t\tif (line !== void 0) {\n\t\t\tthis.buffer.shift();\n\t\t\tthis.lastLine = line;\n\t\t}\n\t\treturn line;\n\t}\n\tadvanceSync() {\n\t\tthis.nextSync();\n\t}\n\tatEndSync() {\n\t\treturn this.peekSync() === void 0;\n\t}\n};\nfunction* decodeStreamSync$1(source, options) {\n\tif (options?.expandPaths !== void 0) throw new Error(\"expandPaths is not supported in streaming decode\");\n\tconst resolvedOptions = {\n\t\tindent: options?.indent ?? 2,\n\t\tstrict: options?.strict ?? true\n\t};\n\tconst scanState = createScanState();\n\tconst cursor = new StreamingLineCursor(parseLinesSync(source, resolvedOptions.indent, resolvedOptions.strict, scanState), scanState);\n\tconst first = cursor.peekSync();\n\tif (!first) {\n\t\tyield { type: \"startObject\" };\n\t\tyield { type: \"endObject\" };\n\t\treturn;\n\t}\n\tif (isArrayHeaderContent(first.content)) {\n\t\tconst headerInfo = parseArrayHeaderLine(first.content, DEFAULT_DELIMITER);\n\t\tif (headerInfo) {\n\t\t\tcursor.advanceSync();\n\t\t\tyield* decodeArrayFromHeaderSync(headerInfo.header, headerInfo.inlineValues, cursor, 0, resolvedOptions);\n\t\t\treturn;\n\t\t}\n\t}\n\tcursor.advanceSync();\n\tif (!!cursor.atEndSync() && !isKeyValueLineSync(first)) {\n\t\tyield {\n\t\t\ttype: \"primitive\",\n\t\t\tvalue: parsePrimitiveToken(first.content.trim())\n\t\t};\n\t\treturn;\n\t}\n\tyield { type: \"startObject\" };\n\tyield* decodeKeyValueSync(first.content, cursor, 0, resolvedOptions);\n\twhile (!cursor.atEndSync()) {\n\t\tconst line = cursor.peekSync();\n\t\tif (!line || line.depth !== 0) break;\n\t\tcursor.advanceSync();\n\t\tyield* decodeKeyValueSync(line.content, cursor, 0, resolvedOptions);\n\t}\n\tyield { type: \"endObject\" };\n}\nfunction* decodeKeyValueSync(content, cursor, baseDepth, options) {\n\tconst arrayHeader = parseArrayHeaderLine(content, DEFAULT_DELIMITER);\n\tif (arrayHeader && arrayHeader.header.key) {\n\t\tyield {\n\t\t\ttype: \"key\",\n\t\t\tkey: arrayHeader.header.key\n\t\t};\n\t\tyield* decodeArrayFromHeaderSync(arrayHeader.header, arrayHeader.inlineValues, cursor, baseDepth, options);\n\t\treturn;\n\t}\n\tconst { key, isQuoted } = parseKeyToken(content, 0);\n\tconst colonIndex = content.indexOf(COLON, key.length);\n\tconst rest = colonIndex >= 0 ? content.slice(colonIndex + 1).trim() : \"\";\n\tyield isQuoted ? {\n\t\ttype: \"key\",\n\t\tkey,\n\t\twasQuoted: true\n\t} : {\n\t\ttype: \"key\",\n\t\tkey\n\t};\n\tif (!rest) {\n\t\tconst nextLine = cursor.peekSync();\n\t\tif (nextLine && nextLine.depth > baseDepth) {\n\t\t\tyield { type: \"startObject\" };\n\t\t\tyield* decodeObjectFieldsSync(cursor, baseDepth + 1, options);\n\t\t\tyield { type: \"endObject\" };\n\t\t\treturn;\n\t\t}\n\t\tyield { type: \"startObject\" };\n\t\tyield { type: \"endObject\" };\n\t\treturn;\n\t}\n\tyield {\n\t\ttype: \"primitive\",\n\t\tvalue: parsePrimitiveToken(rest)\n\t};\n}\nfunction* decodeObjectFieldsSync(cursor, baseDepth, options) {\n\tlet computedDepth;\n\twhile (!cursor.atEndSync()) {\n\t\tconst line = cursor.peekSync();\n\t\tif (!line || line.depth < baseDepth) break;\n\t\tif (computedDepth === void 0 && line.depth >= baseDepth) computedDepth = line.depth;\n\t\tif (line.depth === computedDepth) {\n\t\t\tcursor.advanceSync();\n\t\t\tyield* decodeKeyValueSync(line.content, cursor, computedDepth, options);\n\t\t} else break;\n\t}\n}\nfunction* decodeArrayFromHeaderSync(header, inlineValues, cursor, baseDepth, options) {\n\tyield {\n\t\ttype: \"startArray\",\n\t\tlength: header.length\n\t};\n\tif (inlineValues) {\n\t\tyield* decodeInlinePrimitiveArraySync(header, inlineValues, options);\n\t\tyield { type: \"endArray\" };\n\t\treturn;\n\t}\n\tif (header.fields && header.fields.length > 0) {\n\t\tyield* decodeTabularArraySync(header, cursor, baseDepth, options);\n\t\tyield { type: \"endArray\" };\n\t\treturn;\n\t}\n\tyield* decodeListArraySync(header, cursor, baseDepth, options);\n\tyield { type: \"endArray\" };\n}\nfunction* decodeInlinePrimitiveArraySync(header, inlineValues, options) {\n\tif (!inlineValues.trim()) {\n\t\tassertExpectedCount(0, header.length, \"inline array items\", options);\n\t\treturn;\n\t}\n\tconst primitives = mapRowValuesToPrimitives(parseDelimitedValues(inlineValues, header.delimiter));\n\tassertExpectedCount(primitives.length, header.length, \"inline array items\", options);\n\tfor (const primitive of primitives) yield {\n\t\ttype: \"primitive\",\n\t\tvalue: primitive\n\t};\n}\nfunction* decodeTabularArraySync(header, cursor, baseDepth, options) {\n\tconst rowDepth = baseDepth + 1;\n\tlet rowCount = 0;\n\tlet startLine;\n\tlet endLine;\n\twhile (!cursor.atEndSync() && rowCount < header.length) {\n\t\tconst line = cursor.peekSync();\n\t\tif (!line || line.depth < rowDepth) break;\n\t\tif (line.depth === rowDepth) {\n\t\t\tif (startLine === void 0) startLine = line.lineNumber;\n\t\t\tendLine = line.lineNumber;\n\t\t\tcursor.advanceSync();\n\t\t\tconst values = parseDelimitedValues(line.content, header.delimiter);\n\t\t\tassertExpectedCount(values.length, header.fields.length, \"tabular row values\", options);\n\t\t\tconst primitives = mapRowValuesToPrimitives(values);\n\t\t\tyield { type: \"startObject\" };\n\t\t\tfor (let i = 0; i < header.fields.length; i++) {\n\t\t\t\tyield {\n\t\t\t\t\ttype: \"key\",\n\t\t\t\t\tkey: header.fields[i]\n\t\t\t\t};\n\t\t\t\tyield {\n\t\t\t\t\ttype: \"primitive\",\n\t\t\t\t\tvalue: primitives[i]\n\t\t\t\t};\n\t\t\t}\n\t\t\tyield { type: \"endObject\" };\n\t\t\trowCount++;\n\t\t} else break;\n\t}\n\tassertExpectedCount(rowCount, header.length, \"tabular rows\", options);\n\tif (options.strict && startLine !== void 0 && endLine !== void 0) validateNoBlankLinesInRange(startLine, endLine, cursor.getBlankLines(), options.strict, \"tabular array\");\n\tif (options.strict) validateNoExtraTabularRows(cursor.peekSync(), rowDepth, header);\n}\nfunction* decodeListArraySync(header, cursor, baseDepth, options) {\n\tconst itemDepth = baseDepth + 1;\n\tlet itemCount = 0;\n\tlet startLine;\n\tlet endLine;\n\twhile (!cursor.atEndSync() && itemCount < header.length) {\n\t\tconst line = cursor.peekSync();\n\t\tif (!line || line.depth < itemDepth) break;\n\t\tconst isListItem = line.content.startsWith(LIST_ITEM_PREFIX) || line.content === LIST_ITEM_MARKER;\n\t\tif (line.depth === itemDepth && isListItem) {\n\t\t\tif (startLine === void 0) startLine = line.lineNumber;\n\t\t\tendLine = line.lineNumber;\n\t\t\tyield* decodeListItemSync(cursor, itemDepth, options);\n\t\t\tconst currentLine = cursor.current();\n\t\t\tif (currentLine) endLine = currentLine.lineNumber;\n\t\t\titemCount++;\n\t\t} else break;\n\t}\n\tassertExpectedCount(itemCount, header.length, \"list array items\", options);\n\tif (options.strict && startLine !== void 0 && endLine !== void 0) validateNoBlankLinesInRange(startLine, endLine, cursor.getBlankLines(), options.strict, \"list array\");\n\tif (options.strict) validateNoExtraListItems(cursor.peekSync(), itemDepth, header.length);\n}\nfunction* decodeListItemSync(cursor, baseDepth, options) {\n\tconst line = cursor.nextSync();\n\tif (!line) throw new ReferenceError(\"Expected list item\");\n\tlet afterHyphen;\n\tif (line.content === LIST_ITEM_MARKER) {\n\t\tyield { type: \"startObject\" };\n\t\tyield { type: \"endObject\" };\n\t\treturn;\n\t} else if (line.content.startsWith(LIST_ITEM_PREFIX)) afterHyphen = line.content.slice(LIST_ITEM_PREFIX.length);\n\telse throw new SyntaxError(`Expected list item to start with \"${LIST_ITEM_PREFIX}\"`);\n\tif (!afterHyphen.trim()) {\n\t\tyield { type: \"startObject\" };\n\t\tyield { type: \"endObject\" };\n\t\treturn;\n\t}\n\tif (isArrayHeaderContent(afterHyphen)) {\n\t\tconst arrayHeader = parseArrayHeaderLine(afterHyphen, DEFAULT_DELIMITER);\n\t\tif (arrayHeader) {\n\t\t\tyield* decodeArrayFromHeaderSync(arrayHeader.header, arrayHeader.inlineValues, cursor, baseDepth, options);\n\t\t\treturn;\n\t\t}\n\t}\n\tif (isKeyValueContent(afterHyphen)) {\n\t\tyield { type: \"startObject\" };\n\t\tyield* decodeKeyValueSync(afterHyphen, cursor, baseDepth, options);\n\t\tconst followDepth = baseDepth + 1;\n\t\twhile (!cursor.atEndSync()) {\n\t\t\tconst nextLine = cursor.peekSync();\n\t\t\tif (!nextLine || nextLine.depth < followDepth) break;\n\t\t\tif (nextLine.depth === followDepth && !nextLine.content.startsWith(LIST_ITEM_PREFIX)) {\n\t\t\t\tcursor.advanceSync();\n\t\t\t\tyield* decodeKeyValueSync(nextLine.content, cursor, followDepth, options);\n\t\t\t} else break;\n\t\t}\n\t\tyield { type: \"endObject\" };\n\t\treturn;\n\t}\n\tyield {\n\t\ttype: \"primitive\",\n\t\tvalue: parsePrimitiveToken(afterHyphen)\n\t};\n}\nfunction isKeyValueLineSync(line) {\n\tconst content = line.content;\n\tif (content.startsWith(\"\\\"\")) {\n\t\tconst closingQuoteIndex = findClosingQuote(content, 0);\n\t\tif (closingQuoteIndex === -1) return false;\n\t\treturn content.slice(closingQuoteIndex + 1).includes(COLON);\n\t} else return content.includes(COLON);\n}\nasync function* decodeStream$1(source, options) {\n\tif (options?.expandPaths !== void 0) throw new Error(\"expandPaths is not supported in streaming decode\");\n\tconst resolvedOptions = {\n\t\tindent: options?.indent ?? 2,\n\t\tstrict: options?.strict ?? true\n\t};\n\tconst scanState = createScanState();\n\tif (Symbol.asyncIterator in source) {\n\t\tconst cursor = new StreamingLineCursor(parseLinesAsync(source, resolvedOptions.indent, resolvedOptions.strict, scanState), scanState);\n\t\tconst first = await cursor.peek();\n\t\tif (!first) {\n\t\t\tyield { type: \"startObject\" };\n\t\t\tyield { type: \"endObject\" };\n\t\t\treturn;\n\t\t}\n\t\tif (isArrayHeaderContent(first.content)) {\n\t\t\tconst headerInfo = parseArrayHeaderLine(first.content, DEFAULT_DELIMITER);\n\t\t\tif (headerInfo) {\n\t\t\t\tawait cursor.advance();\n\t\t\t\tyield* decodeArrayFromHeaderAsync(headerInfo.header, headerInfo.inlineValues, cursor, 0, resolvedOptions);\n\t\t\t\treturn;\n\t\t\t}\n\t\t}\n\t\tawait cursor.advance();\n\t\tif (!!await cursor.atEnd() && !isKeyValueLineSync(first)) {\n\t\t\tyield {\n\t\t\t\ttype: \"primitive\",\n\t\t\t\tvalue: parsePrimitiveToken(first.content.trim())\n\t\t\t};\n\t\t\treturn;\n\t\t}\n\t\tyield { type: \"startObject\" };\n\t\tyield* decodeKeyValueAsync(first.content, cursor, 0, resolvedOptions);\n\t\twhile (!await cursor.atEnd()) {\n\t\t\tconst line = await cursor.peek();\n\t\t\tif (!line || line.depth !== 0) break;\n\t\t\tawait cursor.advance();\n\t\t\tyield* decodeKeyValueAsync(line.content, cursor, 0, resolvedOptions);\n\t\t}\n\t\tyield { type: \"endObject\" };\n\t} else yield* decodeStreamSync$1(source, options);\n}\nasync function* decodeKeyValueAsync(content, cursor, baseDepth, options) {\n\tconst arrayHeader = parseArrayHeaderLine(content, DEFAULT_DELIMITER);\n\tif (arrayHeader && arrayHeader.header.key) {\n\t\tyield {\n\t\t\ttype: \"key\",\n\t\t\tkey: arrayHeader.header.key\n\t\t};\n\t\tyield* decodeArrayFromHeaderAsync(arrayHeader.header, arrayHeader.inlineValues, cursor, baseDepth, options);\n\t\treturn;\n\t}\n\tconst { key, isQuoted } = parseKeyToken(content, 0);\n\tconst colonIndex = content.indexOf(COLON, key.length);\n\tconst rest = colonIndex >= 0 ? content.slice(colonIndex + 1).trim() : \"\";\n\tyield isQuoted ? {\n\t\ttype: \"key\",\n\t\tkey,\n\t\twasQuoted: true\n\t} : {\n\t\ttype: \"key\",\n\t\tkey\n\t};\n\tif (!rest) {\n\t\tconst nextLine = await cursor.peek();\n\t\tif (nextLine && nextLine.depth > baseDepth) {\n\t\t\tyield { type: \"startObject\" };\n\t\t\tyield* decodeObjectFieldsAsync(cursor, baseDepth + 1, options);\n\t\t\tyield { type: \"endObject\" };\n\t\t\treturn;\n\t\t}\n\t\tyield { type: \"startObject\" };\n\t\tyield { type: \"endObject\" };\n\t\treturn;\n\t}\n\tyield {\n\t\ttype: \"primitive\",\n\t\tvalue: parsePrimitiveToken(rest)\n\t};\n}\nasync function* decodeObjectFieldsAsync(cursor, baseDepth, options) {\n\tlet computedDepth;\n\twhile (!await cursor.atEnd()) {\n\t\tconst line = await cursor.peek();\n\t\tif (!line || line.depth < baseDepth) break;\n\t\tif (computedDepth === void 0 && line.depth >= baseDepth) computedDepth = line.depth;\n\t\tif (line.depth === computedDepth) {\n\t\t\tawait cursor.advance();\n\t\t\tyield* decodeKeyValueAsync(line.content, cursor, computedDepth, options);\n\t\t} else break;\n\t}\n}\nasync function* decodeArrayFromHeaderAsync(header, inlineValues, cursor, baseDepth, options) {\n\tyield {\n\t\ttype: \"startArray\",\n\t\tlength: header.length\n\t};\n\tif (inlineValues) {\n\t\tyield* decodeInlinePrimitiveArraySync(header, inlineValues, options);\n\t\tyield { type: \"endArray\" };\n\t\treturn;\n\t}\n\tif (header.fields && header.fields.length > 0) {\n\t\tyield* decodeTabularArrayAsync(header, cursor, baseDepth, options);\n\t\tyield { type: \"endArray\" };\n\t\treturn;\n\t}\n\tyield* decodeListArrayAsync(header, cursor, baseDepth, options);\n\tyield { type: \"endArray\" };\n}\nasync function* decodeTabularArrayAsync(header, cursor, baseDepth, options) {\n\tconst rowDepth = baseDepth + 1;\n\tlet rowCount = 0;\n\tlet startLine;\n\tlet endLine;\n\twhile (!await cursor.atEnd() && rowCount < header.length) {\n\t\tconst line = await cursor.peek();\n\t\tif (!line || line.depth < rowDepth) break;\n\t\tif (line.depth === rowDepth) {\n\t\t\tif (startLine === void 0) startLine = line.lineNumber;\n\t\t\tendLine = line.lineNumber;\n\t\t\tawait cursor.advance();\n\t\t\tconst values = parseDelimitedValues(line.content, header.delimiter);\n\t\t\tassertExpectedCount(values.length, header.fields.length, \"tabular row values\", options);\n\t\t\tconst primitives = mapRowValuesToPrimitives(values);\n\t\t\tyield { type: \"startObject\" };\n\t\t\tfor (let i = 0; i < header.fields.length; i++) {\n\t\t\t\tyield {\n\t\t\t\t\ttype: \"key\",\n\t\t\t\t\tkey: header.fields[i]\n\t\t\t\t};\n\t\t\t\tyield {\n\t\t\t\t\ttype: \"primitive\",\n\t\t\t\t\tvalue: primitives[i]\n\t\t\t\t};\n\t\t\t}\n\t\t\tyield { type: \"endObject\" };\n\t\t\trowCount++;\n\t\t} else break;\n\t}\n\tassertExpectedCount(rowCount, header.length, \"tabular rows\", options);\n\tif (options.strict && startLine !== void 0 && endLine !== void 0) validateNoBlankLinesInRange(startLine, endLine, cursor.getBlankLines(), options.strict, \"tabular array\");\n\tif (options.strict) validateNoExtraTabularRows(await cursor.peek(), rowDepth, header);\n}\nasync function* decodeListArrayAsync(header, cursor, baseDepth, options) {\n\tconst itemDepth = baseDepth + 1;\n\tlet itemCount = 0;\n\tlet startLine;\n\tlet endLine;\n\twhile (!await cursor.atEnd() && itemCount < header.length) {\n\t\tconst line = await cursor.peek();\n\t\tif (!line || line.depth < itemDepth) break;\n\t\tconst isListItem = line.content.startsWith(LIST_ITEM_PREFIX) || line.content === LIST_ITEM_MARKER;\n\t\tif (line.depth === itemDepth && isListItem) {\n\t\t\tif (startLine === void 0) startLine = line.lineNumber;\n\t\t\tendLine = line.lineNumber;\n\t\t\tyield* decodeListItemAsync(cursor, itemDepth, options);\n\t\t\tconst currentLine = cursor.current();\n\t\t\tif (currentLine) endLine = currentLine.lineNumber;\n\t\t\titemCount++;\n\t\t} else break;\n\t}\n\tassertExpectedCount(itemCount, header.length, \"list array items\", options);\n\tif (options.strict && startLine !== void 0 && endLine !== void 0) validateNoBlankLinesInRange(startLine, endLine, cursor.getBlankLines(), options.strict, \"list array\");\n\tif (options.strict) validateNoExtraListItems(await cursor.peek(), itemDepth, header.length);\n}\nasync function* decodeListItemAsync(cursor, baseDepth, options) {\n\tconst line = await cursor.next();\n\tif (!line) throw new ReferenceError(\"Expected list item\");\n\tlet afterHyphen;\n\tif (line.content === LIST_ITEM_MARKER) {\n\t\tyield { type: \"startObject\" };\n\t\tyield { type: \"endObject\" };\n\t\treturn;\n\t} else if (line.content.startsWith(LIST_ITEM_PREFIX)) afterHyphen = line.content.slice(LIST_ITEM_PREFIX.length);\n\telse throw new SyntaxError(`Expected list item to start with \"${LIST_ITEM_PREFIX}\"`);\n\tif (!afterHyphen.trim()) {\n\t\tyield { type: \"startObject\" };\n\t\tyield { type: \"endObject\" };\n\t\treturn;\n\t}\n\tif (isArrayHeaderContent(afterHyphen)) {\n\t\tconst arrayHeader = parseArrayHeaderLine(afterHyphen, DEFAULT_DELIMITER);\n\t\tif (arrayHeader) {\n\t\t\tyield* decodeArrayFromHeaderAsync(arrayHeader.header, arrayHeader.inlineValues, cursor, baseDepth, options);\n\t\t\treturn;\n\t\t}\n\t}\n\tif (isKeyValueContent(afterHyphen)) {\n\t\tyield { type: \"startObject\" };\n\t\tyield* decodeKeyValueAsync(afterHyphen, cursor, baseDepth, options);\n\t\tconst followDepth = baseDepth + 1;\n\t\twhile (!await cursor.atEnd()) {\n\t\t\tconst nextLine = await cursor.peek();\n\t\t\tif (!nextLine || nextLine.depth < followDepth) break;\n\t\t\tif (nextLine.depth === followDepth && !nextLine.content.startsWith(LIST_ITEM_PREFIX)) {\n\t\t\t\tawait cursor.advance();\n\t\t\t\tyield* decodeKeyValueAsync(nextLine.content, cursor, followDepth, options);\n\t\t\t} else break;\n\t\t}\n\t\tyield { type: \"endObject\" };\n\t\treturn;\n\t}\n\tyield {\n\t\ttype: \"primitive\",\n\t\tvalue: parsePrimitiveToken(afterHyphen)\n\t};\n}\n\n//#endregion\n//#region src/encode/normalize.ts\nfunction normalizeValue(value) {\n\tif (value === null) return null;\n\tif (typeof value === \"string\" || typeof value === \"boolean\") return value;\n\tif (typeof value === \"number\") {\n\t\tif (Object.is(value, -0)) return 0;\n\t\tif (!Number.isFinite(value)) return null;\n\t\treturn value;\n\t}\n\tif (typeof value === \"bigint\") {\n\t\tif (value >= Number.MIN_SAFE_INTEGER && value <= Number.MAX_SAFE_INTEGER) return Number(value);\n\t\treturn value.toString();\n\t}\n\tif (value instanceof Date) return value.toISOString();\n\tif (Array.isArray(value)) return value.map(normalizeValue);\n\tif (value instanceof Set) return Array.from(value).map(normalizeValue);\n\tif (value instanceof Map) return Object.fromEntries(Array.from(value, ([k, v]) => [String(k), normalizeValue(v)]));\n\tif (isPlainObject(value)) {\n\t\tconst normalized = {};\n\t\tfor (const key in value) if (Object.prototype.hasOwnProperty.call(value, key)) normalized[key] = normalizeValue(value[key]);\n\t\treturn normalized;\n\t}\n\treturn null;\n}\nfunction isJsonPrimitive(value) {\n\treturn value === null || typeof value === \"string\" || typeof value === \"number\" || typeof value === \"boolean\";\n}\nfunction isJsonArray(value) {\n\treturn Array.isArray(value);\n}\nfunction isJsonObject(value) {\n\treturn value !== null && typeof value === \"object\" && !Array.isArray(value);\n}\nfunction isEmptyObject(value) {\n\treturn Object.keys(value).length === 0;\n}\nfunction isPlainObject(value) {\n\tif (value === null || typeof value !== \"object\") return false;\n\tconst prototype = Object.getPrototypeOf(value);\n\treturn prototype === null || prototype === Object.prototype;\n}\nfunction isArrayOfPrimitives(value) {\n\treturn value.length === 0 || value.every((item) => isJsonPrimitive(item));\n}\nfunction isArrayOfArrays(value) {\n\treturn value.length === 0 || value.every((item) => isJsonArray(item));\n}\nfunction isArrayOfObjects(value) {\n\treturn value.length === 0 || value.every((item) => isJsonObject(item));\n}\n\n//#endregion\n//#region src/shared/validation.ts\n/**\n* Checks if a key can be used without quotes.\n*\n* @remarks\n* Valid unquoted keys must start with a letter or underscore,\n* followed by letters, digits, underscores, or dots.\n*/\nfunction isValidUnquotedKey(key) {\n\treturn /^[A-Z_][\\w.]*$/i.test(key);\n}\n/**\n* Checks if a key segment is a valid identifier for safe folding/expansion.\n*\n* @remarks\n* Identifier segments are more restrictive than unquoted keys:\n* - Must start with a letter or underscore\n* - Followed only by letters, digits, or underscores (no dots)\n* - Used for safe key folding and path expansion\n*/\nfunction isIdentifierSegment(key) {\n\treturn /^[A-Z_]\\w*$/i.test(key);\n}\n/**\n* Determines if a string value can be safely encoded without quotes.\n*\n* @remarks\n* A string needs quoting if it:\n* - Is empty\n* - Has leading or trailing whitespace\n* - Could be confused with a literal (boolean, null, number)\n* - Contains structural characters (colons, brackets, braces)\n* - Contains quotes or backslashes (need escaping)\n* - Contains control characters (newlines, tabs, etc.)\n* - Contains the active delimiter\n* - Starts with a list marker (hyphen)\n*/\nfunction isSafeUnquoted(value, delimiter = DEFAULT_DELIMITER) {\n\tif (!value) return false;\n\tif (value !== value.trim()) return false;\n\tif (isBooleanOrNullLiteral(value) || isNumericLike(value)) return false;\n\tif (value.includes(\":\")) return false;\n\tif (value.includes(\"\\\"\") || value.includes(\"\\\\\")) return false;\n\tif (/[[\\]{}]/.test(value)) return false;\n\tif (/[\\n\\r\\t]/.test(value)) return false;\n\tif (value.includes(delimiter)) return false;\n\tif (value.startsWith(LIST_ITEM_MARKER)) return false;\n\treturn true;\n}\n/**\n* Checks if a string looks like a number.\n*\n* @remarks\n* Match numbers like `42`, `-3.14`, `1e-6`, `05`, etc.\n*/\nfunction isNumericLike(value) {\n\treturn /^-?\\d+(?:\\.\\d+)?(?:e[+-]?\\d+)?$/i.test(value) || /^0\\d+$/.test(value);\n}\n\n//#endregion\n//#region src/decode/expand.ts\n/**\n* Symbol used to mark object keys that were originally quoted in the TOON source.\n* Quoted dotted keys should not be expanded, even if they meet expansion criteria.\n*/\nconst QUOTED_KEY_MARKER = Symbol(\"quotedKey\");\n/**\n* Expands dotted keys into nested objects in safe mode.\n*\n* @remarks\n* This function recursively traverses a decoded TOON value and expands any keys\n* containing dots (`.`) into nested object structures, provided all segments\n* are valid identifiers.\n*\n* Expansion rules:\n* - Keys containing dots are split into segments\n* - All segments must pass `isIdentifierSegment` validation\n* - Non-eligible keys (with special characters) are left as literal dotted keys\n* - Deep merge: When multiple dotted keys expand to the same path, their values are merged if both are objects\n* - Conflict handling:\n*   - `strict=true`: Throws TypeError on conflicts (non-object collision)\n*   - `strict=false`: LWW (silent overwrite)\n*\n* @param value - The decoded value to expand\n* @param strict - Whether to throw errors on conflicts\n* @returns The expanded value with dotted keys reconstructed as nested objects\n* @throws TypeError if conflicts occur in strict mode\n*/\nfunction expandPathsSafe(value, strict) {\n\tif (Array.isArray(value)) return value.map((item) => expandPathsSafe(item, strict));\n\tif (isJsonObject(value)) {\n\t\tconst expandedObject = {};\n\t\tconst quotedKeys = value[QUOTED_KEY_MARKER];\n\t\tfor (const [key, keyValue] of Object.entries(value)) {\n\t\t\tconst isQuoted = quotedKeys?.has(key);\n\t\t\tif (key.includes(DOT) && !isQuoted) {\n\t\t\t\tconst segments = key.split(DOT);\n\t\t\t\tif (segments.every((seg) => isIdentifierSegment(seg))) {\n\t\t\t\t\tinsertPathSafe(expandedObject, segments, expandPathsSafe(keyValue, strict), strict);\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\t\t\t}\n\t\t\tconst expandedValue = expandPathsSafe(keyValue, strict);\n\t\t\tif (key in expandedObject) {\n\t\t\t\tconst conflictingValue = expandedObject[key];\n\t\t\t\tif (canMerge(conflictingValue, expandedValue)) mergeObjects(conflictingValue, expandedValue, strict);\n\t\t\t\telse {\n\t\t\t\t\tif (strict) throw new TypeError(`Path expansion conflict at key \"${key}\": cannot merge ${typeof conflictingValue} with ${typeof expandedValue}`);\n\t\t\t\t\texpandedObject[key] = expandedValue;\n\t\t\t\t}\n\t\t\t} else expandedObject[key] = expandedValue;\n\t\t}\n\t\treturn expandedObject;\n\t}\n\treturn value;\n}\n/**\n* Inserts a value at a nested path, creating intermediate objects as needed.\n*\n* @remarks\n* This function walks the segment path, creating nested objects as needed.\n* When an existing value is encountered:\n* - If both are objects: deep merge (continue insertion)\n* - If values differ: conflict\n*   - strict=true: throw TypeError\n*   - strict=false: overwrite with new value (LWW)\n*\n* @param target - The object to insert into\n* @param segments - Array of path segments (e.g., ['data', 'metadata', 'items'])\n* @param value - The value to insert at the end of the path\n* @param strict - Whether to throw on conflicts\n* @throws TypeError if a conflict occurs in strict mode\n*/\nfunction insertPathSafe(target, segments, value, strict) {\n\tlet currentNode = target;\n\tfor (let i = 0; i < segments.length - 1; i++) {\n\t\tconst currentSegment = segments[i];\n\t\tconst segmentValue = currentNode[currentSegment];\n\t\tif (segmentValue === void 0) {\n\t\t\tconst newObj = {};\n\t\t\tcurrentNode[currentSegment] = newObj;\n\t\t\tcurrentNode = newObj;\n\t\t} else if (isJsonObject(segmentValue)) currentNode = segmentValue;\n\t\telse {\n\t\t\tif (strict) throw new TypeError(`Path expansion conflict at segment \"${currentSegment}\": expected object but found ${typeof segmentValue}`);\n\t\t\tconst newObj = {};\n\t\t\tcurrentNode[currentSegment] = newObj;\n\t\t\tcurrentNode = newObj;\n\t\t}\n\t}\n\tconst lastSeg = segments[segments.length - 1];\n\tconst destinationValue = currentNode[lastSeg];\n\tif (destinationValue === void 0) currentNode[lastSeg] = value;\n\telse if (canMerge(destinationValue, value)) mergeObjects(destinationValue, value, strict);\n\telse {\n\t\tif (strict) throw new TypeError(`Path expansion conflict at key \"${lastSeg}\": cannot merge ${typeof destinationValue} with ${typeof value}`);\n\t\tcurrentNode[lastSeg] = value;\n\t}\n}\n/**\n* Deep merges properties from source into target.\n*\n* @remarks\n* For each key in source:\n* - If key doesn't exist in target: copy it\n* - If both values are objects: recursively merge\n* - Otherwise: conflict (strict throws, non-strict overwrites)\n*\n* @param target - The target object to merge into\n* @param source - The source object to merge from\n* @param strict - Whether to throw on conflicts\n* @throws TypeError if a conflict occurs in strict mode\n*/\nfunction mergeObjects(target, source, strict) {\n\tfor (const [key, sourceValue] of Object.entries(source)) {\n\t\tconst targetValue = target[key];\n\t\tif (targetValue === void 0) target[key] = sourceValue;\n\t\telse if (canMerge(targetValue, sourceValue)) mergeObjects(targetValue, sourceValue, strict);\n\t\telse {\n\t\t\tif (strict) throw new TypeError(`Path expansion conflict at key \"${key}\": cannot merge ${typeof targetValue} with ${typeof sourceValue}`);\n\t\t\ttarget[key] = sourceValue;\n\t\t}\n\t}\n}\nfunction canMerge(a, b) {\n\treturn isJsonObject(a) && isJsonObject(b);\n}\n\n//#endregion\n//#region src/decode/event-builder.ts\nfunction buildValueFromEvents(events) {\n\tconst stack = [];\n\tlet root;\n\tfor (const event of events) switch (event.type) {\n\t\tcase \"startObject\": {\n\t\t\tconst obj = {};\n\t\t\tconst quotedKeys = /* @__PURE__ */ new Set();\n\t\t\tif (stack.length === 0) stack.push({\n\t\t\t\ttype: \"object\",\n\t\t\t\tobj,\n\t\t\t\tquotedKeys\n\t\t\t});\n\t\t\telse {\n\t\t\t\tconst parent = stack[stack.length - 1];\n\t\t\t\tif (parent.type === \"object\") {\n\t\t\t\t\tif (parent.currentKey === void 0) throw new Error(\"Object startObject event without preceding key\");\n\t\t\t\t\tparent.obj[parent.currentKey] = obj;\n\t\t\t\t\tparent.currentKey = void 0;\n\t\t\t\t} else if (parent.type === \"array\") parent.arr.push(obj);\n\t\t\t\tstack.push({\n\t\t\t\t\ttype: \"object\",\n\t\t\t\t\tobj,\n\t\t\t\t\tquotedKeys\n\t\t\t\t});\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\t\tcase \"endObject\": {\n\t\t\tif (stack.length === 0) throw new Error(\"Unexpected endObject event\");\n\t\t\tconst context = stack.pop();\n\t\t\tif (context.type !== \"object\") throw new Error(\"Mismatched endObject event\");\n\t\t\tif (context.quotedKeys.size > 0) Object.defineProperty(context.obj, QUOTED_KEY_MARKER, {\n\t\t\t\tvalue: context.quotedKeys,\n\t\t\t\tenumerable: false,\n\t\t\t\twritable: false,\n\t\t\t\tconfigurable: false\n\t\t\t});\n\t\t\tif (stack.length === 0) root = context.obj;\n\t\t\tbreak;\n\t\t}\n\t\tcase \"startArray\": {\n\t\t\tconst arr = [];\n\t\t\tif (stack.length === 0) stack.push({\n\t\t\t\ttype: \"array\",\n\t\t\t\tarr\n\t\t\t});\n\t\t\telse {\n\t\t\t\tconst parent = stack[stack.length - 1];\n\t\t\t\tif (parent.type === \"object\") {\n\t\t\t\t\tif (parent.currentKey === void 0) throw new Error(\"Array startArray event without preceding key\");\n\t\t\t\t\tparent.obj[parent.currentKey] = arr;\n\t\t\t\t\tparent.currentKey = void 0;\n\t\t\t\t} else if (parent.type === \"array\") parent.arr.push(arr);\n\t\t\t\tstack.push({\n\t\t\t\t\ttype: \"array\",\n\t\t\t\t\tarr\n\t\t\t\t});\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\t\tcase \"endArray\": {\n\t\t\tif (stack.length === 0) throw new Error(\"Unexpected endArray event\");\n\t\t\tconst context = stack.pop();\n\t\t\tif (context.type !== \"array\") throw new Error(\"Mismatched endArray event\");\n\t\t\tif (stack.length === 0) root = context.arr;\n\t\t\tbreak;\n\t\t}\n\t\tcase \"key\": {\n\t\t\tif (stack.length === 0) throw new Error(\"Key event outside of object context\");\n\t\t\tconst parent = stack[stack.length - 1];\n\t\t\tif (parent.type !== \"object\") throw new Error(\"Key event in non-object context\");\n\t\t\tparent.currentKey = event.key;\n\t\t\tif (event.wasQuoted) parent.quotedKeys.add(event.key);\n\t\t\tbreak;\n\t\t}\n\t\tcase \"primitive\":\n\t\t\tif (stack.length === 0) root = event.value;\n\t\t\telse {\n\t\t\t\tconst parent = stack[stack.length - 1];\n\t\t\t\tif (parent.type === \"object\") {\n\t\t\t\t\tif (parent.currentKey === void 0) throw new Error(\"Primitive event without preceding key in object\");\n\t\t\t\t\tparent.obj[parent.currentKey] = event.value;\n\t\t\t\t\tparent.currentKey = void 0;\n\t\t\t\t} else if (parent.type === \"array\") parent.arr.push(event.value);\n\t\t\t}\n\t\t\tbreak;\n\t}\n\tif (stack.length !== 0) throw new Error(\"Incomplete event stream: stack not empty at end\");\n\tif (root === void 0) throw new Error(\"No root value built from events\");\n\treturn root;\n}\n\n//#endregion\n//#region src/encode/folding.ts\n/**\n* Attempts to fold a single-key object chain into a dotted path.\n*\n* @remarks\n* Folding traverses nested objects with single keys, collapsing them into a dotted path.\n* It stops when:\n* - A non-single-key object is encountered\n* - An array is encountered (arrays are not \"single-key objects\")\n* - A primitive value is reached\n* - The flatten depth limit is reached\n* - Any segment fails safe mode validation\n*\n* Safe mode requirements:\n* - `options.keyFolding` must be `'safe'`\n* - Every segment must be a valid identifier (no dots, no special chars)\n* - The folded key must not collide with existing sibling keys\n* - No segment should require quoting\n*\n* @param key - The starting key to fold\n* @param value - The value associated with the key\n* @param siblings - Array of all sibling keys at this level (for collision detection)\n* @param options - Resolved encoding options\n* @returns A FoldResult if folding is possible, undefined otherwise\n*/\nfunction tryFoldKeyChain(key, value, siblings, options, rootLiteralKeys, pathPrefix, flattenDepth) {\n\tif (options.keyFolding !== \"safe\") return;\n\tif (!isJsonObject(value)) return;\n\tconst { segments, tail, leafValue } = collectSingleKeyChain(key, value, flattenDepth ?? options.flattenDepth);\n\tif (segments.length < 2) return;\n\tif (!segments.every((seg) => isIdentifierSegment(seg))) return;\n\tconst foldedKey = buildFoldedKey(segments);\n\tconst absolutePath = pathPrefix ? `${pathPrefix}${DOT}${foldedKey}` : foldedKey;\n\tif (siblings.includes(foldedKey)) return;\n\tif (rootLiteralKeys && rootLiteralKeys.has(absolutePath)) return;\n\treturn {\n\t\tfoldedKey,\n\t\tremainder: tail,\n\t\tleafValue,\n\t\tsegmentCount: segments.length\n\t};\n}\n/**\n* Collects a chain of single-key objects into segments.\n*\n* @remarks\n* Traverses nested objects, collecting keys until:\n* - A non-single-key object is found\n* - An array is encountered\n* - A primitive is reached\n* - An empty object is reached\n* - The depth limit is reached\n*\n* @param startKey - The initial key to start the chain\n* @param startValue - The value to traverse\n* @param maxDepth - Maximum number of segments to collect\n* @returns Object containing segments array, tail value, and leaf value\n*/\nfunction collectSingleKeyChain(startKey, startValue, maxDepth) {\n\tconst segments = [startKey];\n\tlet currentValue = startValue;\n\twhile (segments.length < maxDepth) {\n\t\tif (!isJsonObject(currentValue)) break;\n\t\tconst keys = Object.keys(currentValue);\n\t\tif (keys.length !== 1) break;\n\t\tconst nextKey = keys[0];\n\t\tconst nextValue = currentValue[nextKey];\n\t\tsegments.push(nextKey);\n\t\tcurrentValue = nextValue;\n\t}\n\tif (!isJsonObject(currentValue) || isEmptyObject(currentValue)) return {\n\t\tsegments,\n\t\ttail: void 0,\n\t\tleafValue: currentValue\n\t};\n\treturn {\n\t\tsegments,\n\t\ttail: currentValue,\n\t\tleafValue: currentValue\n\t};\n}\nfunction buildFoldedKey(segments) {\n\treturn segments.join(DOT);\n}\n\n//#endregion\n//#region src/encode/primitives.ts\nfunction encodePrimitive(value, delimiter) {\n\tif (value === null) return NULL_LITERAL;\n\tif (typeof value === \"boolean\") return String(value);\n\tif (typeof value === \"number\") return String(value);\n\treturn encodeStringLiteral(value, delimiter);\n}\nfunction encodeStringLiteral(value, delimiter = DEFAULT_DELIMITER) {\n\tif (isSafeUnquoted(value, delimiter)) return value;\n\treturn `${DOUBLE_QUOTE}${escapeString(value)}${DOUBLE_QUOTE}`;\n}\nfunction encodeKey(key) {\n\tif (isValidUnquotedKey(key)) return key;\n\treturn `${DOUBLE_QUOTE}${escapeString(key)}${DOUBLE_QUOTE}`;\n}\nfunction encodeAndJoinPrimitives(values, delimiter = DEFAULT_DELIMITER) {\n\treturn values.map((v) => encodePrimitive(v, delimiter)).join(delimiter);\n}\nfunction formatHeader(length, options) {\n\tconst key = options?.key;\n\tconst fields = options?.fields;\n\tconst delimiter = options?.delimiter ?? COMMA;\n\tlet header = \"\";\n\tif (key) header += encodeKey(key);\n\theader += `[${length}${delimiter !== DEFAULT_DELIMITER ? delimiter : \"\"}]`;\n\tif (fields) {\n\t\tconst quotedFields = fields.map((f) => encodeKey(f));\n\t\theader += `{${quotedFields.join(delimiter)}}`;\n\t}\n\theader += \":\";\n\treturn header;\n}\n\n//#endregion\n//#region src/encode/encoders.ts\nfunction* encodeJsonValue(value, options, depth) {\n\tif (isJsonPrimitive(value)) {\n\t\tconst encodedPrimitive = encodePrimitive(value, options.delimiter);\n\t\tif (encodedPrimitive !== \"\") yield encodedPrimitive;\n\t\treturn;\n\t}\n\tif (isJsonArray(value)) yield* encodeArrayLines(void 0, value, depth, options);\n\telse if (isJsonObject(value)) yield* encodeObjectLines(value, depth, options);\n}\nfunction* encodeObjectLines(value, depth, options, rootLiteralKeys, pathPrefix, remainingDepth) {\n\tconst keys = Object.keys(value);\n\tif (depth === 0 && !rootLiteralKeys) rootLiteralKeys = new Set(keys.filter((k) => k.includes(\".\")));\n\tconst effectiveFlattenDepth = remainingDepth ?? options.flattenDepth;\n\tfor (const [key, val] of Object.entries(value)) yield* encodeKeyValuePairLines(key, val, depth, options, keys, rootLiteralKeys, pathPrefix, effectiveFlattenDepth);\n}\nfunction* encodeKeyValuePairLines(key, value, depth, options, siblings, rootLiteralKeys, pathPrefix, flattenDepth) {\n\tconst currentPath = pathPrefix ? `${pathPrefix}${DOT}${key}` : key;\n\tconst effectiveFlattenDepth = flattenDepth ?? options.flattenDepth;\n\tif (options.keyFolding === \"safe\" && siblings) {\n\t\tconst foldResult = tryFoldKeyChain(key, value, siblings, options, rootLiteralKeys, pathPrefix, effectiveFlattenDepth);\n\t\tif (foldResult) {\n\t\t\tconst { foldedKey, remainder, leafValue, segmentCount } = foldResult;\n\t\t\tconst encodedFoldedKey = encodeKey(foldedKey);\n\t\t\tif (remainder === void 0) {\n\t\t\t\tif (isJsonPrimitive(leafValue)) {\n\t\t\t\t\tyield indentedLine(depth, `${encodedFoldedKey}: ${encodePrimitive(leafValue, options.delimiter)}`, options.indent);\n\t\t\t\t\treturn;\n\t\t\t\t} else if (isJsonArray(leafValue)) {\n\t\t\t\t\tyield* encodeArrayLines(foldedKey, leafValue, depth, options);\n\t\t\t\t\treturn;\n\t\t\t\t} else if (isJsonObject(leafValue) && isEmptyObject(leafValue)) {\n\t\t\t\t\tyield indentedLine(depth, `${encodedFoldedKey}:`, options.indent);\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (isJsonObject(remainder)) {\n\t\t\t\tyield indentedLine(depth, `${encodedFoldedKey}:`, options.indent);\n\t\t\t\tconst remainingDepth = effectiveFlattenDepth - segmentCount;\n\t\t\t\tconst foldedPath = pathPrefix ? `${pathPrefix}${DOT}${foldedKey}` : foldedKey;\n\t\t\t\tyield* encodeObjectLines(remainder, depth + 1, options, rootLiteralKeys, foldedPath, remainingDepth);\n\t\t\t\treturn;\n\t\t\t}\n\t\t}\n\t}\n\tconst encodedKey = encodeKey(key);\n\tif (isJsonPrimitive(value)) yield indentedLine(depth, `${encodedKey}: ${encodePrimitive(value, options.delimiter)}`, options.indent);\n\telse if (isJsonArray(value)) yield* encodeArrayLines(key, value, depth, options);\n\telse if (isJsonObject(value)) {\n\t\tyield indentedLine(depth, `${encodedKey}:`, options.indent);\n\t\tif (!isEmptyObject(value)) yield* encodeObjectLines(value, depth + 1, options, rootLiteralKeys, currentPath, effectiveFlattenDepth);\n\t}\n}\nfunction* encodeArrayLines(key, value, depth, options) {\n\tif (value.length === 0) {\n\t\tyield indentedLine(depth, formatHeader(0, {\n\t\t\tkey,\n\t\t\tdelimiter: options.delimiter\n\t\t}), options.indent);\n\t\treturn;\n\t}\n\tif (isArrayOfPrimitives(value)) {\n\t\tyield indentedLine(depth, encodeInlineArrayLine(value, options.delimiter, key), options.indent);\n\t\treturn;\n\t}\n\tif (isArrayOfArrays(value)) {\n\t\tif (value.every((arr) => isArrayOfPrimitives(arr))) {\n\t\t\tyield* encodeArrayOfArraysAsListItemsLines(key, value, depth, options);\n\t\t\treturn;\n\t\t}\n\t}\n\tif (isArrayOfObjects(value)) {\n\t\tconst header = extractTabularHeader(value);\n\t\tif (header) yield* encodeArrayOfObjectsAsTabularLines(key, value, header, depth, options);\n\t\telse yield* encodeMixedArrayAsListItemsLines(key, value, depth, options);\n\t\treturn;\n\t}\n\tyield* encodeMixedArrayAsListItemsLines(key, value, depth, options);\n}\nfunction* encodeArrayOfArraysAsListItemsLines(prefix, values, depth, options) {\n\tyield indentedLine(depth, formatHeader(values.length, {\n\t\tkey: prefix,\n\t\tdelimiter: options.delimiter\n\t}), options.indent);\n\tfor (const arr of values) if (isArrayOfPrimitives(arr)) {\n\t\tconst arrayLine = encodeInlineArrayLine(arr, options.delimiter);\n\t\tyield indentedListItem(depth + 1, arrayLine, options.indent);\n\t}\n}\nfunction encodeInlineArrayLine(values, delimiter, prefix) {\n\tconst header = formatHeader(values.length, {\n\t\tkey: prefix,\n\t\tdelimiter\n\t});\n\tconst joinedValue = encodeAndJoinPrimitives(values, delimiter);\n\tif (values.length === 0) return header;\n\treturn `${header} ${joinedValue}`;\n}\nfunction* encodeArrayOfObjectsAsTabularLines(prefix, rows, header, depth, options) {\n\tyield indentedLine(depth, formatHeader(rows.length, {\n\t\tkey: prefix,\n\t\tfields: header,\n\t\tdelimiter: options.delimiter\n\t}), options.indent);\n\tyield* writeTabularRowsLines(rows, header, depth + 1, options);\n}\nfunction extractTabularHeader(rows) {\n\tif (rows.length === 0) return;\n\tconst firstRow = rows[0];\n\tconst firstKeys = Object.keys(firstRow);\n\tif (firstKeys.length === 0) return;\n\tif (isTabularArray(rows, firstKeys)) return firstKeys;\n}\nfunction isTabularArray(rows, header) {\n\tfor (const row of rows) {\n\t\tif (Object.keys(row).length !== header.length) return false;\n\t\tfor (const key of header) {\n\t\t\tif (!(key in row)) return false;\n\t\t\tif (!isJsonPrimitive(row[key])) return false;\n\t\t}\n\t}\n\treturn true;\n}\nfunction* writeTabularRowsLines(rows, header, depth, options) {\n\tfor (const row of rows) yield indentedLine(depth, encodeAndJoinPrimitives(header.map((key) => row[key]), options.delimiter), options.indent);\n}\nfunction* encodeMixedArrayAsListItemsLines(prefix, items, depth, options) {\n\tyield indentedLine(depth, formatHeader(items.length, {\n\t\tkey: prefix,\n\t\tdelimiter: options.delimiter\n\t}), options.indent);\n\tfor (const item of items) yield* encodeListItemValueLines(item, depth + 1, options);\n}\nfunction* encodeObjectAsListItemLines(obj, depth, options) {\n\tif (isEmptyObject(obj)) {\n\t\tyield indentedLine(depth, LIST_ITEM_MARKER, options.indent);\n\t\treturn;\n\t}\n\tconst entries = Object.entries(obj);\n\tconst [firstKey, firstValue] = entries[0];\n\tconst encodedKey = encodeKey(firstKey);\n\tif (isJsonPrimitive(firstValue)) yield indentedListItem(depth, `${encodedKey}: ${encodePrimitive(firstValue, options.delimiter)}`, options.indent);\n\telse if (isJsonArray(firstValue)) if (isArrayOfPrimitives(firstValue)) yield indentedListItem(depth, encodeInlineArrayLine(firstValue, options.delimiter, firstKey), options.indent);\n\telse if (isArrayOfObjects(firstValue)) {\n\t\tconst header = extractTabularHeader(firstValue);\n\t\tif (header) {\n\t\t\tyield indentedListItem(depth, formatHeader(firstValue.length, {\n\t\t\t\tkey: firstKey,\n\t\t\t\tfields: header,\n\t\t\t\tdelimiter: options.delimiter\n\t\t\t}), options.indent);\n\t\t\tyield* writeTabularRowsLines(firstValue, header, depth + 1, options);\n\t\t} else {\n\t\t\tyield indentedListItem(depth, `${encodedKey}[${firstValue.length}]:`, options.indent);\n\t\t\tfor (const item of firstValue) yield* encodeObjectAsListItemLines(item, depth + 1, options);\n\t\t}\n\t} else {\n\t\tyield indentedListItem(depth, `${encodedKey}[${firstValue.length}]:`, options.indent);\n\t\tfor (const item of firstValue) yield* encodeListItemValueLines(item, depth + 1, options);\n\t}\n\telse if (isJsonObject(firstValue)) {\n\t\tyield indentedListItem(depth, `${encodedKey}:`, options.indent);\n\t\tif (!isEmptyObject(firstValue)) yield* encodeObjectLines(firstValue, depth + 2, options);\n\t}\n\tfor (let i = 1; i < entries.length; i++) {\n\t\tconst [key, value] = entries[i];\n\t\tyield* encodeKeyValuePairLines(key, value, depth + 1, options);\n\t}\n}\nfunction* encodeListItemValueLines(value, depth, options) {\n\tif (isJsonPrimitive(value)) yield indentedListItem(depth, encodePrimitive(value, options.delimiter), options.indent);\n\telse if (isJsonArray(value)) if (isArrayOfPrimitives(value)) yield indentedListItem(depth, encodeInlineArrayLine(value, options.delimiter), options.indent);\n\telse {\n\t\tyield indentedListItem(depth, formatHeader(value.length, { delimiter: options.delimiter }), options.indent);\n\t\tfor (const item of value) yield* encodeListItemValueLines(item, depth + 1, options);\n\t}\n\telse if (isJsonObject(value)) yield* encodeObjectAsListItemLines(value, depth, options);\n}\nfunction indentedLine(depth, content, indentSize) {\n\treturn \" \".repeat(indentSize * depth) + content;\n}\nfunction indentedListItem(depth, content, indentSize) {\n\treturn indentedLine(depth, LIST_ITEM_PREFIX + content, indentSize);\n}\n\n//#endregion\n//#region src/index.ts\n/**\n* Encodes a JavaScript value into TOON format string.\n*\n* @param input - Any JavaScript value (objects, arrays, primitives)\n* @param options - Optional encoding configuration\n* @returns TOON formatted string\n*\n* @example\n* ```ts\n* encode({ name: 'Alice', age: 30 })\n* // name: Alice\n* // age: 30\n*\n* encode({ users: [{ id: 1 }, { id: 2 }] })\n* // users[]:\n* //   - id: 1\n* //   - id: 2\n*\n* encode(data, { indent: 4, keyFolding: 'safe' })\n* ```\n*/\nfunction encode(input, options) {\n\treturn Array.from(encodeLines(input, options)).join(\"\\n\");\n}\n/**\n* Decodes a TOON format string into a JavaScript value.\n*\n* @param input - TOON formatted string\n* @param options - Optional decoding configuration\n* @returns Parsed JavaScript value (object, array, or primitive)\n*\n* @example\n* ```ts\n* decode('name: Alice\\nage: 30')\n* // { name: 'Alice', age: 30 }\n*\n* decode('users[]:\\n  - id: 1\\n  - id: 2')\n* // { users: [{ id: 1 }, { id: 2 }] }\n*\n* decode(toonString, { strict: false, expandPaths: 'safe' })\n* ```\n*/\nfunction decode(input, options) {\n\treturn decodeFromLines(input.split(\"\\n\"), options);\n}\n/**\n* Encodes a JavaScript value into TOON format as a sequence of lines.\n*\n* This function yields TOON lines one at a time without building the full string,\n* making it suitable for streaming large outputs to files, HTTP responses, or process stdout.\n*\n* @param input - Any JavaScript value (objects, arrays, primitives)\n* @param options - Optional encoding configuration\n* @returns Iterable of TOON lines (without trailing newlines)\n*\n* @example\n* ```ts\n* // Stream to stdout\n* for (const line of encodeLines({ name: 'Alice', age: 30 })) {\n*   console.log(line)\n* }\n*\n* // Collect to array\n* const lines = Array.from(encodeLines(data))\n*\n* // Equivalent to encode()\n* const toonString = Array.from(encodeLines(data, options)).join('\\n')\n* ```\n*/\nfunction encodeLines(input, options) {\n\treturn encodeJsonValue(normalizeValue(input), resolveOptions(options), 0);\n}\n/**\n* Decodes TOON format from pre-split lines into a JavaScript value.\n*\n* This is a convenience wrapper around the streaming decoder that builds\n* the full value in memory. Useful when you already have lines as an array\n* or iterable and want the standard decode behavior with path expansion support.\n*\n* @param lines - Iterable of TOON lines (without newlines)\n* @param options - Optional decoding configuration (supports expandPaths)\n* @returns Parsed JavaScript value (object, array, or primitive)\n*\n* @example\n* ```ts\n* const lines = ['name: Alice', 'age: 30']\n* decodeFromLines(lines)\n* // { name: 'Alice', age: 30 }\n* ```\n*/\nfunction decodeFromLines(lines, options) {\n\tconst resolvedOptions = resolveDecodeOptions(options);\n\tconst decodedValue = buildValueFromEvents(decodeStreamSync$1(lines, {\n\t\tindent: resolvedOptions.indent,\n\t\tstrict: resolvedOptions.strict\n\t}));\n\tif (resolvedOptions.expandPaths === \"safe\") return expandPathsSafe(decodedValue, resolvedOptions.strict);\n\treturn decodedValue;\n}\n/**\n* Synchronously decodes TOON lines into a stream of JSON events.\n*\n* This function yields structured events (startObject, endObject, startArray, endArray,\n* key, primitive) that represent the JSON data model without building the full value tree.\n* Useful for streaming processing, custom transformations, or memory-efficient parsing.\n*\n* @remarks\n* Path expansion (`expandPaths: 'safe'`) is not supported in streaming mode.\n*\n* @param lines - Iterable of TOON lines (without newlines)\n* @param options - Optional decoding configuration (expandPaths not supported)\n* @returns Iterable of JSON stream events\n*\n* @example\n* ```ts\n* const lines = ['name: Alice', 'age: 30']\n* for (const event of decodeStreamSync(lines)) {\n*   console.log(event)\n*   // { type: 'startObject' }\n*   // { type: 'key', key: 'name' }\n*   // { type: 'primitive', value: 'Alice' }\n*   // ...\n* }\n* ```\n*/\nfunction decodeStreamSync(lines, options) {\n\treturn decodeStreamSync$1(lines, options);\n}\n/**\n* Asynchronously decodes TOON lines into a stream of JSON events.\n*\n* This function yields structured events (startObject, endObject, startArray, endArray,\n* key, primitive) that represent the JSON data model without building the full value tree.\n* Supports both sync and async iterables for maximum flexibility with file streams,\n* network responses, or other async sources.\n*\n* @remarks\n* Path expansion (`expandPaths: 'safe'`) is not supported in streaming mode.\n*\n* @param source - Async or sync iterable of TOON lines (without newlines)\n* @param options - Optional decoding configuration (expandPaths not supported)\n* @returns Async iterable of JSON stream events\n*\n* @example\n* ```ts\n* const fileStream = createReadStream('data.toon', 'utf-8')\n* const lines = splitLines(fileStream) // Async iterable of lines\n*\n* for await (const event of decodeStream(lines)) {\n*   console.log(event)\n*   // { type: 'startObject' }\n*   // { type: 'key', key: 'name' }\n*   // { type: 'primitive', value: 'Alice' }\n*   // ...\n* }\n* ```\n*/\nfunction decodeStream(source, options) {\n\treturn decodeStream$1(source, options);\n}\nfunction resolveOptions(options) {\n\treturn {\n\t\tindent: options?.indent ?? 2,\n\t\tdelimiter: options?.delimiter ?? DEFAULT_DELIMITER,\n\t\tkeyFolding: options?.keyFolding ?? \"off\",\n\t\tflattenDepth: options?.flattenDepth ?? Number.POSITIVE_INFINITY\n\t};\n}\nfunction resolveDecodeOptions(options) {\n\treturn {\n\t\tindent: options?.indent ?? 2,\n\t\tstrict: options?.strict ?? true,\n\t\texpandPaths: options?.expandPaths ?? \"off\"\n\t};\n}\n\n//#endregion\nexport { DEFAULT_DELIMITER, DELIMITERS, decode, decodeFromLines, decodeStream, decodeStreamSync, encode, encodeLines };","export type DataKind = \"math\" | \"url\" | \"output_text\" | \"input_text\" | \"image\" | \"image_url\" | \"text\" | \"input_image\" | \"input_url\" | \"json\" | \"markdown\" | \"code\" | \"entity\" | \"structured\" | \"unknown\";\nexport type DataInput = {\n    dataSource: string | Blob | File | any,\n    dataKind?: DataKind | null,\n    context?: DataContext | null\n}\n\nexport type DataContext = {\n    existingData?: any;\n    entityType?: string;\n    operation?: \"create\" | \"modify\" | \"merge\" | \"analyze\" | \"extract\";\n    filters?: DataFilter[];\n    searchTerms?: string[];\n    priority?: \"low\" | \"medium\" | \"high\";\n}\n\nexport type DataFilter = {\n    field: string;\n    operator: \"eq\" | \"neq\" | \"contains\" | \"startsWith\" | \"endsWith\" | \"gt\" | \"lt\" | \"gte\" | \"lte\" | \"in\" | \"nin\" | \"exists\" | \"regex\";\n    value: any;\n    caseSensitive?: boolean;\n}\n\nexport type ModificationInstruction = {\n    action: \"update\" | \"delete\" | \"merge\" | \"append\" | \"replace\" | \"transform\";\n    target: string;\n    value?: any;\n    conditions?: DataFilter[];\n    transformFn?: string;\n}\n\n//\nexport const PROMPT_COMPUTE_EFFORT = (data: DataInput): \"low\" | \"medium\" | \"high\" => {\n    const context = data?.context;\n\n    // High effort for complex operations\n    if (context?.operation === \"merge\" || context?.operation === \"modify\") return \"high\";\n    if (context?.filters && context.filters.length > 3) return \"high\";\n    if (data?.dataKind === \"math\") return \"high\";\n    if (data?.dataKind === \"structured\" || data?.dataKind === \"entity\") return \"high\";\n\n    // Blob/File handling\n    if (data?.dataSource instanceof Blob || data?.dataSource instanceof File) {\n        const size = data.dataSource.size;\n        if (size > 1024 * 1024) return \"high\"; // >1MB (keep existing logic for effort calculation)\n        if (data?.dataKind === \"image\") return \"medium\";\n        return \"medium\";\n    }\n\n    // String handling with context\n    if (typeof data?.dataSource === \"string\") {\n        const len = data.dataSource.length;\n        if (len > 10000) return \"high\";\n        if (data?.dataSource?.includes?.(\"math\")) return \"high\";\n        if (data?.dataKind === \"json\" || data?.dataKind === \"code\") return \"medium\";\n        if (context?.searchTerms?.length) return \"medium\";\n        return \"medium\";\n    }\n\n    // Object handling\n    if (typeof data?.dataSource === \"object\" && data?.dataSource !== null) {\n        const keys = Object.keys(data.dataSource);\n        if (keys.length > 20) return \"high\";\n        if (context?.existingData) return \"high\";\n        return \"medium\";\n    }\n\n    return \"medium\";\n}\n\n//\nexport const COMPUTE_TEMPERATURE = (data: DataInput): number => {\n    const context = data?.context;\n\n    // Deterministic operations need low temperature\n    if (context?.operation === \"extract\" || context?.operation === \"analyze\") return 0.1;\n    if (context?.operation === \"modify\" && context?.existingData) return 0.2;\n    if (data?.dataKind === \"math\") return 0.1;\n    if (data?.dataKind === \"json\" || data?.dataKind === \"structured\") return 0.2;\n    if (data?.dataKind === \"code\") return 0.3;\n\n    // Creative operations can use higher temperature\n    if (context?.operation === \"create\") return 0.6;\n\n    // Default by kind\n    if (data?.dataKind === \"url\") return 0.3;\n    if (data?.dataKind === \"input_image\") return 0.4;\n    if (data?.dataKind === \"input_text\") return 0.5;\n    if (data?.dataKind === \"markdown\") return 0.5;\n\n    return 0.4;\n}\n\n//\nexport const typesForKind: Record<DataKind, \"input_text\" | \"image_url\" | \"input_image\" | \"input_url\" | \"text_search_result\" | \"json_schema\" | \"json_schema_search_result\"> = {\n    \"math\": \"input_text\",\n    \"url\": \"input_image\",\n    \"text\": \"input_text\",\n    \"input_text\": \"input_text\",\n    \"output_text\": \"input_text\",\n    \"image_url\": \"input_image\",\n    \"image\": \"input_image\",\n    \"input_image\": \"input_image\",\n    \"input_url\": \"input_image\",\n    \"json\": \"input_text\",\n    \"markdown\": \"input_text\",\n    \"code\": \"input_text\",\n    \"entity\": \"input_text\",\n    \"structured\": \"input_text\"\n}\n\n//\nexport const getDataKindByMIMEType = (mime: string): DataKind => {\n    if (!mime) return \"input_text\";\n    const lower = mime.toLowerCase();\n    if (lower.includes(\"image\")) return \"input_image\";\n    if (lower.includes(\"json\")) return \"json\";\n    if (lower.includes(\"javascript\") || lower.includes(\"typescript\")) return \"code\";\n    if (lower.includes(\"markdown\") || lower.includes(\"md\")) return \"markdown\";\n    if (lower.includes(\"url\")) return \"input_url\";\n    if (lower.includes(\"text/html\")) return \"markdown\";\n    if (lower.includes(\"text/plain\")) return \"input_text\";\n    return \"input_text\";\n}\n\n//\nexport const detectDataKindFromContent = (content: string): DataKind => {\n    if (!content || typeof content !== \"string\") return \"input_text\";\n\n    const trimmed = content.trim();\n\n    // Check for JSON\n    if ((trimmed.startsWith(\"{\") && trimmed.endsWith(\"}\")) ||\n        (trimmed.startsWith(\"[\") && trimmed.endsWith(\"]\"))) {\n        try { JSON.parse(trimmed); return \"json\"; } catch { /* not valid JSON */ }\n    }\n\n    // Check for URL\n    if (URL.canParse(trimmed?.trim?.() || \"\", typeof (typeof window != \"undefined\" ? window : globalThis)?.location == \"undefined\" ? undefined : ((typeof window != \"undefined\" ? window : globalThis)?.location?.origin || \"\"))) return \"url\";\n\n    // Check for base64 image\n    if (trimmed.startsWith(\"data:image/\") && trimmed.includes(\";base64,\")) return \"input_image\";\n\n    // Check for math expressions\n    if (/\\$\\$[\\s\\S]+\\$\\$|\\$[^$]+\\$|\\\\begin\\{equation\\}/.test(trimmed)) return \"math\";\n\n    // Check for code\n    if (/```[\\s\\S]+```|^(function|const|let|var|class|import|export)\\s/m.test(trimmed)) return \"code\";\n\n    // Check for markdown\n    if (/^#{1,6}\\s|^\\*\\*|^-\\s|\\[.+\\]\\(.+\\)|^>\\s/m.test(trimmed)) return \"markdown\";\n\n    return \"input_text\";\n}\n\n//\nexport const actionWithDataType = (data: DataInput): string => {\n    const context = data?.context;\n    const kindType = typesForKind?.[data?.dataKind || \"input_text\"];\n\n    // Build context-aware prompt based on operation\n    const contextPrompt = buildContextPrompt(context);\n\n    switch (kindType) {\n        case \"input_image\":\n            return `${contextPrompt}\n\nRecognize data from image, also preferred to orient by fonts in image.\n\nAfter recognition, do not include or remember image itself.\n\n---\n\nIn (\\`recognized_data\\` key), can be written phone numbers, emails, URLs, dates, times, codes, etc. Additional formatting rules:\n\nIn recognized from image data (what you seen in image), do:\n- If textual content, format as Markdown string (multiline).\n- If phone number, format as as correct phone number (in normalized format).\n  - Also, if phone numbers (for example starts with +7, format as 8), replace to correct regional code.\n  - Remove brackets, parentheses, spaces or other symbols from phone number.\n  - Trim spaces from phone number.\n- If email, format as as correct email (in normalized format), and trim spaces from email.\n- If URL, format as as correct URL (in normalized format), and unicode codes to human readable, and trim spaces from URL.\n- If date, format as as correct date (in normalized format).\n- If time, format as as correct time (in normalized format).\n- If math (expression, equation, formula), format as $KaTeX$\n- If table (or looks alike table), format as | table |\n- If image, format as [$image$]($image$)\n- If code, format as \\`\\`\\`$code$\\`\\`\\` (multiline) or \\`$code$\\` (single-line)\n- If JSON, format as correct JSON string, and trim spaces from JSON string.\n- If other, format as $text$.\n- If seen alike list, format as list (in markdown format).\n\n---\n\nSome additional actions:\n- Collect some special data tags and keywords (if has any).\n- Also, can you provide in markdown pre-formatted free-form analyzed or recognized verbose data (in \\`verbose_data\\` key).\n\n---\n\nCRITICAL OUTPUT FORMAT: Return ONLY valid JSON. No markdown code blocks, no explanations, no prose.\nYour response must start with { or [ and end with } or ].\n\nExpected output structure:\n{\n    \"keywords_and_tags\": [\"string array\"],\n    \"recognized_data\": [\"any array\"],\n    \"verbose_data\": \"markdown string\",\n    \"using_ready\": true,\n    \"confidence\": 0.95,\n    \"suggested_type\": \"document_type\"\n}\n`;\n\n        case \"input_text\":\n            return `${contextPrompt}\n\nAnalyze text and extract specific or special data from it, also normalize data by those rules...\n\n---\n\nIn (\\`recognized_data\\` key), can be written phone numbers, emails, URLs, dates, times, codes, etc. Additional formatting rules:\n\nNormalize phone numbers, emails, URLs, dates, times, codes, etc for best efforts and by those rules.\n- If phone number, format as as correct phone number (in normalized format).\n  - If phone numbers (for example starts with +7, format as 8), replace to correct regional code.\n  - Trim spaces from phone numbers, emails, URLs, dates, times, codes, etc.\n  - Remove brackets, parentheses, spaces or other symbols from phone numbers.\n- If email, format as as correct email (in normalized format), and trim spaces from email.\n- If URL, format as as correct URL (in normalized format), and unicode codes to human readable, and trim spaces from URL.\n- If date, format as as correct date (in normalized format).\n- If time, format as as correct time (in normalized format).\n- If math, format as $KaTeX$\n- If table, format as | table |\n- If image, format as [$image$]($image$)\n- If code, format as \\`\\`\\`$code$\\`\\`\\` (multiline) or \\`$code$\\` (single-line)\n- If JSON, format as correct JSON string, and trim spaces from JSON string.\n- If other, format as $text$.\n- If seen alike list, format as list (in markdown format).\n\n---\n\nSome additional actions:\n- Collect some special data tags and keywords (if has any).\n- Also, can you provide in markdown pre-formatted free-form analyzed or recognized verbose data (in \\`verbose_data\\` key).\n- Detect entity type if applicable (task, event, person, place, service, item, etc.)\n\n---\n\nCRITICAL OUTPUT FORMAT: Return ONLY valid JSON. No markdown code blocks, no explanations, no prose.\nYour response must start with { or [ and end with } or ].\n\nExpected output structure:\n{\n    \"keywords_and_tags\": [\"string array\"],\n    \"recognized_data\": [\"any array\"],\n    \"verbose_data\": \"markdown string\",\n    \"using_ready\": true,\n    \"confidence\": 0.95,\n    \"suggested_type\": \"entity_type\",\n    \"suggested_modifications\": []\n}\n`;\n    }\n    return contextPrompt || \"\";\n}\n\n//\nconst buildContextPrompt = (context?: DataContext | null): string => {\n    if (!context) return \"\";\n\n    const parts: string[] = [];\n\n    if (context.operation) {\n        const opDescriptions: Record<string, string> = {\n            create: \"Create new data entries based on provided information.\",\n            modify: \"Modify existing data with provided changes while preserving structure.\",\n            merge: \"Intelligently merge new data with existing data, avoiding duplicates.\",\n            analyze: \"Analyze and extract structured information from the data.\",\n            extract: \"Extract specific data points matching the criteria.\"\n        };\n        parts.push(`Operation: ${opDescriptions[context.operation] || context.operation}`);\n    }\n\n    if (context.entityType) {\n        parts.push(`Target entity type: ${context.entityType}`);\n    }\n\n    if (context.existingData) {\n        parts.push(`Existing data context provided - consider for merge/update operations.`);\n    }\n\n    if (context.filters?.length) {\n        const filterDesc = context.filters.map(f =>\n            `${f.field} ${f.operator} ${JSON.stringify(f.value)}`\n        ).join(\", \");\n        parts.push(`Apply filters: ${filterDesc}`);\n    }\n\n    if (context.searchTerms?.length) {\n        parts.push(`Search terms: ${context.searchTerms.join(\", \")}`);\n    }\n\n    if (context.priority) {\n        parts.push(`Priority level: ${context.priority}`);\n    }\n\n    return parts.length ? `Context:\\n${parts.join(\"\\n\")}\\n\\n---\\n` : \"\";\n}\n\n//\nexport const buildModificationPrompt = (instructions: ModificationInstruction[]): string => {\n    if (!instructions?.length) return \"\";\n\n    const parts = instructions.map((inst, i) => {\n        const condStr = inst.conditions?.length\n            ? ` when ${inst.conditions.map(c => `${c.field} ${c.operator} ${JSON.stringify(c.value)}`).join(\" AND \")}`\n            : \"\";\n\n        switch (inst.action) {\n            case \"update\":\n                return `${i + 1}. UPDATE field \"${inst.target}\" to ${JSON.stringify(inst.value)}${condStr}`;\n            case \"delete\":\n                return `${i + 1}. DELETE field \"${inst.target}\"${condStr}`;\n            case \"merge\":\n                return `${i + 1}. MERGE into \"${inst.target}\" with ${JSON.stringify(inst.value)}${condStr}`;\n            case \"append\":\n                return `${i + 1}. APPEND ${JSON.stringify(inst.value)} to \"${inst.target}\"${condStr}`;\n            case \"replace\":\n                return `${i + 1}. REPLACE \"${inst.target}\" with ${JSON.stringify(inst.value)}${condStr}`;\n            case \"transform\":\n                return `${i + 1}. TRANSFORM \"${inst.target}\" using: ${inst.transformFn}${condStr}`;\n            default:\n                return \"\";\n        }\n    }).filter(Boolean);\n\n    return parts.length\n        ? `\\nModification instructions:\\n${parts.join(\"\\n\")}\\n`\n        : \"\";\n}\n\n//\nexport const DATA_MODIFICATION_PROMPT = `\nYou are a data modification assistant. Your task is to modify existing data based on the provided instructions.\n\nRules for modification:\n1. Preserve the original data structure unless explicitly asked to change it.\n2. Apply modifications in order, one by one.\n3. Validate data types match the schema.\n4. Return the complete modified entity, not just the changes.\n5. If a modification cannot be applied, include it in the \"errors\" array with explanation.\n\nCRITICAL: Output ONLY valid JSON. No markdown code blocks, no explanations, no prose.\nYour response must start with { and end with }.\n\nExpected output structure:\n{\n    \"modified_entity\": { /* complete modified entity */ },\n    \"changes_made\": [ /* list of applied changes */ ],\n    \"errors\": [ /* list of failed modifications with reasons */ ],\n    \"warnings\": [ /* non-critical issues */ ]\n}\n`;\n\n//\nexport const DATA_SELECTION_PROMPT = `\nYou are a data selection and filtering assistant. Your task is to find and select data matching the criteria.\n\nSelection rules:\n1. Apply all filters in order (AND logic by default).\n2. Rank results by relevance to search terms.\n3. Include confidence scores for fuzzy matches.\n4. Group similar results to avoid duplicates.\n\nCRITICAL: Output ONLY valid JSON. No markdown code blocks, no explanations, no prose.\nYour response must start with { and end with }.\n\nExpected output structure:\n{\n    \"selected_items\": [ /* items matching criteria */ ],\n    \"total_matches\": number,\n    \"filter_stats\": { /* breakdown by filter */ },\n    \"suggestions\": [ /* related items that might be relevant */ ]\n}\n`;\n\n//\nexport const ENTITY_MERGE_PROMPT = `\nYou are an entity merging assistant. Your task is to intelligently merge multiple entities or data sources.\n\nMerge rules:\n1. Prefer newer/more complete data when conflicts arise.\n2. Combine arrays without duplicates.\n3. Merge nested objects recursively.\n4. Preserve IDs and relationships.\n5. Track the source of each merged field.\n\nCRITICAL: Output ONLY valid JSON. No markdown code blocks, no explanations, no prose.\nYour response must start with { and end with }.\n\nExpected output structure:\n{\n    \"merged_entity\": { /* result of merge */ },\n    \"conflicts_resolved\": [ /* list of conflicts and how they were resolved */ ],\n    \"sources_used\": [ /* which source contributed what */ ],\n    \"merge_confidence\": number\n}\n`;\n","/**\n * Robust AI Response Parser\n *\n * Handles extraction of JSON from AI responses that may include:\n * - Pure JSON strings\n * - JSON wrapped in markdown code blocks (```json ... ```)\n * - Multiple JSON code blocks (returns first valid one)\n * - JSON with trailing/leading whitespace\n * - JSON with BOM characters\n * - Partial or malformed JSON (best-effort recovery)\n *\n * @see https://platform.openai.com/docs/api-reference/responses\n */\n\nimport { JSOX } from \"jsox\";\n\nexport type ParseResult<T = unknown> = {\n    ok: boolean;\n    data?: T;\n    raw?: string;\n    error?: string;\n    source?: \"direct\" | \"markdown_block\" | \"recovered\" | \"fallback\";\n};\n\n/**\n * Regex patterns for extracting JSON from various formats.\n * Ordered by specificity - most specific patterns first.\n */\nconst JSON_EXTRACTION_PATTERNS = [\n    // ```json ... ``` or ```JSON ... ``` (case insensitive)\n    /```json\\s*\\n?([\\s\\S]*?)\\n?```/i,\n    // ```toon ... ``` (custom format used in project)\n    /```toon\\s*\\n?([\\s\\S]*?)\\n?```/i,\n    // Generic code block ``` ... ```\n    /```\\s*\\n?([\\s\\S]*?)\\n?```/,\n    // JSON in curly braces (object)\n    /(\\{[\\s\\S]*\\})/,\n    // JSON array\n    /(\\[[\\s\\S]*\\])/,\n] as const;\n\n/**\n * Clean raw text from common issues before parsing.\n */\nconst cleanRawText = (text: string): string => {\n    if (!text || typeof text !== \"string\") return \"\";\n\n    return text\n        // Remove BOM\n        .replace(/^\\uFEFF/, \"\")\n        // Remove zero-width characters\n        .replace(/[\\u200B-\\u200D\\uFEFF]/g, \"\")\n        // Normalize line endings\n        .replace(/\\r\\n/g, \"\\n\")\n        .replace(/\\r/g, \"\\n\")\n        // Trim whitespace\n        .trim();\n};\n\n/**\n * Attempt to fix common JSON issues.\n */\nconst attemptJSONRecovery = (text: string): string => {\n    let cleaned = text;\n\n    // Remove trailing commas before ] or }\n    cleaned = cleaned.replace(/,(\\s*[}\\]])/g, \"$1\");\n\n    // Fix unescaped newlines in strings (very basic)\n    // This is a simple heuristic - won't catch all cases\n    cleaned = cleaned.replace(/:\\s*\"([^\"]*)\\n([^\"]*)\"/g, (match, p1, p2) => {\n        return `: \"${p1}\\\\n${p2}\"`;\n    });\n\n    // Remove control characters except newlines and tabs\n    cleaned = cleaned.replace(/[\\x00-\\x08\\x0B\\x0C\\x0E-\\x1F]/g, \"\");\n\n    return cleaned;\n};\n\n/**\n * Try to parse JSON using multiple strategies.\n */\nexport const tryParseJSON = <T = unknown>(text: string): { ok: boolean; data?: T; error?: string } => {\n    if (!text) return { ok: false, error: \"Empty input\" };\n\n    // Strategy 1: Direct JSOX parse (more lenient than JSON.parse)\n    try {\n        const data = JSOX.parse(text) as T;\n        return { ok: true, data };\n    } catch { /* continue */ }\n\n    // Strategy 2: Standard JSON.parse\n    try {\n        const data = JSON.parse(text) as T;\n        return { ok: true, data };\n    } catch { /* continue */ }\n\n    // Strategy 3: Try with recovery\n    try {\n        const recovered = attemptJSONRecovery(text);\n        const data = JSOX.parse(recovered) as T;\n        return { ok: true, data };\n    } catch { /* continue */ }\n\n    // Strategy 4: Try removing any leading/trailing non-JSON characters\n    try {\n        const match = text.match(/^[^{[]*([{\\[][\\s\\S]*[}\\]])[^}\\]]*$/);\n        if (match?.[1]) {\n            const data = JSOX.parse(match[1]) as T;\n            return { ok: true, data };\n        }\n    } catch { /* continue */ }\n\n    return { ok: false, error: \"Failed to parse JSON with all strategies\" };\n};\n\n/**\n * Extract JSON from AI response text.\n * Handles markdown code blocks, raw JSON, and various edge cases.\n *\n * @param response - Raw AI response string\n * @returns ParseResult with extracted data or error\n */\nexport const extractJSONFromAIResponse = <T = unknown>(response: string | null | undefined): ParseResult<T> => {\n    if (response == null) {\n        return { ok: false, error: \"Response is null or undefined\" };\n    }\n\n    if (typeof response !== \"string\") {\n        // If already an object, return as-is\n        if (typeof response === \"object\") {\n            return { ok: true, data: response as T, source: \"direct\" };\n        }\n        return { ok: false, error: `Expected string, got ${typeof response}` };\n    }\n\n    const cleaned = cleanRawText(response);\n    if (!cleaned) {\n        return { ok: false, error: \"Response is empty after cleaning\", raw: response };\n    }\n\n    // First, try direct parsing (fastest path)\n    const directResult = tryParseJSON<T>(cleaned);\n    if (directResult.ok) {\n        return { ok: true, data: directResult.data, raw: response, source: \"direct\" };\n    }\n\n    // Try extracting from markdown code blocks\n    for (const pattern of JSON_EXTRACTION_PATTERNS) {\n        const match = cleaned.match(pattern);\n        if (match?.[1]) {\n            const extracted = cleanRawText(match[1]);\n            const result = tryParseJSON<T>(extracted);\n            if (result.ok) {\n                return {\n                    ok: true,\n                    data: result.data,\n                    raw: response,\n                    source: \"markdown_block\"\n                };\n            }\n        }\n    }\n\n    // Try to find any JSON-like structure and parse it\n    const jsonLikeMatch = cleaned.match(/(\\{[\\s\\S]+\\}|\\[[\\s\\S]+\\])/);\n    if (jsonLikeMatch?.[1]) {\n        const recovered = attemptJSONRecovery(jsonLikeMatch[1]);\n        const result = tryParseJSON<T>(recovered);\n        if (result.ok) {\n            return {\n                ok: true,\n                data: result.data,\n                raw: response,\n                source: \"recovered\"\n            };\n        }\n    }\n\n    // Last resort: return as text in a structured format\n    return {\n        ok: false,\n        error: \"Could not extract valid JSON from response\",\n        raw: response\n    };\n};\n\n/**\n * Parse AI response with guaranteed JSON output.\n * Falls back to a wrapper object if parsing fails.\n *\n * @param response - Raw AI response\n * @param fallbackKey - Key to use for wrapping raw text (default: \"data\")\n */\nexport const parseAIResponseSafe = <T = unknown>(\n    response: string | null | undefined,\n    fallbackKey: string = \"data\"\n): { ok: boolean; data: T | { [key: string]: string }; raw?: any; source: ParseResult[\"source\"]; wasRecovered: boolean; error?: string } => {\n    const result = extractJSONFromAIResponse<T>(response) as { ok: boolean; data?: T; error?: string; source: ParseResult[\"source\"]; raw?: any };\n\n    if (result.ok && result.data !== undefined) {\n        return {\n            raw: result.raw || response,\n            ok: true,\n            data: result.data,\n            source: result.source,\n            wasRecovered: result.source === \"recovered\",\n            error: result.error || undefined\n        };\n    }\n\n    // Return fallback wrapper\n    return {\n        raw: result.raw || response,\n        ok: false,\n        data: { [fallbackKey]: result.raw || String(response) } as { [key: string]: string },\n        source: \"fallback\",\n        wasRecovered: false,\n        error: result.error || undefined\n    };\n};\n\n/**\n * Extract all JSON blocks from a response (for responses with multiple JSON objects).\n */\nexport const extractAllJSONBlocks = <T = unknown>(response: string): ParseResult<T>[] => {\n    if (!response || typeof response !== \"string\") return [];\n\n    const results: ParseResult<T>[] = [];\n    const cleaned = cleanRawText(response);\n\n    // Find all markdown code blocks\n    const blockPattern = /```(?:json|toon)?\\s*\\n?([\\s\\S]*?)\\n?```/gi;\n    let match: RegExpExecArray | null;\n\n    while ((match = blockPattern.exec(cleaned)) !== null) {\n        if (match[1]) {\n            const extracted = cleanRawText(match[1]);\n            const result = tryParseJSON<T>(extracted);\n            if (result.ok) {\n                results.push({\n                    ok: true,\n                    data: result.data,\n                    raw: match[0],\n                    source: \"markdown_block\"\n                });\n            }\n        }\n    }\n\n    // If no markdown blocks found, try direct parse\n    if (results.length === 0) {\n        const directResult = extractJSONFromAIResponse<T>(response);\n        if (directResult.ok) {\n            results.push(directResult);\n        }\n    }\n\n    return results;\n};\n\n/**\n * Strict JSON instructions to include in AI prompts.\n * Following OpenAI Responses API best practices.\n *\n * @see https://platform.openai.com/docs/api-reference/responses\n */\nexport const STRICT_JSON_INSTRUCTIONS = `\nCRITICAL OUTPUT FORMAT REQUIREMENTS:\n\n1. Your response MUST be ONLY valid JSON - no markdown, no explanations, no prose.\n2. Do NOT wrap the JSON in code blocks (\\`\\`\\`json or \\`\\`\\`).\n3. Do NOT include any text before or after the JSON object.\n4. The response must start with { or [ and end with } or ].\n5. All strings must be properly escaped (newlines as \\\\n, quotes as \\\\\").\n6. Use null for missing/unknown values, not undefined or empty strings.\n7. Numbers should be unquoted. Booleans should be true/false (lowercase).\n8. Arrays should not have trailing commas.\n9. The JSON must be parseable by JSON.parse() without modification.\n\nIf you cannot provide the requested data, return: {\"error\": \"description of the issue\", \"ok\": false}\n`;\n\n/**\n * Shorter version of JSON instructions for context-limited prompts.\n */\nexport const COMPACT_JSON_INSTRUCTIONS = `OUTPUT ONLY: Valid JSON. No markdown, no code blocks, no explanations. Start with { or [, end with } or ]. All strings escaped. Must pass JSON.parse().`;\n\n/**\n * Build a complete prompt that enforces JSON output.\n */\nexport const buildJSONEnforcedPrompt = (\n    basePrompt: string,\n    outputSchema?: string\n): string => {\n    const schemaHint = outputSchema\n        ? `\\n\\nExpected output schema:\\n${outputSchema}`\n        : \"\";\n\n    return `${basePrompt}${schemaHint}\\n\\n${STRICT_JSON_INSTRUCTIONS}`;\n};\n\n","import { encode } from \"@toon-format/toon\";\nimport {\n    actionWithDataType,\n    getDataKindByMIMEType,\n    typesForKind,\n    detectDataKindFromContent,\n    PROMPT_COMPUTE_EFFORT,\n    COMPUTE_TEMPERATURE,\n    buildModificationPrompt,\n    DATA_MODIFICATION_PROMPT,\n    DATA_SELECTION_PROMPT,\n    ENTITY_MERGE_PROMPT,\n    type DataInput,\n    type DataKind,\n    type DataContext,\n    type DataFilter,\n    type ModificationInstruction\n} from \"./GPT-Config\";\nimport { JSOX } from \"jsox\";\nimport {\n    extractJSONFromAIResponse,\n    STRICT_JSON_INSTRUCTIONS\n} from \"../../utils/AIResponseParser\";\n\nconst hasFile = () => typeof (globalThis as any).File !== \"undefined\";\nconst hasBlob = () => typeof (globalThis as any).Blob !== \"undefined\";\n\n// Standardized file size limits across the service layer\nexport const MAX_FILE_SIZE = 10 * 1024 * 1024; // 10MB for file processing\nexport const MAX_BASE64_SIZE = 10 * 1024 * 1024; // 10MB for base64 encoding\n\n// Default request timeout configurations based on effort level (in milliseconds)\nexport const DEFAULT_REQUEST_TIMEOUTS = {\n    low: 60 * 1000,      // 1 minute\n    medium: 5 * 60 * 1000, // 5 minutes\n    high: 15 * 60 * 1000   // 15 minutes\n} as const;\n\nexport const DEFAULT_MAX_RETRIES = 2;\nexport const RETRY_DELAY = 2000; // 2 seconds\n\n/**\n * Get timeout configuration from settings or use defaults\n */\nfunction getTimeoutConfig(effort: \"low\" | \"medium\" | \"high\"): { timeout: number; maxRetries: number } {\n    try {\n        // Try to get settings from runtime or load them\n        const settings = ((globalThis as any).runtimeSettings as any)?.ai ||\n                        require(\"../../config/RuntimeSettings\").getRuntimeSettings?.()?.ai ||\n                        require(\"../../config/Settings\").loadSettings?.()?.ai;\n\n        const timeoutSettings = settings?.requestTimeout;\n        const maxRetries = settings?.maxRetries ?? DEFAULT_MAX_RETRIES;\n\n        const timeout = (timeoutSettings?.[effort] ?? DEFAULT_REQUEST_TIMEOUTS[effort]) * 1000; // Convert to ms\n\n        return { timeout, maxRetries };\n    } catch {\n        // Fallback to defaults if settings can't be loaded\n        return {\n            timeout: DEFAULT_REQUEST_TIMEOUTS[effort],\n            maxRetries: DEFAULT_MAX_RETRIES\n        };\n    }\n}\n\n// Optimized base64 encoding with memory safety\nconst toBase64 = (bytes: Uint8Array): string => {\n    // Node.js environment\n    if (typeof (globalThis as any).Buffer !== \"undefined\") {\n        return (globalThis as any).Buffer.from(bytes).toString(\"base64\");\n    }\n\n    // Browser environment - use chunked processing for large files\n    const CHUNK_SIZE = 1024 * 1024; // 1MB chunks to avoid memory issues\n    if (bytes.length > CHUNK_SIZE) {\n        let result = \"\";\n        for (let i = 0; i < bytes.length; i += CHUNK_SIZE) {\n            const chunk = bytes.slice(i, i + CHUNK_SIZE);\n            let binary = \"\";\n            for (let j = 0; j < chunk.length; j++) {\n                binary += String.fromCharCode(chunk[j]);\n            }\n            result += (typeof btoa === \"function\" ? btoa(binary) : \"\");\n        }\n        return result;\n    }\n\n    // Small files - direct processing\n    let binary = \"\";\n    for (let i = 0; i < bytes.length; i++) binary += String.fromCharCode(bytes[i]);\n    // @ts-ignore\n    return typeof btoa === \"function\" ? btoa(binary) : \"\";\n};\n\n//\nexport type RequestOptions = {\n    effort?: \"low\" | \"medium\" | \"high\";\n    verbosity?: \"low\" | \"medium\" | \"high\";\n    temperature?: number;\n    maxTokens?: number;\n    stream?: boolean;\n    responseFormat?: \"json\" | \"text\" | \"markdown\";\n}\n\nexport type AIResponse<T = unknown> = {\n    ok: boolean;\n    data?: T;\n    error?: string;\n    usage?: {\n        promptTokens: number;\n        completionTokens: number;\n        totalTokens: number;\n    };\n    responseId?: string | null;\n}\n\n//\nexport const getUsableData = async (data: DataInput) => {\n    const FileCtor = hasFile() ? (globalThis as any).File : undefined;\n    const BlobCtor = hasBlob() ? (globalThis as any).Blob : undefined;\n    const isFileOrBlob =\n        (BlobCtor && data?.dataSource instanceof BlobCtor) ||\n        (FileCtor && data?.dataSource instanceof FileCtor);\n\n    if (isFileOrBlob) {\n        const fileSize = data?.dataSource?.size || 0;\n        const MAX_FILE_SIZE = 10 * 1024 * 1024; // 10MB limit\n\n        // Check file size limit\n        if (fileSize > MAX_FILE_SIZE) {\n            console.warn(`[GPT-Responses] File too large: ${fileSize} bytes > ${MAX_FILE_SIZE} bytes`);\n            return {\n                \"type\": \"input_text\",\n                \"text\": `[File too large: ${(fileSize / 1024 / 1024).toFixed(1)}MB. Maximum allowed: ${(MAX_FILE_SIZE / 1024 / 1024).toFixed(1)}MB]`\n            };\n        }\n\n        if (typesForKind?.[data?.dataKind || \"input_text\"] === \"input_image\" || (data?.dataSource?.type?.startsWith?.(\"image/\"))) {\n            try {\n                const BASE64URL = `data:${data?.dataSource?.type};base64,`;\n                const arrayBuffer = await data?.dataSource?.arrayBuffer();\n                if (!arrayBuffer) {\n                    throw new Error(\"Failed to read file as ArrayBuffer\");\n                }\n                const bytes = new Uint8Array(arrayBuffer);\n                const URL = BASE64URL + toBase64(bytes);\n                return {\n                    \"type\": \"input_image\",\n                    \"detail\": \"auto\",\n                    \"image_url\": URL\n                };\n            } catch (error) {\n                console.error(\"[GPT-Responses] Failed to process image file:\", error);\n                return {\n                    \"type\": \"input_text\",\n                    \"text\": `[Failed to process image file: ${error}]`\n                };\n            }\n        }\n\n        // Handle other file types as text\n        try {\n            const text = await data?.dataSource?.text?.();\n            if (text) {\n                return {\n                    \"type\": \"input_text\",\n                    \"text\": text\n                };\n            }\n        } catch (error) {\n            console.error(\"[GPT-Responses] Failed to read text file:\", error);\n            return {\n                \"type\": \"input_text\",\n                \"text\": `[Failed to read text file: ${error}]`\n            };\n        }\n    } else if (typeof data?.dataSource == \"string\") {\n        // Auto-detect data kind if not specified\n        const effectiveKind = data?.dataKind || detectDataKindFromContent(data.dataSource);\n\n        // be aware, this may be base64 encoded image\n        if (\n            (data?.dataSource?.startsWith?.(\"data:image/\") && data?.dataSource?.includes?.(\";base64,\")) ||\n            URL.canParse(data?.dataSource?.trim?.() || \"\", typeof (typeof window != \"undefined\" ? window : globalThis)?.location == \"undefined\" ? undefined : ((typeof window != \"undefined\" ? window : globalThis)?.location?.origin || \"\")) ||\n            (typesForKind?.[effectiveKind] == \"input_image\")\n        ) {\n            return {\n                \"type\": \"input_image\",\n                \"image_url\": data?.dataSource,\n                \"detail\": \"auto\"\n            }\n        }\n\n        // anyways returns Promise<string>\n        return {\n            \"type\": \"input_text\",\n            \"text\": data?.dataSource\n        }\n    }\n\n    // is not Blob or File, so it's (may be) string (if not string, try to parse it as JSON)\n    let result = data?.dataSource;\n    try {\n        result = (typeof data?.dataSource != \"object\") ? data?.dataSource : encode(data?.dataSource);\n    } catch (e) {\n        console.warn(e);\n    }\n\n    //\n    return {\n        \"type\": typesForKind?.[data?.dataKind || \"input_text\"] || \"text\",\n        \"text\": result\n    }\n}\n\n//\nexport class GPTResponses {\n    private apiKey: string;\n    private apiSecret: string;\n    private apiUrl: string = \"https://api.proxyapi.ru/openai/v1\";\n    private model: string = \"gpt-5.2\";\n    private responseId?: string | null = null;\n\n    protected pending: any[] = [];\n    protected messages: any[] = [];\n    protected tools: Map<string, any> = new Map();\n    protected context: DataContext | null = null;\n    protected responseMap: Map<string, any> = new Map();\n\n    //\n    constructor(apiKey: string, apiUrl: string, apiSecret: string, model: string) {\n        this.apiKey = apiKey || \"\";\n        this.apiUrl = apiUrl || this.apiUrl;\n        this.apiSecret = apiSecret || \"\";\n        this.model = model || this.model;\n    }\n\n    //\n    setContext(context: DataContext | null) {\n        this.context = context;\n        return this;\n    }\n\n    //\n    async useMCP(serverLabel: string, origin: string, clientKey: string, secretKey: string) {\n        this.tools.set(origin?.trim?.(), {\n            \"type\": \"mcp\",\n            \"server_label\": serverLabel,\n            \"server_url\": origin,\n            \"headers\": {\n                \"authorization\": `Bearer ${clientKey}:${secretKey}`\n            },\n            \"require_approval\": \"never\"\n        })\n        return this.tools.get(origin?.trim?.());\n    }\n\n    //\n    async convertPlainToInput(\n        dataSource: (string | Blob | File | any),\n        dataKind: DataKind | null = null,\n        additionalAction: string | null = null\n    ): Promise<any> {\n        dataKind ??= getDataKindByMIMEType(dataSource?.type) || \"input_text\";\n\n        const dataInput: DataInput = { dataSource, dataKind, context: this.context };\n        const usableData = await getUsableData(dataInput);\n\n        return {\n            type: \"message\",\n            role: \"user\",\n            content: [\n                { type: \"input_text\", text: \"What to do: \" + actionWithDataType(dataInput) },\n                additionalAction ? { type: \"text\", text: \"Additional request data: \" + additionalAction } : null,\n                { type: \"input_text\", text: \"\\n === BEGIN:ATTACHED_DATA === \\n\" },\n                { ...usableData },\n                { type: \"input_text\", text: \"\\n === END:ATTACHED_DATA === \\n\" },\n            ]?.filter?.((item) => item !== null)\n        };\n    }\n\n    //\n    async attachToRequest(\n        dataSource: (string | Blob | File | any),\n        dataKind: DataKind | null = null,\n        firstAction: string | null = null\n    ) {\n        this.pending.push(await this.convertPlainToInput(\n            dataSource,\n            dataKind ??= getDataKindByMIMEType(dataSource?.type) || \"input_text\"\n        ));\n        if (firstAction) {\n            this.pending.push(await this.askToDoAction(firstAction));\n        }\n        return this.pending[this.pending.length - 1];\n    }\n\n    //\n    async attachExistingData(existingData: any, entityType?: string) {\n        this.context = {\n            ...this.context,\n            existingData,\n            entityType: entityType || this.context?.entityType\n        };\n\n        await this.giveForRequest(`existing_data: \\`${encode(existingData)}\\`\\n`);\n        return this;\n    }\n\n    //\n    async giveForRequest(whatIsIt: string) {\n        this?.pending?.push?.({\n            type: \"message\",\n            role: \"user\",\n            content: [{ type: \"input_text\", text: \"Additional data for request: \" }, { type: \"input_text\", text: whatIsIt }]\n        });\n        return this?.pending?.[this?.pending?.length - 1];\n    }\n\n    //\n    async askToDoAction(action: string) {\n        this?.pending?.push?.({\n            type: \"message\",\n            role: \"user\",\n            content: [{ type: \"input_text\", text: action }]\n        });\n        return this?.pending?.[this?.pending?.length - 1];\n    }\n\n    //\n    beginFromResponseId(responseId: string | null = null) {\n        this.responseId = (this.responseId = (responseId || this.responseId));\n        return this;\n    }\n\n    //\n    async sendRequest(\n        effort: \"low\" | \"medium\" | \"high\" = \"low\",\n        verbosity: \"low\" | \"medium\" | \"high\" = \"low\",\n        prevResponseId: string | null = null,\n        options: RequestOptions = {}\n    ): Promise<string | null> {\n        effort ??= \"low\";\n        verbosity ??= \"low\";\n\n        // De-duplicate pending items\n        const uniquePending = new Map();\n        for (const item of this.pending) {\n            if (!item) continue;\n            try {\n                const key = typeof item === 'object' ? JSOX.stringify(item) : String(item);\n                if (!uniquePending.has(key)) {\n                    uniquePending.set(key, item);\n                }\n            } catch (e) {\n                uniquePending.set(Math.random().toString(), item);\n            }\n        }\n        const filteredInput = Array.from(uniquePending.values());\n\n        // Build strict JSON instructions for json response format\n        // Following OpenAI Responses API best practices\n        const jsonInstructions = options?.responseFormat === \"json\"\n            ? STRICT_JSON_INSTRUCTIONS\n            : undefined;\n\n        const requestBody: any = {\n            model: this.model,\n            tools: Array.from(this?.tools?.values?.() || [])?.filter?.((tool: any) => !!tool),\n            input: filteredInput,\n            reasoning: { \"effort\": effort },\n            text: { verbosity: verbosity },\n            max_output_tokens: options?.maxTokens || 400000,\n            previous_response_id: (this.responseId = (prevResponseId || this?.responseId)),\n            instructions: jsonInstructions\n        };\n\n        // Add temperature if specified\n        if (options?.temperature !== undefined) {\n            requestBody.temperature = options.temperature;\n        }\n\n        // Execute request with retry logic and timeout\n        const { timeout: timeoutMs, maxRetries } = getTimeoutConfig(effort);\n        console.log(\"[GPT] Making request to:\", `${this?.apiUrl}/responses`);\n        console.log(\"[GPT] API key present:\", !!this?.apiKey);\n        console.log(\"[GPT] Request timeout:\", `${timeoutMs}ms (${effort} effort)`);\n        console.log(\"[GPT] Max retries:\", maxRetries);\n        console.log(\"[GPT] Request body size:\", JSON.stringify(requestBody).length, \"characters\");\n\n        let lastError: Error | null = null;\n\n        for (let attempt = 0; attempt <= maxRetries; attempt++) {\n            if (attempt > 0) {\n                console.log(`[GPT] Retry attempt ${attempt}/${maxRetries} after ${RETRY_DELAY}ms delay`);\n                await new Promise(resolve => setTimeout(resolve, RETRY_DELAY));\n            }\n\n            try {\n                const controller = new AbortController();\n                const timeoutId = setTimeout(() => {\n                    console.warn(`[GPT] Request timeout after ${timeoutMs}ms (attempt ${attempt + 1})`);\n                    controller.abort();\n                }, timeoutMs);\n\n                const response = await fetch(`${this?.apiUrl}/responses`, {\n                    method: \"POST\",\n                    priority: 'auto',\n                    // Remove keepalive for better timeout control\n                    signal: controller.signal,\n                    headers: {\n                        \"Content-Type\": \"application/json\",\n                        ...(this?.apiKey ? { \"Authorization\": `Bearer ${this?.apiKey}` } : {})\n                    },\n                    body: JSON.stringify(requestBody),\n                });\n\n                clearTimeout(timeoutId);\n\n                // Handle the response\n                console.log(\"[GPT] Response status:\", response.status, `(attempt ${attempt + 1})`);\n\n                if (response.status !== 200) {\n                    const error = await response?.json?.()?.catch?.((e) => {\n                        console.error(\"[GPT] Failed to parse error response:\", e);\n                        return null;\n                    });\n                    const errorMessage = error?.error?.message || error?.message || `HTTP ${response.status}`;\n                    lastError = new Error(`API error (${response.status}): ${errorMessage}`);\n                    console.error(\"[GPT] API error:\", errorMessage);\n\n                    // Don't retry on client errors (4xx)\n                    if (response.status >= 400 && response.status < 500) {\n                        throw lastError;\n                    }\n\n                    // Continue to retry on server errors (5xx) or network issues\n                    continue;\n                }\n\n                // Success - process the response\n                return await this.processSuccessfulResponse(response);\n\n            } catch (e) {\n                lastError = e instanceof Error ? e : new Error(String(e));\n                console.error(`[GPT] Request failed (attempt ${attempt + 1}):`, lastError.message);\n\n                // Don't retry on abort (timeout) or client errors\n                if (lastError.name === 'AbortError' || (lastError.message.includes('HTTP 4'))) {\n                    break;\n                }\n\n                // Continue to next retry attempt\n            }\n        }\n\n        // All retries failed\n        const errorMessage = lastError ? lastError.message : 'Unknown error after all retries';\n        console.error(\"[GPT] All retry attempts failed:\", errorMessage);\n        throw new Error(`Request failed after ${maxRetries + 1} attempts: ${errorMessage}`);\n    }\n\n    /**\n     * Process a successful response from the API\n     */\n    private async processSuccessfulResponse(response: Response): Promise<string | null> {\n\n        const resp = await response?.json?.()?.catch?.((e) => {\n            console.warn(\"[GPT] Failed to parse successful response:\", e);\n            return null;\n        });\n        if (!resp) return null;\n\n        //\n        this.responseMap.set((this.responseId = (resp?.id || resp?.response_id || this.responseId)), resp);\n        this?.messages?.push?.(...(this?.pending || []));\n        this?.pending?.splice?.(0, this?.pending?.length);\n        this.messages.push(...(resp?.output || []));\n\n        // Try best-effort extraction of textual content\n        const extractText = (r: any): string | null => {\n            try {\n                if (!r) return null;\n                if (typeof r === \"string\") return r;\n                if (r.output_text && Array.isArray(r.output_text) && r.output_text.length) {\n                    return r.output_text.join(\"\\n\\n\");\n                }\n                const outputs = r.output || [];\n                const texts: string[] = [];\n                for (const msg of outputs) {\n                    const content = msg?.content || [];\n                    if (!content) continue;\n                    for (const part of content) {\n                        if (typeof part?.text === \"string\") texts.push(part.text);\n                        else if (part?.text?.value) texts.push(part.text.value);\n                    }\n                }\n                if (texts.length) return texts.join(\"\\n\\n\");\n            } catch (e) {\n                console.warn(\"[GPT] Error extracting text:\", e);\n            }\n            return null;\n        };\n\n        const text = extractText(resp);\n        if (text != null) return text;\n\n        // Fallback: return last message content as JSON string\n        try {\n            return JSOX.parse(resp?.output ?? resp) as any;\n        } catch { /* noop */ }\n        return \"\";\n    }\n\n    // === NEW METHODS FOR DATA MODIFICATION ===\n\n    //\n    async modifyExistingData(\n        existingData: any,\n        modificationPrompt: string,\n        instructions: ModificationInstruction[] = []\n    ): Promise<AIResponse<any>> {\n        try {\n            this.setContext({\n                operation: \"modify\",\n                existingData\n            });\n\n            await this.giveForRequest(DATA_MODIFICATION_PROMPT);\n            await this.giveForRequest(`existing_entity: \\`${encode(existingData)}\\`\\n`);\n\n            if (instructions.length) {\n                await this.giveForRequest(buildModificationPrompt(instructions));\n            }\n\n            await this.askToDoAction(modificationPrompt);\n\n            const raw = await this.sendRequest(\"high\", \"medium\", null, {\n                responseFormat: \"json\",\n                temperature: 0.2\n            });\n\n\n            // Use robust JSON extraction to handle markdown-wrapped responses\n            const parseResult = extractJSONFromAIResponse<any>(raw);\n            if (!parseResult.ok) {\n                console.warn(\"JSON extraction failed:\", parseResult.error, \"Raw:\", parseResult.raw);\n                return { ok: false, error: parseResult.error || \"Failed to parse AI response\" };\n            }\n\n            return {\n                ok: true,\n                data: parseResult.data?.modified_entity || parseResult.data,\n                responseId: this.responseId\n            };\n        } catch (e) {\n            console.error(\"Error in modifyExistingData:\", e);\n            return { ok: false, error: String(e) };\n        }\n    }\n\n    //\n    async selectAndFilterData(\n        dataSet: any[],\n        filters: DataFilter[],\n        searchTerms: string[] = []\n    ): Promise<AIResponse<any[]>> {\n        try {\n            this.setContext({\n                operation: \"extract\",\n                filters,\n                searchTerms\n            });\n\n            await this.giveForRequest(DATA_SELECTION_PROMPT);\n            await this.giveForRequest(`data_set: \\`${encode(dataSet)}\\`\\n`);\n\n            const filterDesc = filters.map(f =>\n                `Filter: ${f.field} ${f.operator} ${JSON.stringify(f.value)}`\n            ).join(\"\\n\");\n\n            await this.askToDoAction(`\nSelect items from the provided data set matching these criteria:\n${filterDesc}\n${searchTerms.length ? `\\nSearch terms: ${searchTerms.join(\", \")}` : \"\"}\n\nReturn matching items with relevance scores.\n            `);\n\n            const raw = await this.sendRequest(\"medium\", \"low\", null, {\n                responseFormat: \"json\",\n                temperature: 0.1\n            });\n\n\n            // Use robust JSON extraction to handle markdown-wrapped responses\n            const parseResult = extractJSONFromAIResponse<any>(raw);\n            if (!parseResult.ok) {\n                console.warn(\"JSON extraction failed:\", parseResult.error, \"Raw:\", parseResult.raw);\n                return { ok: false, error: parseResult.error || \"Failed to parse AI response\" };\n            }\n\n            return {\n                ok: true,\n                data: parseResult.data?.selected_items || parseResult.data,\n                responseId: this.responseId\n            };\n        } catch (e) {\n            console.error(\"Error in selectAndFilterData:\", e);\n            return { ok: false, error: String(e) };\n        }\n    }\n\n    //\n    async mergeEntities(\n        primary: any,\n        secondary: any | any[],\n        mergeStrategy: \"prefer_primary\" | \"prefer_secondary\" | \"prefer_newer\" | \"merge_all\" = \"prefer_primary\"\n    ): Promise<AIResponse<any>> {\n        try {\n            this.setContext({\n                operation: \"merge\",\n                existingData: primary\n            });\n\n            await this.giveForRequest(ENTITY_MERGE_PROMPT);\n            await this.giveForRequest(`primary_entity: \\`${encode(primary)}\\`\\n`);\n            await this.giveForRequest(`secondary_data: \\`${encode(secondary)}\\`\\n`);\n\n            await this.askToDoAction(`\nMerge the secondary data into the primary entity using \"${mergeStrategy}\" strategy:\n- prefer_primary: Keep primary values when conflicts occur\n- prefer_secondary: Use secondary values when conflicts occur\n- prefer_newer: Compare timestamps and use newer values\n- merge_all: Combine all unique values (arrays concatenated, objects deeply merged)\n\nReturn the merged entity with conflict resolution details.\n            `);\n\n            const raw = await this.sendRequest(\"high\", \"medium\", null, {\n                responseFormat: \"json\",\n                temperature: 0.2\n            });\n\n\n            // Use robust JSON extraction to handle markdown-wrapped responses\n            const parseResult = extractJSONFromAIResponse<any>(raw);\n            if (!parseResult.ok) {\n                console.warn(\"JSON extraction failed:\", parseResult.error, \"Raw:\", parseResult.raw);\n                return { ok: false, error: parseResult.error || \"Failed to parse AI response\" };\n            }\n\n            return {\n                ok: true,\n                data: parseResult.data?.merged_entity || parseResult.data,\n                responseId: this.responseId\n            };\n        } catch (e) {\n            console.error(\"Error in mergeEntities:\", e);\n            return { ok: false, error: String(e) };\n        }\n    }\n\n    //\n    async searchSimilar(\n        referenceEntity: any,\n        candidateSet: any[],\n        similarityThreshold: number = 0.7\n    ): Promise<AIResponse<{ item: any; similarity: number }[]>> {\n        try {\n            this.setContext({\n                operation: \"analyze\"\n            });\n\n            await this.giveForRequest(`reference_entity: \\`${encode(referenceEntity)}\\`\\n`);\n            await this.giveForRequest(`candidate_set: \\`${encode(candidateSet)}\\`\\n`);\n\n            // Note: We still show expected format in prompt but ask for raw JSON output\n            await this.askToDoAction(`\nFind items in the candidate set that are similar to the reference entity.\nConsider semantic similarity, not just exact matches.\nCompare:\n- Names/titles (fuzzy match)\n- Types/kinds\n- Properties overlap\n- Relationships\n\nReturn items with similarity score >= ${similarityThreshold}\n\nExpected output structure:\n{\n    \"similar_items\": [\n        { \"item\": {...}, \"similarity\": 0.85, \"match_reasons\": [...] }\n    ],\n    \"potential_duplicates\": [...],\n    \"related_but_different\": [...]\n}\n            `);\n\n            const raw = await this.sendRequest(\"medium\", \"medium\", null, {\n                responseFormat: \"json\",\n                temperature: 0.3\n            });\n\n\n            // Use robust JSON extraction to handle markdown-wrapped responses\n            const parseResult = extractJSONFromAIResponse<any>(raw);\n            if (!parseResult.ok) {\n                console.warn(\"JSON extraction failed:\", parseResult.error, \"Raw:\", parseResult.raw);\n                return { ok: false, error: parseResult.error || \"Failed to parse AI response\" };\n            }\n\n            return {\n                ok: true,\n                data: parseResult.data?.similar_items || [],\n                responseId: this.responseId\n            };\n        } catch (e) {\n            console.error(\"Error in searchSimilar:\", e);\n            return { ok: false, error: String(e) };\n        }\n    }\n\n    //\n    async batchProcess(\n        items: any[],\n        operation: string,\n        batchSize: number = 10\n    ): Promise<AIResponse<any[]>> {\n        const results: any[] = [];\n        const errors: string[] = [];\n\n        for (let i = 0; i < items.length; i += batchSize) {\n            const batch = items.slice(i, i + batchSize);\n\n            await this.giveForRequest(`batch_items: \\`${encode(batch)}\\`\\n`);\n            // Note: We show expected format but ask for raw JSON\n            await this.askToDoAction(`\nProcess this batch of ${batch.length} items:\n${operation}\n\nReturn processed items in same order.\nExpected output: { \"processed\": [...], \"failed\": [...] }\n            `);\n\n            const raw = await this.sendRequest(\"medium\", \"low\", null, {\n                responseFormat: \"json\"\n            });\n\n            if (raw) {\n                // Use robust JSON extraction to handle markdown-wrapped responses\n                const parseResult = extractJSONFromAIResponse<any>(raw);\n                if (parseResult.ok && parseResult.data) {\n                    results.push(...(parseResult.data?.processed || []));\n                    if (parseResult.data?.failed?.length) {\n                        errors.push(...parseResult.data.failed.map((f: any) => f?.error || \"Unknown error\"));\n                    }\n                } else {\n                    console.warn(\"Batch parsing failed:\", parseResult.error);\n                }\n            }\n        }\n\n        return {\n            ok: errors.length === 0,\n            data: results,\n            error: errors.length ? errors.join(\"; \") : undefined,\n            responseId: this.responseId\n        };\n    }\n\n    //\n    clearPending() {\n        this.pending.splice(0, this.pending.length);\n        return this;\n    }\n\n    //\n    getResponseId() { return this?.responseId; }\n    getMessages() { return this?.messages; }\n    getPending() { return this?.pending; }\n    getContext() { return this?.context; }\n\n    //\n    getResponse(responseId: string) { return this?.responseMap?.get?.(responseId); }\n}\n\n// === HELPER FUNCTIONS ===\n\n//\nexport const createGPTInstance = (\n    apiKey: string,\n    apiUrl?: string,\n    model?: string\n): GPTResponses => {\n    return new GPTResponses(\n        apiKey,\n        apiUrl || \"https://api.proxyapi.ru/openai/v1\",\n        \"\",\n        model || \"gpt-5.2\"\n    );\n}\n\n//\nexport const quickRecognize = async (\n    apiKey: string,\n    data: string | Blob | File,\n    apiUrl?: string,\n    options: RequestOptions & { timeoutOverride?: number } = {}\n): Promise<AIResponse<any>> => {\n    const gpt = createGPTInstance(apiKey, apiUrl);\n    await gpt.attachToRequest(data);\n\n    let raw;\n    try {\n        // Use timeout override if provided, otherwise use default medium effort timeout\n        const timeoutOptions = options.timeoutOverride\n            ? { ...options, maxTokens: options.maxTokens }\n            : options;\n\n        raw = await gpt.sendRequest(\"medium\", \"medium\", null, timeoutOptions);\n    } catch (e) {\n        const errorMessage = e instanceof Error ? e.message : String(e);\n        console.error(\"[quickRecognize] Request failed:\", errorMessage);\n        return { ok: false, error: errorMessage };\n    }\n\n    if (!raw) {\n        return { ok: false, error: \"No response from AI service\" };\n    }\n\n    // Use robust JSON extraction to handle markdown-wrapped responses\n    const parseResult = extractJSONFromAIResponse<any>(raw);\n    if (parseResult.ok) {\n        return { ok: true, data: parseResult.data };\n    }\n\n    // Fallback to raw text if JSON extraction fails\n    console.warn(\"[quickRecognize] JSON extraction failed, using raw text\");\n    return { ok: true, data: raw };\n}\n\n//\nexport const quickModify = async (\n    apiKey: string,\n    existingData: any,\n    modificationPrompt: string,\n    apiUrl?: string\n): Promise<AIResponse<any>> => {\n    const gpt = createGPTInstance(apiKey, apiUrl);\n    return gpt.modifyExistingData(existingData, modificationPrompt);\n}\n","/*\n * Instruction Utilities\n * Pure functions for working with AI instructions (backend-compatible)\n */\n\nimport type { CustomInstruction } from \"../config/SettingsTypes\";\n\nexport type { CustomInstruction };\n\n/**\n * Builds a combined prompt from base instruction and custom instruction\n */\nexport const buildInstructionPrompt = (baseInstruction: string, customInstruction: string): string => {\n    if (!customInstruction?.trim()) return baseInstruction;\n\n    return `${baseInstruction}\n\n---\n\nUSER CUSTOM INSTRUCTIONS:\n${customInstruction.trim()}\n\n---\n\nApply the user's custom instructions above when processing the data. Prioritize user instructions when they conflict with default behavior.\n`;\n};\n\n/**\n * SVG Graphics generation instruction addon\n */\nexport const SVG_GRAPHICS_ADDON = `\n---\n\nGRAPHICS GENERATION (when applicable):\nWhen the problem involves functions, graphs, geometric shapes, diagrams, or data that can be visualized:\n\nGenerate inline SVG as Markdown image with data URI:\n![<title>](data:image/svg+xml,<encodeURIComponent_encoded_svg>)\n\nSVG Requirements:\n- Use encodeURIComponent() encoding for the entire SVG string\n- viewBox=\"0 0 400 300\" (or appropriate dimensions)\n- Colors: #3b82f6 (blue), #10b981 (green), #f59e0b (orange), #ef4444 (red)\n- Include axis labels, tick marks, and legends\n- Use <text> elements for annotations\n- Keep SVG minimal but informative\n\nApply to:\n Function graphs: f(x), parametric, polar\n Geometric constructions and proofs\n Data visualizations and charts\n Diagrams and flowcharts\n Coordinate systems and number lines\n\nAlways include both the mathematical solution AND the visualization.\n`;\n\n/**\n * Builds instruction with optional SVG graphics support\n */\nexport const buildInstructionWithGraphics = (\n    baseInstruction: string,\n    customInstruction: string,\n    includeSvgGraphics: boolean\n): string => {\n    let result = buildInstructionPrompt(baseInstruction, customInstruction);\n\n    if (includeSvgGraphics) {\n        result += SVG_GRAPHICS_ADDON;\n    }\n\n    return result;\n};\n\n/**\n * Generates a unique ID for custom instructions\n */\nexport const generateInstructionId = (): string => {\n    return `ci_${Date.now()}_${Math.random().toString(36).slice(2, 8)}`;\n};\n\n/**\n * Default instruction templates\n */\nexport const DEFAULT_INSTRUCTION_TEMPLATES: Omit<CustomInstruction, \"id\">[] = [\n    {\n        label: \"Markdown & KaTeX\",\n        instruction: `Format all recognized content as clean Markdown with proper KaTeX math notation.\n\nRules for math expressions:\n- Inline math: use SINGLE dollar signs, e.g. $x^2 + y^2 = z^2$\n- Block/display math: use DOUBLE dollar signs on separate lines:\n  $$\\\\int_0^1 f(x) dx$$\n- Do NOT add extra dollar signs - use exactly one $ for inline, exactly two $$ for block\n- Preserve original mathematical notation accurately\n\nRules for text formatting:\n- Use proper heading levels (# ## ###)\n- Format lists with - or 1. 2. 3.\n- Use **bold** and *italic* appropriately\n- Format code as \\`inline\\` or \\`\\`\\`block\\`\\`\\`\n- Format tables as | Markdown | tables |\n\nPrioritize mathematical accuracy and proper Markdown structure.`,\n        enabled: true,\n        order: 0\n    },\n    {\n        label: \"Solve & Answer\",\n        instruction: `Solve problems or answer questions. Auto-detect the type:\n Math equations  Solve step-by-step with KaTeX\n Quiz/test questions  Provide correct answer with explanation\n Homework problems  Solve and explain reasoning\n\nFormat:\n**Problem/Question:** <content, use $KaTeX$ for math>\n**Solution/Answer:** <step-by-step or direct answer>\n**Explanation:** <clear reasoning>\n\nFor multiple choice: identify correct option + explain why.\nFor math: use $ for inline, $$ for block equations.\nShow all work and simplify the final answer.`,\n        enabled: true,\n        order: 1\n    },\n    {\n        label: \"Solve with Graphics\",\n        instruction: `Solve problems and generate visual representations when applicable.\n\nFor functions, graphs, diagrams, geometric shapes, or data visualizations:\nGenerate inline SVG code as a data URI: \\`![Graph](data:image/svg+xml,<encoded_svg>)\\`\n\nSVG Generation Rules:\n1. Use encodeURIComponent() encoding for the SVG content\n2. Keep SVG minimal but accurate (viewBox, paths, text labels)\n3. Use appropriate colors: #2563eb (blue) for main, #dc2626 (red) for secondary\n4. Include axis labels, grid lines, and legends where helpful\n5. Size: viewBox=\"0 0 400 300\" for standard graphs\n\nWhen to generate SVG:\n Function plots: y = f(x), parametric curves, polar plots\n Geometric diagrams: triangles, circles, angles, constructions\n Data charts: bar, line, pie charts\n Flowcharts and simple diagrams\n Number lines and coordinate systems\n\nFormat:\n**Problem:** <description>\n**Solution:** <step-by-step with $KaTeX$>\n**Visualization:**\n![<title>](data:image/svg+xml,<encodeURIComponent_svg>)\n\nAlways provide both the mathematical solution AND the visual when graphics are suitable.`,\n        enabled: true,\n        order: 2\n    },\n    {\n        label: \"Write code\",\n        instruction: `Generate code based on the recognized request/description.\n\nFormat:\n**Request:** <what the code should do>\n**Language:** <programming language>\n**Code:**\n\\`\\`\\`<lang>\n<code>\n\\`\\`\\`\n\nWrite clean, functional code with meaningful names and brief comments.`,\n        enabled: true,\n        order: 3\n    },\n    {\n        label: \"Extract CSS\",\n        instruction: `Generate CSS that matches the visual appearance of the content.\n\nExtract:\n- Colors (oklch, hex, rgb)\n- Typography (font, size, weight)\n- Spacing (padding, margin, gap)\n- Layout (flex, grid)\n- Effects (shadow, radius, gradients)\n\nUse CSS custom properties and modern syntax.\nInclude responsive considerations.`,\n        enabled: true,\n        order: 4\n    },\n    {\n        label: \"Generate Diagram\",\n        instruction: `Generate SVG diagrams, charts, or visual representations from descriptions.\n\nOutput as inline data URI: ![<title>](data:image/svg+xml,<encoded_svg>)\n\nDiagram Types:\n Flowcharts: processes, algorithms, decision trees\n Charts: bar, line, pie, scatter plots\n Diagrams: UML, ER, network, architecture\n Graphs: mathematical functions, data visualization\n Geometric: shapes, constructions, proofs\n\nSVG Requirements:\n1. Use encodeURIComponent() for the SVG string\n2. viewBox=\"0 0 600 400\" (adjust as needed)\n3. Clean, minimal SVG with proper structure\n4. Colors: #3b82f6 primary, #10b981 secondary, #f59e0b accent\n5. Include labels, arrows, and legends\n6. Use <text> for readable annotations\n\nExample output format:\n**Diagram:** <description>\n![<title>](data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%20viewBox%3D%220%200%20400%20300%22%3E...%3C%2Fsvg%3E)`,\n        enabled: true,\n        order: 5\n    },\n    {\n        label: \"Extract contacts\",\n        instruction: \"Focus on extracting contact information: phone numbers, emails, addresses, and names. Format phone numbers in E.164 format.\",\n        enabled: true,\n        order: 6\n    },\n    {\n        label: \"Summarize content\",\n        instruction: \"Provide a brief summary of the recognized content. Include key points and main takeaways.\",\n        enabled: true,\n        order: 7\n    },\n    {\n        label: \"Extract URLs and links\",\n        instruction: \"Focus on extracting all URLs, links, and web addresses. Validate and normalize them.\",\n        enabled: true,\n        order: 8\n    },\n    {\n        label: \"Code extraction\",\n        instruction: \"Focus on extracting code snippets. Detect the programming language and format appropriately with syntax highlighting markers.\",\n        enabled: true,\n        order: 9\n    },\n    {\n        label: \"Table extraction\",\n        instruction: \"Focus on extracting tabular data. Format as proper Markdown tables with headers.\",\n        enabled: true,\n        order: 10\n    }\n];\n","/*\n * Unified AI Service for CrossWord\n * Consolidated AI/GPT/service API/Config/Architecture/Code for PWA, CRX, ShareTarget, and Core\n * Supports multiple input formats, batch recognition, and intelligent data extraction.\n */\n\nimport { getRuntimeSettings } from \"../../config/RuntimeSettings\";\nimport { loadSettings } from \"../../config/Settings\";\nimport {\n    getUsableData,\n    GPTResponses,\n    createGPTInstance,\n    type AIResponse\n} from \"../model/GPT-Responses\";\nimport {\n    detectDataKindFromContent,\n    type DataKind,\n    type DataContext\n} from \"../model/GPT-Config\";\nimport { extractJSONFromAIResponse } from \"../../utils/AIResponseParser\";\nimport { buildInstructionPrompt, SVG_GRAPHICS_ADDON } from \"../InstructionUtils\";\nimport type { ResponseLanguage } from \"../../config/SettingsTypes\";\n\n// ============================================================================\n// PLATFORM ADAPTERS\n// ============================================================================\n// Unified platform-specific functionality\n\nexport interface ClipboardResult {\n    ok: boolean;\n    data?: string;\n    error?: string;\n    method?: string;\n}\n\nexport interface ImageProcessingOptions {\n    maxWidth?: number;\n    maxHeight?: number;\n    quality?: number;\n    format?: 'png' | 'jpeg';\n}\n\nexport interface PlatformAdapter {\n    copyToClipboard(data: string): Promise<ClipboardResult>;\n    readFromClipboard(): Promise<ClipboardResult>;\n    processImage?(dataUrl: string, options?: ImageProcessingOptions): Promise<string>;\n    captureScreenshot?(rect?: { x: number; y: number; width: number; height: number }): Promise<string>;\n    showNotification?(message: string, options?: { type?: 'info' | 'success' | 'warning' | 'error'; duration?: number }): void;\n}\n\n// Platform-specific implementations\nconst createPwaAdapter = (): PlatformAdapter => ({\n    async copyToClipboard(data: string): Promise<ClipboardResult> {\n        try {\n            // Import PWA clipboard functionality\n            const { writeText } = await import(\"../../../frontend/shared/Clipboard\");\n            return await writeText(data) as ClipboardResult;\n        } catch (e) {\n            return { ok: false, error: String(e) };\n        }\n    },\n\n    async readFromClipboard(): Promise<ClipboardResult> {\n        try {\n            // PWA clipboard reading\n            if (navigator.clipboard?.readText) {\n                const text = await navigator.clipboard.readText();\n                return { ok: true, data: text };\n            }\n            return { ok: false, error: \"Clipboard access not available\" };\n        } catch (e) {\n            return { ok: false, error: String(e) };\n        }\n    },\n\n    async processImage(dataUrl: string, options?: ImageProcessingOptions): Promise<string> {\n        // Basic image processing for PWA (can be enhanced)\n        return dataUrl;\n    },\n\n    showNotification(message: string, options?: { type?: 'info' | 'success' | 'warning' | 'error'; duration?: number }): void {\n        // Use PWA toast system\n        try {\n            import(\"../../../frontend/shared/Toast\").then(({ showToast }) => {\n                showToast({\n                    message,\n                    kind: options?.type || 'info',\n                    duration: options?.duration || 3000\n                });\n            });\n        } catch (e) {\n            console.log(message); // Fallback\n        }\n    }\n});\n\nconst createCrxAdapter = (): PlatformAdapter => ({\n    async copyToClipboard(data: string): Promise<ClipboardResult> {\n        try {\n            // Import CRX clipboard functionality\n            const { requestCopyViaCRX } = await import(\"../../../frontend/shared/Clipboard\");\n            const result = await requestCopyViaCRX(data);\n            return { ok: result.ok, data: result.data as string | undefined };\n        } catch (e) {\n            return { ok: false, error: String(e) as string | undefined };\n        }\n    },\n\n    async readFromClipboard(): Promise<ClipboardResult> {\n        try {\n            // CRX clipboard reading (may be limited)\n            if (navigator.clipboard?.readText) {\n                const text = await navigator.clipboard.readText();\n                return { ok: true, data: text };\n            }\n            return { ok: false, error: \"Clipboard access not available\" };\n        } catch (e) {\n            return { ok: false, error: String(e) };\n        }\n    },\n\n    async processImage(dataUrl: string, options?: ImageProcessingOptions): Promise<string> {\n        try {\n            // Check if we're in a service worker (no Canvas API)\n            const isServiceWorker = typeof window === 'undefined' || !window.document;\n\n            if (isServiceWorker) {\n                console.warn(\"[RecognizeData] Image processing not available in service worker context\");\n                return dataUrl;\n            }\n\n            // CRX has advanced image processing\n            const { encodeWithJSquash, removeAnyPrefix } = await import(\"../../utils/ImageProcess\");\n\n            // Compress if needed - use standardized size limit\n            const { MAX_BASE64_SIZE } = await import(\"../model/GPT-Responses\");\n            const SIZE_THRESHOLD = 2 * 1024 * 1024; // 2MB for data URL compression\n            if (dataUrl.length <= SIZE_THRESHOLD) return dataUrl;\n\n            // Convert to compressed JPEG\n            try {\n                // @ts-ignore\n                const binary = Uint8Array.fromBase64(removeAnyPrefix(dataUrl), { alphabet: \"base64\" });\n                const blob = new Blob([binary], { type: \"image/png\" });\n                const bitmap = await createImageBitmap(blob);\n                const arrayBuffer = await encodeWithJSquash(bitmap);\n                bitmap?.close?.();\n\n                if (arrayBuffer) { // @ts-ignore\n                    const base64 = new Uint8Array(arrayBuffer).toBase64({ alphabet: \"base64\" });\n                    return `data:image/jpeg;base64,${base64}`;\n                }\n            } catch (processingError) {\n                console.warn(\"[RecognizeData] Image compression failed:\", processingError);\n            }\n\n            return dataUrl;\n        } catch (e) {\n            console.warn(\"[RecognizeData] Image processing failed:\", e);\n            return dataUrl;\n        }\n    },\n\n    async captureScreenshot(rect?: { x: number; y: number; width: number; height: number }): Promise<string> {\n        try {\n            // CRX screenshot capture\n            if (typeof chrome !== 'undefined' && chrome.tabs?.captureVisibleTab) {\n                const captureOptions: any = { format: \"png\", scale: 1 };\n                if (rect) {\n                    captureOptions.rect = rect;\n                }\n\n                return new Promise((resolve, reject) => {\n                    chrome.tabs.captureVisibleTab(captureOptions, (dataUrl) => {\n                        if (chrome.runtime.lastError) {\n                            reject(new Error(chrome.runtime.lastError.message));\n                        } else {\n                            resolve(dataUrl);\n                        }\n                    });\n                });\n            }\n            throw new Error(\"Screenshot capture not available\");\n        } catch (e) {\n            throw new Error(`Screenshot capture failed: ${e}`);\n        }\n    },\n\n    showNotification(message: string, options?: { type?: 'info' | 'success' | 'warning' | 'error'; duration?: number }): void {\n        // Use CRX notification system or fallback to console\n        console.log(`[${options?.type || 'info'}] ${message}`);\n    }\n});\n\nconst createCoreAdapter = (): PlatformAdapter => ({\n    async copyToClipboard(data: string): Promise<ClipboardResult> {\n        try {\n            // Core has limited clipboard access, try modern API\n            if (navigator.clipboard?.writeText) {\n                await navigator.clipboard.writeText(data);\n                return { ok: true, data, method: \"clipboard-api\" };\n            }\n\n            // Fallback to legacy method\n            const textArea = document.createElement(\"textarea\");\n            textArea.value = data;\n            textArea.style.cssText = \"position:fixed;left:-9999px;top:-9999px;opacity:0;\";\n            document.body.appendChild(textArea);\n            textArea.select();\n\n            const success = document.execCommand(\"copy\");\n            textArea.remove();\n\n            return success\n                ? { ok: true, data, method: \"legacy\" }\n                : { ok: false, error: \"Copy failed\" };\n        } catch (e) {\n            return { ok: false, error: String(e) };\n        }\n    },\n\n    async readFromClipboard(): Promise<ClipboardResult> {\n        try {\n            if (navigator.clipboard?.readText) {\n                const text = await navigator.clipboard.readText();\n                return { ok: true, data: text };\n            }\n            return { ok: false, error: \"Clipboard access not available\" };\n        } catch (e) {\n            return { ok: false, error: String(e) };\n        }\n    },\n\n    showNotification(message: string, options?: { type?: 'info' | 'success' | 'warning' | 'error'; duration?: number }): void {\n        // Core uses console logging\n        console.log(`[${options?.type || 'info'}] ${message}`);\n    }\n});\n\n// Get the appropriate platform adapter\nexport const getPlatformAdapter = (): PlatformAdapter => {\n    const platform = detectPlatform();\n\n    switch (platform) {\n        case 'crx':\n            return createCrxAdapter();\n        case 'pwa':\n            return createPwaAdapter();\n        case 'core':\n        default:\n            return createCoreAdapter();\n    }\n};\n\n// Platform detection for unified behavior\nexport const detectPlatform = (): 'pwa' | 'crx' | 'core' | 'unknown' => {\n    try {\n        // Check for Chrome extension context\n        if (typeof chrome !== 'undefined' && chrome?.runtime?.id) {\n            return 'crx';\n        }\n\n        // Check for service worker context\n        if (typeof self !== 'undefined' && 'ServiceWorkerGlobalScope' in self) {\n            return 'pwa';\n        }\n\n        // Check for PWA context (standalone mode)\n        if (typeof navigator !== 'undefined' && 'standalone' in navigator) {\n            return 'pwa';\n        }\n\n        return 'core';\n    } catch {\n        return 'unknown';\n    }\n};\n\n// Unified settings loader that works across platforms\nexport const loadAISettings = async () => {\n    const platform = detectPlatform();\n    console.log(\"[AI] Detected platform:\", platform);\n\n    try {\n        if (platform === 'crx') {\n            console.log(\"[AI] Loading CRX settings...\");\n            // CRX uses direct settings loading\n            const settings = await loadSettings();\n            console.log(\"[AI] CRX settings loaded:\", !!settings, settings?.ai ? \"AI config present\" : \"No AI config\");\n            return settings;\n        } else {\n            console.log(\"[AI] Loading PWA/Core runtime settings...\");\n            // PWA/Core use runtime settings\n            const settings = await getRuntimeSettings();\n            console.log(\"[AI] Runtime settings loaded:\", !!settings, settings?.ai ? \"AI config present\" : \"No AI config\");\n            return settings;\n        }\n    } catch (e) {\n        console.error(`[AI-Service] Failed to load settings for platform ${platform}:`, e);\n        return null;\n    }\n};\n\n// Unified custom instruction loading that works across platforms\nexport const getActiveCustomInstruction = async (): Promise<string> => {\n    try {\n        // Try direct import first (works in most contexts)\n        const { getActiveInstructionText } = await import(\"../CustomInstructions\");\n        return await getActiveInstructionText();\n    } catch {\n        // Fallback for contexts where direct import fails\n        try {\n            const { getActiveInstructionText } = await import(\"../CustomInstructions\");\n            return await getActiveInstructionText();\n        } catch {\n            return \"\";\n        }\n    }\n};\n\n// Language instruction builders\nconst LANGUAGE_INSTRUCTIONS: Record<ResponseLanguage, string> = {\n    auto: \"\", // No explicit language instruction\n    en: \"\\n\\nIMPORTANT: Respond in English. All explanations, answers, and comments must be in English.\",\n    ru: \"\\n\\n:    .  ,        .\"\n};\n\nconst TRANSLATE_INSTRUCTION = \"\\n\\nAdditionally, translate the recognized content to the response language if it differs from the source.\";\n\n// Get language instruction based on settings (unified across platforms)\nexport const getLanguageInstruction = async (): Promise<string> => {\n    try {\n        const settings = await loadAISettings();\n        const lang = settings?.ai?.responseLanguage || \"auto\";\n        const translate = settings?.ai?.translateResults || false;\n\n        let instruction = LANGUAGE_INSTRUCTIONS[lang] || \"\";\n        if (translate && lang !== \"auto\") {\n            instruction += TRANSLATE_INSTRUCTION;\n        }\n        return instruction;\n    } catch {\n        return \"\";\n    }\n};\n\n// Get SVG graphics addon based on settings (unified across platforms)\nexport const getSvgGraphicsAddon = async (): Promise<string> => {\n    try {\n        const settings = await loadAISettings();\n        return settings?.ai?.generateSvgGraphics ? SVG_GRAPHICS_ADDON : \"\";\n    } catch {\n        return \"\";\n    }\n};\n\n//\nexport type RecognitionMode = \"auto\" | \"image\" | \"text\" | \"structured\" | \"mixed\";\n\nexport type RecognitionResult = {\n    ok: boolean;\n    recognized_data: any[];\n    keywords_and_tags: string[];\n    verbose_data: string;\n    suggested_type: string | null;\n    confidence: number;\n    source_kind: DataKind;\n    processing_time_ms: number;\n    errors: string[];\n    warnings: string[];\n}\n\nexport type BatchRecognitionResult = {\n    ok: boolean;\n    results: RecognitionResult[];\n    total_processed: number;\n    total_successful: number;\n    total_failed: number;\n    combined_keywords: string[];\n    processing_time_ms: number;\n}\n\nexport type ExtractionRule = {\n    name: string;\n    pattern?: string;\n    type: \"phone\" | \"email\" | \"url\" | \"date\" | \"time\" | \"number\" | \"code\" | \"custom\";\n    format?: string;\n    required?: boolean;\n}\n\nexport type ExtractionResult = {\n    field: string;\n    value: any;\n    confidence: number;\n    raw: string;\n    normalized: string;\n}\n\n//\nconst DEFAULT_MODEL = 'gpt-5.2';\nconst DEFAULT_API_URL = 'https://api.proxyapi.ru/openai/v1';\nconst ENDPOINT = '/responses';\n\n//\nexport const IMAGE_INSTRUCTION = `\nRecognize data from image, also preferred to orient by fonts in image.\n\nIn recognition result, do not include image itself.\n\nIn recognized from image data (what you seen in image), do:\n- If textual content, format as Markdown string (multiline).\n- If math (expression, equation, formula):\n  - For inline math, use SINGLE dollar signs: $x^2 + y^2 = z^2$\n  - For block/display math, use DOUBLE dollar signs: $$\\\\int_0^1 f(x) dx$$\n  - Do NOT add extra dollar signs - use exactly one $ for inline, exactly two $$ for block\n- If table (or looks alike table), format as | table |\n- If image reference, format as [$image$]($image$)\n- If code, format as \\`\\`\\`$code$\\`\\`\\` (multiline) or \\`$code$\\` (single-line)\n- If JSON, format as JSON string.\n- If phone number, format as correct phone number (in normalized format).\n  - If phone numbers (for example starts with +7, format as 8), replace to correct regional code.\n  - Trim spaces from phone numbers, emails, URLs, dates, times, codes, etc.\n  - Remove brackets, parentheses, spaces or other symbols from phone numbers.\n- If email, format as correct email (in normalized format).\n- If URL, format as correct URL (in normalized format), decode unicode to readable.\n- If date, format as correct date (ISO format preferred).\n- If time, format as correct time (24h format preferred).\n- If barcode/QR code, extract the encoded data.\n- If other, format as $text$.\n- If seen alike list, format as list (in markdown format).\n\nAdditional analysis:\n- Detect document type (receipt, business card, screenshot, etc.)\n- Extract structured data when possible (names, addresses, prices)\n- Identify any logos or branding\n- Note image quality issues that may affect recognition\n\nIf nothing found, return: {\"ok\": false, \"error\": \"No data recognized\"}\n\nCRITICAL OUTPUT FORMAT: Return ONLY valid JSON. No markdown code blocks, no explanations, no prose.\nYour response must start with { and end with }.\n\nExpected output structure:\n{\n    \"recognized_data\": [...],\n    \"keywords_and_tags\": [...],\n    \"verbose_data\": \"markdown description\",\n    \"document_type\": \"...\",\n    \"structured_extraction\": {...},\n    \"confidence\": 0.0-1.0,\n    \"quality_notes\": [...]\n}\n`;\n\n//\nexport const DATA_CONVERSION_INSTRUCTION = `\nHere may be HTML, Regular Text, LaTeX, etc input formats.\n\nNeeds to convert or reformat presented data to target format (Markdown string).\n\n- If textual content, format as Markdown string (multiline).\n- If math (expression, equation, formula):\n  - For inline math, use SINGLE dollar signs: $x^2 + y^2 = z^2$\n  - For block/display math, use DOUBLE dollar signs: $$\\\\int_0^1 f(x) dx$$\n  - Do NOT add extra dollar signs - use exactly one $ for inline, exactly two $$ for block\n- If table (or looks alike table), format as | table |\n- If image, format as [$image$]($image$)\n- If code, format as \\`\\`\\`$code$\\`\\`\\` (multiline) or \\`$code$\\` (single-line)\n- If JSON, format as correct JSON string, and trim spaces from JSON string.\n- If phone number, format as correct phone number (in normalized format).\n  - If phone numbers (for example starts with +7, format as 8), replace to correct regional code.\n  - Trim spaces from phone numbers, emails, URLs, dates, times, codes, etc.\n  - Remove brackets, parentheses, spaces or other symbols from phone numbers.\n- If email, format as correct email (in normalized format).\n- If URL, format as correct URL (in normalized format).\n- If date, format as correct date (ISO format preferred).\n- If time, format as correct time (24h format).\n- If other, format as $text$.\n- If seen alike list, format as list (in markdown format).\n\nAdditional processing:\n- Detect the source format (HTML, LaTeX, plain text, etc.)\n- Preserve semantic structure during conversion\n- Extract metadata if present\n- Normalize encoding issues\n\nCRITICAL OUTPUT FORMAT: Return ONLY valid JSON. No markdown code blocks, no explanations, no prose.\nYour response must start with { and end with }.\n\nExpected output structure:\n{\n    \"recognized_data\": [...],\n    \"keywords_and_tags\": [...],\n    \"verbose_data\": \"markdown content\",\n    \"source_format\": \"...\",\n    \"confidence\": 0.0-1.0\n}\n`;\n\n//\nexport const ENTITY_EXTRACTION_INSTRUCTION = `\nExtract structured entity data from the provided content.\n\nEntity types to detect:\n- task: jobs, actions, to-do items\n- event: meetings, appointments, occurrences\n- person: contacts, people mentions\n- place: locations, addresses, venues\n- service: products, offerings\n- item: goods, objects, inventory\n- factor: conditions, circumstances\n- bonus: promotions, discounts, codes\n\nFor each entity found, extract:\n- type: entity type from list above\n- id: suggested unique identifier\n- name: machine-readable name\n- title: human-readable title\n- kind: specific subtype\n- properties: relevant attributes\n- description: markdown description\n\nCRITICAL OUTPUT FORMAT: Return ONLY valid JSON. No markdown code blocks, no explanations, no prose.\nYour response must start with { and end with }.\n\nExpected output structure:\n{\n    \"entities\": [...],\n    \"keywords\": [...],\n    \"short_description\": \"markdown summary\",\n    \"extraction_confidence\": 0.0-1.0\n}\n`;\n\n//\nexport const SOLVE_AND_ANSWER_INSTRUCTION = `\nSolve equations, answer questions, and explain mathematical or logical problems from the provided content.\n\nFor equations and math problems:\n- Show step-by-step solutions\n- Provide final answers clearly marked\n- Explain reasoning for each step\n\nFor general questions:\n- Provide accurate, well-reasoned answers\n- Include relevant context and explanations\n- If multiple interpretations possible, address them\n\nFor quizzes and tests:\n- Show the correct answer with explanation\n- Explain why other options are incorrect\n\nAlways respond in the specified language and format results clearly.\n`;\n\nexport const EQUATION_SOLVE_INSTRUCTION = SOLVE_AND_ANSWER_INSTRUCTION;\nexport const ANSWER_QUESTION_INSTRUCTION = SOLVE_AND_ANSWER_INSTRUCTION;\n\nexport const WRITE_CODE_INSTRUCTION = `\nWrite clean, efficient, and well-documented code based on the provided description, requirements, or image.\n\nCode requirements:\n- Use appropriate programming language for the task\n- Follow language-specific best practices and conventions\n- Include proper error handling\n- Add meaningful comments and documentation\n- Make code readable and maintainable\n- Use appropriate data structures and algorithms\n\nIf generating from an image or visual description:\n- Analyze the visual elements and requirements\n- Implement the described functionality\n- Ensure code compiles and runs correctly\n\nAlways respond in the specified language and provide complete, working code.\n`;\n\nexport const EXTRACT_CSS_INSTRUCTION = `\nExtract and generate clean, modern CSS from the provided content, image, or description.\n\nCSS requirements:\n- Use modern CSS features and best practices\n- Generate semantic, maintainable stylesheets\n- Include responsive design considerations\n- Use appropriate selectors and specificity\n- Follow CSS naming conventions (BEM, etc.)\n- Include comments for complex styles\n\nIf extracting from an image:\n- Analyze visual design elements\n- Generate corresponding CSS rules\n- Preserve layout, colors, typography, and spacing\n- Use modern CSS features (Flexbox, Grid, etc.)\n\nAlways respond in the specified language and provide complete, valid CSS.\n`;\n\n//\nexport type AIConfig = { apiKey?: string; baseUrl?: string; model?: string };\n\n// Unified GPT instance creation that works across platforms\nexport const getGPTInstance = async (config?: AIConfig): Promise<GPTResponses | null> => {\n    console.log(\"[AI] getGPTInstance called with config:\", !!config);\n    const settings = await loadSettings();\n    console.log(\"[AI] Settings loaded:\", !!settings, settings?.ai ? \"AI settings present\" : \"No AI settings\");\n\n    const apiKey = config?.apiKey || settings?.ai?.apiKey;\n    console.log(\"[AI] API key available:\", !!apiKey);\n\n    if (!apiKey) {\n        console.error(\"[AI] No API key found - returning null\");\n        return null;\n    }\n\n    const baseUrl = config?.baseUrl || settings?.ai?.baseUrl || DEFAULT_API_URL;\n    const model = config?.model || settings?.ai?.model || DEFAULT_MODEL;\n    console.log(\"[AI] Creating GPT instance with URL:\", baseUrl, \"model:\", model);\n\n    return createGPTInstance(\n        apiKey,\n        baseUrl,\n        model\n    );\n}\n\n//\nexport type RecognizeByInstructionsOptions = {\n    customInstruction?: string;\n    useActiveInstruction?: boolean;\n};\n\n//\nexport const recognizeByInstructions = async (\n    input: any,\n    instructions: string,\n    sendResponse?: (result: any) => void,\n    config?: AIConfig,\n    options?: RecognizeByInstructionsOptions\n): Promise<{ ok: boolean; data?: string; error?: string }> => {\n    const settings = (await loadSettings())?.ai;\n\n    const token = config?.apiKey || settings?.apiKey;\n    if (!token) {\n        const result = { ok: false, error: \"No API key or input\" };\n        sendResponse?.(result);\n        return result;\n    }\n    if (!input) {\n        const result = { ok: false, error: \"No input provided\" };\n        sendResponse?.(result);\n        return result;\n    }\n\n    // Apply custom instructions if provided or if useActiveInstruction is set\n    let finalInstructions = instructions;\n    console.log(\"[RecognizeData] Custom instruction from options:\", !!options?.customInstruction);\n    console.log(\"[RecognizeData] useActiveInstruction:\", options?.useActiveInstruction);\n\n    if (options?.customInstruction) {\n        console.log(\"[RecognizeData] Using provided custom instruction\");\n        finalInstructions = buildInstructionPrompt(instructions, options.customInstruction);\n    } else if (options?.useActiveInstruction !== false) {\n        console.log(\"[RecognizeData] Fetching active instruction from settings...\");\n        const activeInstruction = await getActiveCustomInstruction();\n        console.log(\"[RecognizeData] Active instruction:\", activeInstruction ? `\"${activeInstruction.substring(0, 50)}...\"` : \"(none)\");\n        if (activeInstruction) {\n            finalInstructions = buildInstructionPrompt(instructions, activeInstruction);\n            console.log(\"[RecognizeData] Applied active custom instruction\");\n        }\n    } else {\n        console.log(\"[RecognizeData] Custom instructions disabled via options\");\n    }\n\n    // Use GPTResponses class instead of direct API call for consistency\n    const gpt = createGPTInstance(token, config?.baseUrl || settings?.baseUrl || DEFAULT_API_URL, config?.model || settings?.model || DEFAULT_MODEL);\n\n    // Clear any previous pending items and set up the instruction\n    gpt.clearPending();\n    await gpt.askToDoAction(finalInstructions);\n\n    // Check if input is already formatted as a message array (from analyzeRecognizeUnified)\n    if (Array.isArray(input) && (input?.[0]?.type === \"message\" || input?.[0]?.['role'])) {\n        // Input is already formatted, add it directly to pending\n        await gpt?.getPending?.()?.push?.(...input);\n    } else {\n        // Input is raw data source, attach it properly\n        await gpt?.attachToRequest?.(input);\n    }\n\n    // Send the request\n    let response;\n    let error;\n    try {\n        response = await gpt?.sendRequest?.(\"low\", \"low\");\n    } catch (e) {\n        error = String(e);\n    }\n\n    const output = {\n        ok: !!response && !error,\n        data: response?.trim?.() || undefined,\n        error: error || (response ? undefined : \"No response from AI\")\n    };\n\n    sendResponse?.(output);\n    return output;\n};\n\n//\nexport const recognizeImageData = async (\n    input: any,\n    sendResponse?: (result: any) => void,\n    config?: AIConfig,\n    options?: RecognizeByInstructionsOptions\n): Promise<{ ok: boolean; data?: string; error?: string }> => {\n    return recognizeByInstructions(input, IMAGE_INSTRUCTION, sendResponse, config, options);\n};\n\n//\nexport const convertTextualData = async (\n    input: any,\n    sendResponse?: (result: any) => void,\n    config?: AIConfig,\n    options?: RecognizeByInstructionsOptions\n): Promise<{ ok: boolean; data?: string; error?: string }> => {\n    return recognizeByInstructions(input, DATA_CONVERSION_INSTRUCTION, sendResponse, config, options);\n};\n\n//\nexport const analyzeRecognizeUnified = async (\n    rawData: File | Blob | string,\n    sendResponse?: (result: any) => void,\n    config?: AIConfig,\n    options?: RecognizeByInstructionsOptions\n): Promise<{ ok: boolean; data?: string; error?: string }> => {\n    const content = await getUsableData({ dataSource: rawData });\n    const input = [{\n        type: \"message\",\n        role: \"user\",\n        content: [content]\n    }];\n    return (content?.[0]?.type === \"input_image\" || content?.type === \"input_image\")\n        ? recognizeImageData(input, sendResponse, config, options)\n        : convertTextualData(input, sendResponse, config, options);\n};\n\n// === NEW ENHANCED FUNCTIONS ===\n\n//\nexport const recognizeWithContext = async (\n    data: File | Blob | string,\n    context: DataContext,\n    mode: RecognitionMode = \"auto\",\n    config?: AIConfig\n): Promise<RecognitionResult> => {\n    const startTime = performance.now();\n\n    const result: RecognitionResult = {\n        ok: false,\n        recognized_data: [],\n        keywords_and_tags: [],\n        verbose_data: \"\",\n        suggested_type: null,\n        confidence: 0,\n        source_kind: \"input_text\",\n        processing_time_ms: 0,\n        errors: [],\n        warnings: []\n    };\n\n    try {\n        const gpt = await getGPTInstance(config);\n        if (!gpt) {\n            result.errors.push(\"No GPT instance available\");\n            return result;\n        }\n\n        // Set context\n        gpt.setContext(context);\n\n        // Determine data kind\n        let dataKind: DataKind = \"input_text\";\n        if (data instanceof File || data instanceof Blob) {\n            if (data.type.startsWith(\"image/\")) {\n                dataKind = \"input_image\";\n            } else if (data.type.includes(\"json\")) {\n                dataKind = \"json\";\n            }\n        } else if (typeof data === \"string\") {\n            dataKind = detectDataKindFromContent(data);\n        }\n        result.source_kind = dataKind;\n\n        // Override mode if specified\n        if (mode === \"image\") dataKind = \"input_image\";\n        else if (mode === \"text\") dataKind = \"input_text\";\n        else if (mode === \"structured\") dataKind = \"json\";\n\n        // Attach data\n        if (Array.isArray(data) && (data?.[0]?.type === \"message\" || data?.[0]?.['role'])) {\n            await gpt?.getPending?.()?.push?.(...data);\n        } else {\n            await gpt?.attachToRequest?.(data, dataKind);\n        }\n\n        // Choose instruction based on kind\n        const instruction = dataKind === \"input_image\"\n            ? IMAGE_INSTRUCTION\n            : DATA_CONVERSION_INSTRUCTION;\n\n        // Add context to instruction\n        const contextAddition = context.entityType\n            ? `\\n\\nExpected entity type context: ${context.entityType}`\n            : \"\";\n        const searchAddition = context.searchTerms?.length\n            ? `\\n\\nFocus on finding: ${context.searchTerms.join(\", \")}`\n            : \"\";\n\n        await gpt.askToDoAction(instruction + contextAddition + searchAddition);\n\n        const raw = await gpt.sendRequest(\n            context.priority === \"high\" ? \"high\" : \"medium\",\n            \"medium\",\n            null,\n            { responseFormat: \"json\", temperature: 0.3 }\n        );\n\n        if (!raw) {\n            result.errors.push(\"No response from AI\");\n            return result;\n        }\n\n        // Use robust JSON extraction to handle markdown-wrapped responses\n        const parseResult = extractJSONFromAIResponse<any>(raw);\n        if (!parseResult.ok) {\n            console.warn(\"JSON extraction failed:\", parseResult.error, \"Raw:\", parseResult.raw);\n            result.errors.push(parseResult.error || \"Failed to parse AI response\");\n            // Attempt to use raw text as fallback\n            result.verbose_data = raw;\n            return result;\n        }\n\n        const parsed = parseResult.data;\n        result.ok = true;\n        result.recognized_data = parsed?.recognized_data || [parsed?.verbose_data || raw];\n        result.keywords_and_tags = parsed?.keywords_and_tags || parsed?.keywords || [];\n        result.verbose_data = parsed?.verbose_data || \"\";\n        result.suggested_type = parsed?.document_type || parsed?.source_format || null;\n        result.confidence = parsed?.confidence || 0.7;\n\n    } catch (e) {\n        console.error(\"Error in recognizeWithContext:\", e);\n        result.errors.push(String(e));\n    }\n\n    result.processing_time_ms = performance.now() - startTime;\n    return result;\n}\n\n//\nexport const batchRecognize = async (\n    items: (File | Blob | string)[],\n    context?: DataContext,\n    concurrency: number = 3,\n    config?: AIConfig\n): Promise<BatchRecognitionResult> => {\n    const startTime = performance.now();\n\n    const result: BatchRecognitionResult = {\n        ok: true,\n        results: [],\n        total_processed: items.length,\n        total_successful: 0,\n        total_failed: 0,\n        combined_keywords: [],\n        processing_time_ms: 0\n    };\n\n    const keywordSet = new Set<string>();\n\n    // Process in batches with concurrency limit\n    for (let i = 0; i < items.length; i += concurrency) {\n        const batch = items.slice(i, i + concurrency);\n\n        const promises = batch.map(item =>\n            recognizeWithContext(item, context || {}, \"auto\", config)\n        );\n\n        const batchResults = await Promise.all(promises);\n\n        for (const r of batchResults) {\n            result.results.push(r);\n\n            if (r.ok) {\n                result.total_successful++;\n                r.keywords_and_tags.forEach(k => keywordSet.add(k));\n            } else {\n                result.total_failed++;\n            }\n        }\n    }\n\n    result.ok = result.total_failed === 0;\n    result.combined_keywords = Array.from(keywordSet);\n    result.processing_time_ms = performance.now() - startTime;\n\n    return result;\n}\n\n//\nexport const extractEntities = async (\n    data: File | Blob | string,\n    config?: AIConfig\n): Promise<AIResponse<any[]>> => {\n    try {\n        const gpt = await getGPTInstance(config);\n        if (!gpt) {\n            return { ok: false, error: \"No GPT instance\" };\n        }\n\n        const dataKind = typeof data === \"string\"\n            ? detectDataKindFromContent(data)\n            : (data instanceof File || data instanceof Blob) && data.type.startsWith(\"image/\")\n                ? \"input_image\"\n                : \"input_text\";\n\n        //\n        if (Array.isArray(data) && (data?.[0]?.type === \"message\" || data?.[0]?.['role'])) {\n            await gpt?.getPending?.()?.push?.(...data);\n        } else {\n            await gpt?.attachToRequest?.(data, dataKind);\n        }\n\n        //\n        await gpt.askToDoAction(ENTITY_EXTRACTION_INSTRUCTION);\n\n        const raw = await gpt.sendRequest(\"high\", \"medium\", null, {\n            responseFormat: \"json\",\n            temperature: 0.2\n        });\n\n        if (!raw) {\n            return { ok: false, error: \"No response\" };\n        }\n\n        // Use robust JSON extraction to handle markdown-wrapped responses\n        const parseResult = extractJSONFromAIResponse<any>(raw);\n        if (!parseResult.ok) {\n            console.warn(\"JSON extraction failed:\", parseResult.error, \"Raw:\", parseResult.raw);\n            return { ok: false, error: parseResult.error || \"Failed to parse AI response\" };\n        }\n\n        return {\n            ok: true,\n            data: parseResult.data?.entities || [],\n            responseId: gpt.getResponseId()\n        };\n\n    } catch (e) {\n        console.error(\"Error in extractEntities:\", e);\n        return { ok: false, error: String(e) };\n    }\n}\n\n//\nexport const extractByRules = async (\n    data: string,\n    rules: ExtractionRule[]\n): Promise<ExtractionResult[]> => {\n    const results: ExtractionResult[] = [];\n\n    try {\n        const gpt = await getGPTInstance();\n        if (!gpt) {\n            return results;\n        }\n\n        const rulesDescription = rules.map(r =>\n            `- ${r.name} (${r.type}): ${r.pattern ? `pattern: ${r.pattern}` : \"auto-detect\"}${r.format ? `, format as: ${r.format}` : \"\"}${r.required ? \" [REQUIRED]\" : \"\"}`\n        ).join(\"\\n\");\n\n        await gpt.giveForRequest(`\nInput data:\n\\`\\`\\`\n${data}\n\\`\\`\\`\n\nExtraction rules:\n${rulesDescription}\n        `);\n\n        // Note: Using cleaner prompt without markdown code blocks\n        await gpt.askToDoAction(`\nExtract data according to the rules.\nFor each rule, find matching content and normalize it.\n\nCRITICAL OUTPUT FORMAT: Return ONLY valid JSON. No markdown code blocks, no explanations.\nYour response must start with { and end with }.\n\nExpected output structure:\n{\n    \"extractions\": [\n        {\n            \"field\": \"rule name\",\n            \"value\": \"normalized value\",\n            \"confidence\": 0.0-1.0,\n            \"raw\": \"original text\",\n            \"normalized\": \"formatted value\"\n        }\n    ],\n    \"missing_required\": [\"list of required fields not found\"]\n}\n        `);\n\n        const raw = await gpt.sendRequest(\"medium\", \"low\", null, {\n            responseFormat: \"json\",\n            temperature: 0.1\n        });\n\n        if (!raw) return results;\n\n        // Use robust JSON extraction to handle markdown-wrapped responses\n        const parseResult = extractJSONFromAIResponse<any>(raw);\n        if (!parseResult.ok || !parseResult.data) {\n            console.warn(\"JSON extraction failed in extractByRules:\", parseResult.error);\n            return results;\n        }\n\n        return parseResult.data?.extractions || [];\n    } catch (e) {\n        console.error(\"Error in extractByRules:\", e);\n        return results;\n    }\n}\n\n//\nexport const smartRecognize = async (\n    data: File | Blob | string,\n    hints?: {\n        expectedType?: string;\n        language?: string;\n        domain?: string;\n        extractEntities?: boolean;\n    },\n    config?: AIConfig\n): Promise<RecognitionResult & { entities?: any[] }> => {\n    const baseResult = await recognizeWithContext(data, {\n        entityType: hints?.expectedType,\n        searchTerms: hints?.domain ? [hints.domain] : undefined\n    }, \"auto\", config);\n\n    if (!baseResult.ok) {\n        return baseResult;\n    }\n\n    // Optionally extract entities\n    if (hints?.extractEntities) {\n        const entityResult = await extractEntities(data, config);\n        return {\n            ...baseResult,\n            entities: entityResult.ok ? entityResult.data : undefined\n        };\n    }\n\n    return baseResult;\n}\n\n//\nexport const recognizeAndNormalize = async (\n    data: File | Blob | string,\n    normalizations: {\n        phones?: boolean;\n        emails?: boolean;\n        urls?: boolean;\n        dates?: boolean;\n        addresses?: boolean;\n    } = {}\n): Promise<RecognitionResult & { normalized: Record<string, any[]> }> => {\n    const baseResult = await recognizeWithContext(data, {});\n\n    const normalized: Record<string, any[]> = {\n        phones: [],\n        emails: [],\n        urls: [],\n        dates: [],\n        addresses: []\n    };\n\n    if (!baseResult.ok) {\n        return { ...baseResult, normalized };\n    }\n\n    try {\n        const gpt = await getGPTInstance();\n        if (!gpt) {\n            return { ...baseResult, normalized };\n        }\n\n        const enabledNormalizations = Object.entries(normalizations)\n            .filter(([_, v]) => v)\n            .map(([k]) => k);\n\n        if (enabledNormalizations.length === 0) {\n            return { ...baseResult, normalized };\n        }\n\n        await gpt.giveForRequest(`\nRecognized data:\n\\`\\`\\`\n${baseResult.verbose_data || baseResult.recognized_data.join(\"\\n\")}\n\\`\\`\\`\n        `);\n\n        // Note: Using cleaner prompt without markdown code blocks\n        await gpt.askToDoAction(`\nExtract and normalize the following types: ${enabledNormalizations.join(\", \")}\n\nNormalization rules:\n- phones: E.164 format or local format with country code\n- emails: lowercase, trimmed\n- urls: full URL with protocol\n- dates: ISO 8601 format (YYYY-MM-DD or YYYY-MM-DDTHH:mm:ss)\n- addresses: structured with street, city, country if detectable\n\nCRITICAL OUTPUT FORMAT: Return ONLY valid JSON. No markdown code blocks, no explanations.\nYour response must start with { and end with }.\n\nExpected output structure:\n{\n    \"phones\": [\"...\"],\n    \"emails\": [\"...\"],\n    \"urls\": [\"...\"],\n    \"dates\": [\"...\"],\n    \"addresses\": [{ \"raw\": \"...\", \"structured\": {...} }]\n}\n        `);\n\n        const raw = await gpt.sendRequest(\"medium\", \"low\", null, {\n            responseFormat: \"json\",\n            temperature: 0.1\n        });\n\n        if (raw) {\n            // Use robust JSON extraction to handle markdown-wrapped responses\n            const parseResult = extractJSONFromAIResponse<any>(raw);\n            if (parseResult.ok && parseResult.data) {\n                Object.assign(normalized, parseResult.data);\n            } else {\n                console.warn(\"JSON extraction failed in normalization:\", parseResult.error);\n                baseResult.warnings.push(\"Normalization JSON parsing partially failed\");\n            }\n        }\n\n    } catch (e) {\n        console.error(\"Error in normalization phase:\", e);\n        baseResult.warnings.push(\"Normalization partially failed\");\n    }\n\n    return { ...baseResult, normalized };\n}\n\n//\nexport const recognizeFromClipboard = async (): Promise<RecognitionResult | null> => {\n    try {\n        // Try to read clipboard\n        const clipboardItems = await navigator.clipboard.read().catch(() => null);\n\n        if (clipboardItems) {\n            for (const item of clipboardItems) {\n                // Check for image\n                for (const type of item.types) {\n                    if (type.startsWith(\"image/\")) {\n                        const blob = await item.getType(type);\n                        return recognizeWithContext(blob, {});\n                    }\n                }\n            }\n        }\n\n        // Fallback to text\n        const text = await navigator.clipboard.readText().catch(() => null);\n        if (text) {\n            return recognizeWithContext(text, {});\n        }\n\n        return null;\n\n    } catch (e) {\n        console.error(\"Error reading clipboard:\", e);\n        return null;\n    }\n}\n\n//\nexport const solveAndAnswer = async (\n    input: any,\n    options?: RecognizeByInstructionsOptions\n): Promise<RecognitionResult> => {\n    console.log(\"[AI] solveAndAnswer called with input:\", input?.substring?.(0, 100) || input);\n\n    const gpt = await getGPTInstance();\n    console.log(\"[AI] GPT instance created:\", !!gpt);\n\n    if (!gpt) {\n        console.error(\"[AI] Failed to create GPT instance - check API key and settings\");\n        return { ok: false, recognized_data: [], keywords_and_tags: [], verbose_data: \"\", suggested_type: null, confidence: 0, source_kind: \"unknown\", processing_time_ms: 0, errors: [\"AI service not available\"], warnings: [] };\n    }\n\n    const startTime = Date.now();\n\n    try {\n        // Build instruction with language and SVG support\n        const languageInstruction = await getLanguageInstruction();\n        const svgAddon = await getSvgGraphicsAddon();\n        const instruction = SOLVE_AND_ANSWER_INSTRUCTION + languageInstruction + svgAddon;\n\n        // Apply custom instruction if provided\n        let customInstruction = \"\";\n        if (options?.customInstruction) {\n            customInstruction = options.customInstruction;\n        } else if (options?.useActiveInstruction) {\n            customInstruction = await getActiveCustomInstruction();\n        }\n\n        if (customInstruction) {\n            await gpt.askToDoAction(customInstruction);\n        }\n\n        // Set up the solve/answer instruction\n        await gpt.askToDoAction(instruction);\n\n        // Give input data\n        await gpt.giveForRequest(input);\n\n        // Send request and get response\n        console.log(\"[AI] Sending request with effort='high', verbosity='medium'\");\n        const rawResponse = await gpt.sendRequest(\"high\", \"medium\");\n        const processingTime = Date.now() - startTime;\n\n        console.log(\"[AI] Raw response received:\", !!rawResponse, rawResponse?.substring?.(0, 200) || \"null/empty\");\n\n        if (rawResponse) {\n            console.log(\"[AI] solveAndAnswer success\");\n            return {\n                ok: true,\n                recognized_data: [rawResponse],\n                keywords_and_tags: [\"solution\", \"answer\"],\n                verbose_data: rawResponse,\n                suggested_type: \"solution\",\n                confidence: 0.9,\n                source_kind: \"text\" as unknown as DataKind,\n                processing_time_ms: processingTime,\n                errors: [],\n                warnings: []\n            };\n        } else {\n            console.error(\"[AI] solveAndAnswer failed - no response from sendRequest\");\n            return {\n                ok: false,\n                recognized_data: [],\n                keywords_and_tags: [],\n                verbose_data: \"\",\n                suggested_type: null,\n                confidence: 0,\n                source_kind: \"unknown\",\n                processing_time_ms: processingTime,\n                errors: [\"Failed to get response\"],\n                warnings: []\n            };\n        }\n    } catch (e) {\n        return {\n            ok: false,\n            recognized_data: [],\n            keywords_and_tags: [],\n            verbose_data: \"\",\n            suggested_type: null,\n            confidence: 0,\n            source_kind: \"unknown\",\n            processing_time_ms: Date.now() - startTime,\n            errors: [String(e)],\n            warnings: []\n        };\n    }\n};\n\n//\nexport const writeCode = async (\n    input: any,\n    options?: RecognizeByInstructionsOptions\n): Promise<RecognitionResult> => {\n    const gpt = await getGPTInstance();\n    if (!gpt) return { ok: false, recognized_data: [], keywords_and_tags: [], verbose_data: \"\", suggested_type: null, confidence: 0, source_kind: \"unknown\", processing_time_ms: 0, errors: [\"AI service not available\"], warnings: [] };\n\n    const startTime = Date.now();\n\n    try {\n        // Build instruction with language and SVG support\n        const languageInstruction = await getLanguageInstruction();\n        const svgAddon = await getSvgGraphicsAddon();\n        const instruction = WRITE_CODE_INSTRUCTION + languageInstruction + svgAddon;\n\n        // Apply custom instruction if provided\n        let customInstruction = \"\";\n        if (options?.customInstruction) {\n            customInstruction = options.customInstruction;\n        } else if (options?.useActiveInstruction) {\n            customInstruction = await getActiveCustomInstruction();\n        }\n\n        if (customInstruction) {\n            await gpt.askToDoAction(customInstruction);\n        }\n\n        // Set up the code writing instruction\n        await gpt.askToDoAction(instruction);\n\n        // Give input data\n        await gpt.giveForRequest(input);\n\n        // Send request and get response\n        const rawResponse = await gpt.sendRequest(\"high\", \"medium\");\n        const processingTime = Date.now() - startTime;\n\n        if (rawResponse) {\n            return {\n                ok: true,\n                recognized_data: [rawResponse],\n                keywords_and_tags: [\"code\", \"programming\"],\n                verbose_data: rawResponse,\n                suggested_type: \"code\",\n                confidence: 0.9,\n                source_kind: \"text\" as unknown as DataKind,\n                processing_time_ms: processingTime,\n                errors: [],\n                warnings: []\n            };\n        } else {\n            return {\n                ok: false,\n                recognized_data: [],\n                keywords_and_tags: [],\n                verbose_data: \"\",\n                suggested_type: null,\n                confidence: 0,\n                source_kind: \"unknown\",\n                processing_time_ms: processingTime,\n                errors: [\"Failed to generate code\"],\n                warnings: []\n            };\n        }\n    } catch (e) {\n        return {\n            ok: false,\n            recognized_data: [],\n            keywords_and_tags: [],\n            verbose_data: \"\",\n            suggested_type: null,\n            confidence: 0,\n            source_kind: \"unknown\",\n            processing_time_ms: Date.now() - startTime,\n            errors: [String(e)],\n            warnings: []\n        };\n    }\n};\n\n//\nexport const extractCSS = async (\n    input: any,\n    options?: RecognizeByInstructionsOptions\n): Promise<RecognitionResult> => {\n    const gpt = await getGPTInstance();\n    if (!gpt) return { ok: false, recognized_data: [], keywords_and_tags: [], verbose_data: \"\", suggested_type: null, confidence: 0, source_kind: \"unknown\", processing_time_ms: 0, errors: [\"AI service not available\"], warnings: [] };\n\n    const startTime = Date.now();\n\n    try {\n        // Build instruction with language and SVG support\n        const languageInstruction = await getLanguageInstruction();\n        const svgAddon = await getSvgGraphicsAddon();\n        const instruction = EXTRACT_CSS_INSTRUCTION + languageInstruction + svgAddon;\n\n        // Apply custom instruction if provided\n        let customInstruction = \"\";\n        if (options?.customInstruction) {\n            customInstruction = options.customInstruction;\n        } else if (options?.useActiveInstruction) {\n            customInstruction = await getActiveCustomInstruction();\n        }\n\n        if (customInstruction) {\n            await gpt.askToDoAction(customInstruction);\n        }\n\n        // Set up the CSS extraction instruction\n        await gpt.askToDoAction(instruction);\n\n        // Give input data\n        await gpt.giveForRequest(input);\n\n        // Send request and get response\n        const rawResponse = await gpt.sendRequest(\"high\", \"medium\");\n        const processingTime = Date.now() - startTime;\n\n        if (rawResponse) {\n            return {\n                ok: true,\n                recognized_data: [rawResponse],\n                keywords_and_tags: [\"css\", \"styles\", \"stylesheet\"],\n                verbose_data: rawResponse,\n                suggested_type: \"css\",\n                confidence: 0.9,\n                source_kind: \"text\" as unknown as DataKind,\n                processing_time_ms: processingTime,\n                errors: [],\n                warnings: []\n            };\n        } else {\n            return {\n                ok: false,\n                recognized_data: [],\n                keywords_and_tags: [],\n                verbose_data: \"\",\n                suggested_type: null,\n                confidence: 0,\n                source_kind: \"unknown\",\n                processing_time_ms: processingTime,\n                errors: [\"Failed to extract CSS\"],\n                warnings: []\n            };\n        }\n    } catch (e) {\n        return {\n            ok: false,\n            recognized_data: [],\n            keywords_and_tags: [],\n            verbose_data: \"\",\n            suggested_type: null,\n            confidence: 0,\n            source_kind: \"unknown\",\n            processing_time_ms: Date.now() - startTime,\n            errors: [String(e)],\n            warnings: []\n        };\n    }\n};\n\n// Convenience aliases\nexport const solveEquation = solveAndAnswer;\nexport const answerQuestion = solveAndAnswer;\n\n// ============================================================================\n// UNIFIED AI SERVICE INTERFACE\n// ============================================================================\n// This interface provides consistent access to all AI functions across platforms\n// (PWA, CRX, Core, ShareTarget). All platforms should use these exports.\n\nexport const UnifiedAIService = {\n    // Platform detection and adaptation\n    detectPlatform,\n    getPlatformAdapter,\n\n    // Settings and configuration\n    loadAISettings,\n    getLanguageInstruction,\n    getSvgGraphicsAddon,\n    getActiveCustomInstruction,\n\n    // Core AI functions\n    recognizeByInstructions,\n    recognizeImageData,\n    convertTextualData,\n    analyzeRecognizeUnified,\n\n    // Specialized AI functions (unified across platforms)\n    solveAndAnswer,\n    solveEquation,\n    answerQuestion,\n    writeCode,\n    extractCSS,\n\n    // Utility functions\n    batchRecognize,\n    extractEntities,\n    smartRecognize\n\n    // Types are available as module exports: RecognitionResult, BatchRecognitionResult, etc.\n};\n\n// Default export for convenience\nexport default UnifiedAIService;\n","/*\n * Custom Instructions Service\n * Manages user-defined instructions for AI recognition operations\n */\n\nimport { loadSettings, saveSettings } from \"@rs-core/config/Settings\";\nimport type { AppSettings } from \"@rs-core/config/SettingsTypes\";\nimport {\n    generateInstructionId,\n    buildInstructionPrompt,\n    DEFAULT_INSTRUCTION_TEMPLATES,\n    type CustomInstruction\n} from \"./InstructionUtils\";\n\nexport type { CustomInstruction };\nexport { buildInstructionPrompt, DEFAULT_INSTRUCTION_TEMPLATES };\n\nconst generateId = generateInstructionId;\n\nexport const getCustomInstructions = async (): Promise<CustomInstruction[]> => {\n    const settings = await loadSettings();\n    return settings?.ai?.customInstructions || [];\n};\n\nexport const getActiveInstruction = async (): Promise<CustomInstruction | null> => {\n    try {\n        const settings = await loadSettings();\n        const instructions = settings?.ai?.customInstructions || [];\n        const activeId = settings?.ai?.activeInstructionId;\n\n        console.log(\"[CustomInstructions] getActiveInstruction - activeId:\", activeId);\n        console.log(\"[CustomInstructions] getActiveInstruction - instructions count:\", instructions.length);\n\n        if (!activeId) {\n            console.log(\"[CustomInstructions] No activeInstructionId set\");\n            return null;\n        }\n\n        const active = instructions.find(i => i.id === activeId);\n        if (active) {\n            console.log(\"[CustomInstructions] Found active instruction:\", active.label);\n        } else {\n            console.warn(\"[CustomInstructions] activeInstructionId not found in instructions:\", activeId);\n            console.log(\"[CustomInstructions] Available IDs:\", instructions.map(i => i.id));\n        }\n\n        return active || null;\n    } catch (e) {\n        console.error(\"[CustomInstructions] Error in getActiveInstruction:\", e);\n        return null;\n    }\n};\n\nexport const getActiveInstructionText = async (): Promise<string> => {\n    const instruction = await getActiveInstruction();\n    const text = instruction?.instruction || \"\";\n    console.log(\"[CustomInstructions] getActiveInstructionText:\", text ? `\"${text.substring(0, 50)}...\"` : \"(empty)\");\n    return text;\n};\n\nexport const setActiveInstruction = async (id: string | null): Promise<void> => {\n    const settings = await loadSettings();\n    const updated: AppSettings = {\n        ...settings,\n        ai: {\n            ...settings.ai,\n            activeInstructionId: id || \"\"\n        }\n    };\n    await saveSettings(updated);\n};\n\nexport const addInstruction = async (label: string, instruction: string): Promise<CustomInstruction> => {\n    const settings = await loadSettings();\n    const instructions = settings?.ai?.customInstructions || [];\n\n    const newInstruction: CustomInstruction = {\n        id: generateId(),\n        label: label.trim() || \"Untitled\",\n        instruction: instruction.trim(),\n        enabled: true,\n        order: instructions.length\n    };\n\n    const updated: AppSettings = {\n        ...settings,\n        ai: {\n            ...settings.ai,\n            customInstructions: [...instructions, newInstruction]\n        }\n    };\n\n    await saveSettings(updated);\n    return newInstruction;\n};\n\n/**\n * Add multiple instructions at once (avoids race conditions from parallel saves)\n */\nexport const addInstructions = async (\n    items: { label: string; instruction: string; enabled?: boolean }[]\n): Promise<CustomInstruction[]> => {\n    if (!items.length) return [];\n\n    const settings = await loadSettings();\n    const instructions = settings?.ai?.customInstructions || [];\n\n    const newInstructions: CustomInstruction[] = items.map((item, index) => ({\n        id: generateId(),\n        label: item.label.trim() || \"Untitled\",\n        instruction: item.instruction.trim(),\n        enabled: item.enabled ?? true,\n        order: instructions.length + index\n    }));\n\n    const updated: AppSettings = {\n        ...settings,\n        ai: {\n            ...settings.ai,\n            customInstructions: [...instructions, ...newInstructions]\n        }\n    };\n\n    await saveSettings(updated);\n    return newInstructions;\n};\n\nexport const updateInstruction = async (id: string, updates: Partial<Omit<CustomInstruction, \"id\">>): Promise<boolean> => {\n    const settings = await loadSettings();\n    const instructions = settings?.ai?.customInstructions || [];\n    const index = instructions.findIndex(i => i.id === id);\n\n    if (index === -1) return false;\n\n    instructions[index] = { ...instructions[index], ...updates };\n\n    const updated: AppSettings = {\n        ...settings,\n        ai: {\n            ...settings.ai,\n            customInstructions: instructions\n        }\n    };\n\n    await saveSettings(updated);\n    return true;\n};\n\nexport const deleteInstruction = async (id: string): Promise<boolean> => {\n    const settings = await loadSettings();\n    const instructions = settings?.ai?.customInstructions || [];\n    const filtered = instructions.filter(i => i.id !== id);\n\n    if (filtered.length === instructions.length) return false;\n\n    // If deleting the active instruction, clear activeInstructionId\n    const newActiveId = settings.ai?.activeInstructionId === id ? \"\" : (settings.ai?.activeInstructionId || \"\");\n\n    const updated: AppSettings = {\n        ...settings,\n        ai: {\n            ...settings.ai,\n            customInstructions: filtered,\n            activeInstructionId: newActiveId\n        }\n    };\n\n    await saveSettings(updated);\n    return true;\n};\n\nexport const reorderInstructions = async (orderedIds: string[]): Promise<void> => {\n    const settings = await loadSettings();\n    const instructions = settings?.ai?.customInstructions || [];\n\n    const reordered = orderedIds\n        .map((id, index) => {\n            const instr = instructions.find(i => i.id === id);\n            return instr ? { ...instr, order: index } : null;\n        })\n        .filter((i): i is any => i !== null && i !== undefined) as CustomInstruction[];\n\n    const updated: AppSettings = {\n        ...settings,\n        ai: {\n            ...settings.ai,\n            customInstructions: reordered\n        }\n    };\n\n    await saveSettings(updated);\n};\n\nexport const addDefaultTemplates = async (): Promise<CustomInstruction[]> => {\n    const settings = await loadSettings();\n    const existing = settings?.ai?.customInstructions || [];\n\n    if (existing.length > 0) return existing;\n\n    const newInstructions: CustomInstruction[] = DEFAULT_INSTRUCTION_TEMPLATES.map((template, index) => ({\n        ...template,\n        id: generateId(),\n        order: index\n    }));\n\n    const updated: AppSettings = {\n        ...settings,\n        ai: {\n            ...settings.ai,\n            customInstructions: newInstructions\n        }\n    };\n\n    await saveSettings(updated);\n    return newInstructions;\n};\n"],"file":"CustomInstructions.js"}